--- context size varying
(40% used for test)

99 utterances, 0 context, DBN[13, 512, 512, 512, 512, 48], 12 epochs: accuracy=0.285305
99 utterances, 1 context, DBN[39, 512, 512, 512, 512, 48], 12 epochs: accuracy=0.472697
99 utterances, 2 context, DBN[65, 512, 512, 512, 512, 48], 12 epochs: accuracy=0.577273
99 utterances, 3 context, DBN[91, 512, 512, 512, 512, 48], 12 epochs: accuracy=0.694279
99 utterances, 5 context, DBN[143, 512, 512, 512, 512, 48], 12 epochs: accuracy=0.764866
99 utterances, 6 context, DBN[169, 512, 512, 512, 512, 48], 12 epochs: accuracy=0.802273
99 utterances, 7 context, DBN[195, 512, 512, 512, 512, 48], 12 epochs: accuracy=0.804144
99 utterances, 8 context, DBN[221, 512, 512, 512, 512, 48], 12 epochs: accuracy=0.817894
99 utterances, 9 context, DBN[247, 512, 512, 512, 512, 48], 12 epochs: accuracy=0.840088
99 utterances, 10 context, DBN[273, 512, 512, 512, 512, 48], 12 epochs: accuracy=0.841006
99 utterances, 11 context, DBN[299, 512, 512, 512, 512, 48], 12 epochs: accuracy=0.836398
99 utterances, 12 context, DBN[325, 512, 512, 512, 512, 48], 12 epochs: accuracy=0.529815

--- layers varying
(40% used for test)

99 utterances, 9 context, DBN[247, 256, 48], 12 epochs: accuracy=0.445458
99 utterances, 9 context, DBN[247, 512, 48], 12 epochs: accuracy=0.459473
99 utterances, 9 context, DBN[247, 1024, 48], 12 epochs: accuracy=0.467747
99 utterances, 9 context, DBN[247, 2048, 48], 12 epochs: accuracy=0.486153

99 utterances, 9 context, DBN[247, 256, 256, 48], 12 epochs: accuracy=0.680176
99 utterances, 9 context, DBN[247, 512, 512, 48], 12 epochs: accuracy=0.748734
99 utterances, 9 context, DBN[247, 1024, 1024, 48], 12 epochs: accuracy=0.797028
99 utterances, 9 context, DBN[247, 2048, 2048, 48], 12 epochs: accuracy=0.806484

99 utterances, 9 context, DBN[247, 256, 256, 256, 48], 12 epochs: accuracy=0.742317
99 utterances, 9 context, DBN[247, 512, 512, 512, 48], 12 epochs: accuracy=0.852246
99 utterances, 9 context, DBN[247, 1024, 1024, 1024, 48], 12 epochs: accuracy=0.876900
99 utterances, 9 context, DBN[247, 2048, 2048, 2048, 48], 12 epochs: accuracy=0.003884
295 utterances, 7 context, DBN[195, 2048, 2048, 2048, 70], 12 epochs: accuracy=0.836887

99 utterances, 9 context, DBN[247, 256, 256, 256, 256, 48], 12 epochs: accuracy=0.712428
99 utterances, 9 context, DBN[247, 512, 512, 512, 512, 48], 12 epochs: accuracy=0.832827
99 utterances, 9 context, DBN[247, 1024, 1024, 1024, 1024, 48], 12 epochs: accuracy=0.848024
99 utterances, 9 context, DBN[247, 2048, 2048, 2048, 2048, 48], 12 epochs: accuracy=0.003884

99 utterances, 9 context, DBN[247, 256, 256, 256, 256, 256, 48], 12 epochs: accuracy=0.592199
99 utterances, 9 context, DBN[247, 512, 512, 512, 512, 512, 48], 12 epochs: accuracy=0.815434
99 utterances, 9 context, DBN[247, 1024, 1024, 1024, 1024, 1024, 48], 12 epochs: accuracy=0.801587

--- early stopping
(40% used for test, 40% of rest used for held out validation)

49 utterances, 7 context, DBN[195, 512, 512, 512, 35], 20 epochs: accuracy=0.748904
99 utterances, 7 context, DBN[195, 512, 512, 512, 48], 20 epochs: accuracy=0.753015
99 utterances, 7 context, DBN[195, 512, 512, 512, 48], 30 epochs: accuracy=0.820589
99 utterances, 7 context, DBN[195, 512, 512, 512, 48], 40 epochs: accuracy=0.832510
99 utterances, 7 context, DBN[195, 512, 512, 512, 48], 50 epochs: accuracy=0.834978
99 utterances, 7 context, DBN[195, 512, 512, 512, 48], 60 epochs: accuracy=0.834703
99 utterances, 7 context, DBN[195, 512, 512, 512, 48], 80 epochs: accuracy=0.835526
99 utterances, 7 context, DBN[195, 512, 512, 512, 48], 100 epochs: accuracy=0.835389
10 utterances, 10 context, DBN[273, 256, 256, 256, 21], 80 epochs: accuracy=0.697907
10 utterances, 10 context, DBN[273, 256, 256, 256, 21], 80 epochs: accuracy=0.697907

99 utterances, 10 context, DBN[273, 512, 512, 512, 512, 48], 40 epochs: accuracy=0.868390
99 utterances, 10 context, DBN[273, 1024, 1024, 1024, 48], 40 epochs: accuracy=0.874037
99 utterances, 9 context, DBN[247, 1024, 1024, 1024, 48], 40 epochs: accuracy=0.878757

--- pretraining epochs varying

29 utterances, 0 context, DBN[13, 256, 256, 256, 32], 15 epochs: accuracy=0.187013
29 utterances, 2 context, DBN[65, 256, 256, 256, 32], 15 epochs: accuracy=0.181537
29 utterances, 0 context, DBN[13, 512, 512, 512, 32], 15 epochs: accuracy=0.187013

495 utterances, 9 context, DBN[247, 1024, 1024, 1024, 143], 15 epochs: accuracy=0.000087
495 utterances, 9 context, DBN[247, 1024, 1024, 1024, 143], 15 epochs: accuracy=0.000087

595 utterances, 0 context, DBN[13, 1024, 1024, 1024, 167], 10 epochs: accuracy=0.183730
595 utterances, 0 context, DBN[13, 1024, 1024, 1024, 167], 10 epochs: accuracy=0.079302
595 utterances, 0 context, DBN[13, 1024, 1024, 1024, 167], 10 epochs: accuracy=0.079302
595 utterances, 0 context, DBN[13, 1024, 1024, 1024, 167], 10 epochs: accuracy=0.079302

--- trying to predict

295 utterances, 9 context, DBN[247, 1024, 1024, 1024, 70], 0 pretrain_epochs, 15 epochs: accuracy=0.919470
295 utterances, 9 context, DBN[247, 1024, 1024, 1024, 70], 0 pretrain_epochs, 40 epochs: accuracy=0.946197
99 utterances, 10 context, DBN[273, 1024, 1024, 1024, 48], 0 pretrain_epochs, 15 epochs: accuracy=0.808771
295 utterances, 10 context, DBN[273, 1024, 1024, 1024, 70], 0 pretrain_epochs, 15 epochs: accuracy=0.799909
295 utterances, 10 context, DBN[273, 1024, 1024, 1024, 70], 0 pretrain_epochs, 15 epochs: accuracy=0.916046
295 utterances, 10 context, DBN[273, 1024, 1024, 1024, 70], 0 pretrain_epochs, 15 epochs: accuracy=0.484841

99 utterances, 10 context, DBN[273, 1024, 1024, 1024, 48], 0 pretrain_epochs, 15 epochs, validation True: accuracy=0.808771
99 utterances, 10 context, DBN[273, 1024, 1024, 1024, 48], 0 pretrain_epochs, 15 epochs, validation True: accuracy=0.812681
99 utterances, 10 context, DBN[273, 1024, 1024, 1024, 48], 0 pretrain_epochs, 15 epochs, validation True: accuracy=0.788373
97 utterances, 10 context, DBN[273, 1024, 1024, 1024, 48], 0 pretrain_epochs, 15 epochs, validation True: accuracy=0.813071
292 utterances, 10 context, DBN[273, 1024, 1024, 1024, 70], 0 pretrain_epochs, 15 epochs, validation False: accuracy=0.918724
97 utterances, 10 context, DBN[273, 1024, 1024, 1024, 48], 0 pretrain_epochs, 15 epochs, validation True: accuracy=0.814106
99 utterances, 10 context, DBN[273, 1024, 1024, 1024, 48], 0 pretrain_epochs, 10 epochs, validation True: accuracy=0.695733


50 utterances, 10 context, DBN[273, 1024, 1024, 1024, 48], 0 pretrain_epochs, 15 epochs, validation True: accuracy=0.870895
60 utterances, 10 context, DBN[273, 1024, 1024, 1024, 48], 0 pretrain_epochs, 15 epochs, validation size 0.2: accuracy=0.888697
60 utterances, 10 context, DBN[273, 1024, 1024, 1024, 48], 0 pretrain_epochs, 15 epochs, validation size 0.2: accuracy=0.155880
60 utterances, 10 context, DBN[273, 1024, 1024, 1024, 48], 0 pretrain_epochs, 15 epochs, validation size 0.2: accuracy=0.150096
100 utterances, 10 context, DBN[273, 1024, 1024, 1024, 48], 0 pretrain_epochs, 15 epochs, validation size 0.4: accuracy=0.241641

===============================
--- trying everything again


--- layers size
300 utterances, 9 context, DBN[247, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.177222
300 utterances, 9 context, DBN[247, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.184356
300 utterances, 9 context, DBN[247, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.195058
300 utterances, 9 context, DBN[247, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.178824
300 utterances, 9 context, DBN[247, 256, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.206638
300 utterances, 9 context, DBN[247, 512, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.206328
300 utterances, 9 context, DBN[247, 1024, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.192163
300 utterances, 9 context, DBN[247, 2048, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.205191
300 utterances, 9 context, DBN[247, 256, 256, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.176291
300 utterances, 9 context, DBN[247, 512, 512, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.172982
300 utterances, 9 context, DBN[247, 1024, 1024, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.153492
300 utterances, 9 context, DBN[247, 2048, 2048, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.165435
300 utterances, 9 context, DBN[247, 256, 256, 256, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.152665
300 utterances, 9 context, DBN[247, 512, 512, 512, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.159179
300 utterances, 9 context, DBN[247, 1024, 1024, 1024, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.158093
300 utterances, 9 context, DBN[247, 2048, 2048, 2048, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.159696
300 utterances, 9 context, DBN[247, 256, 256, 256, 256, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.150132
300 utterances, 9 context, DBN[247, 512, 512, 512, 512, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.156853
300 utterances, 9 context, DBN[247, 1024, 1024, 1024, 1024, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.145944
300 utterances, 9 context, DBN[247, 2048, 2048, 2048, 2048, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.010960
300 utterances, 9 context, DBN[247, 256, 256, 256, 256, 256, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.119061
300 utterances, 9 context, DBN[247, 512, 512, 512, 512, 512, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.137621
300 utterances, 9 context, DBN[247, 1024, 1024, 1024, 1024, 1024, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.133847
300 utterances, 9 context, DBN[247, 2048, 2048, 2048, 2048, 2048, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.010960

300 utterances, 0 context, DBN[13, 1024, 1024, 1024, 1024, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.150204
300 utterances, 1 context, DBN[39, 1024, 1024, 1024, 1024, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.125637
300 utterances, 2 context, DBN[65, 1024, 1024, 1024, 1024, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.126082
300 utterances, 3 context, DBN[91, 1024, 1024, 1024, 1024, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.130426
300 utterances, 4 context, DBN[117, 1024, 1024, 1024, 1024, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.135472
300 utterances, 5 context, DBN[143, 1024, 1024, 1024, 1024, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.133380
300 utterances, 6 context, DBN[169, 1024, 1024, 1024, 1024, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.134197
300 utterances, 7 context, DBN[195, 1024, 1024, 1024, 1024, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.147071
300 utterances, 8 context, DBN[221, 1024, 1024, 1024, 1024, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.154357
300 utterances, 9 context, DBN[247, 1024, 1024, 1024, 1024, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.139951
300 utterances, 10 context, DBN[273, 1024, 1024, 1024, 1024, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.155060
300 utterances, 11 context, DBN[299, 1024, 1024, 1024, 1024, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.156539
300 utterances, 12 context, DBN[325, 1024, 1024, 1024, 1024, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.160315
300 utterances, 13 context, DBN[351, 1024, 1024, 1024, 1024, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.177534
300 utterances, 14 context, DBN[377, 1024, 1024, 1024, 1024, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.162970
300 utterances, 15 context, DBN[403, 1024, 1024, 1024, 1024, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.165572
300 utterances, 16 context, DBN[429, 1024, 1024, 1024, 1024, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.170173
300 utterances, 17 context, DBN[455, 1024, 1024, 1024, 1024, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.166195
300 utterances, 18 context, DBN[481, 1024, 1024, 1024, 1024, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.163655
300 utterances, 19 context, DBN[507, 1024, 1024, 1024, 1024, 72], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.154851

100 utterances, 9 context, DBN[247, 1024, 48], 0 pretrain_epochs, 10 epochs, LR=0.1, validation size 0.2: accuracy=0.178841309824
100 utterances, 9 context, DBN[247, 1024, 48], 0 pretrain_epochs, 10 epochs, LR=0.01, validation size 0.2: accuracy=0.198092839151
100 utterances, 9 context, DBN[247, 1024, 48], 0 pretrain_epochs, 2 epochs, LR=0.01, validation size 0.2: accuracy=0.154680460537
100 utterances, 9 context, DBN[247, 1024, 48], 0 pretrain_epochs, 10 epochs, LR=0.001, validation size 0.2: accuracy=0.112630442605
100 utterances, 9 context, DBN[247, 1024, 48], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.325598802395
100 utterances, 9 context, DBN[247, 1024, 48], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.194560669456
100 utterances, 9 context, DBN[247, 1024, 48], 0 pretrain_epochs, 10 epochs, validation size 0.0: accuracy=0.129707112971
3000 utterances, 9 context, DBN[247, 1024, 1024, 1024, 1024, 297], 0 pretrain_epochs, 10 epochs, validation size 0.1: accuracy=0.130318506361

--- 18 MFCC features

100 utt., 7 cont., DBN[270, 512, 512, 512, 48], 0 pre- epochs, 10 epochs, LR: 0.01, valid. size 0.1: accuracy=0.234164517054
100 utt., 7 cont., DBN[1920, 512, 512, 512, 48], 0 pre- epochs, 5 epochs, LR: 0.01, valid. size 0.1: accuracy=0.193258426966

--- spec features

100 utterances, 0 context, DBN[128, 512, 512, 512, 48], 0 pretrain_epochs, 10 epochs, validation size 0.1: accuracy=0.247094188377
100 utterances, 0 context, DBN[128, 1024, 1024, 1024, 48], 0 pretrain_epochs, 10 epochs, validation size 0.1: accuracy=0.181658193195
100 utterances, 3 context, DBN[896, 512, 512, 512, 48], 0 pretrain_epochs, 10 epochs, validation size 0.1: accuracy=0.186744560838
100 utterances, 7 context, DBN[1920, 512, 512, 512, 48], 0 pretrain_epochs, 10 epochs, validation size 0.1: accuracy=0.249160369437
100 utterances, 3 context, DBN[896, 512, 512, 512, 48], 0 pretrain_epochs, 10 epochs, LR: 0.01, validation size 0.1: accuracy=0.247569803516 (CV acc: ~0.27)
100 utt., 7 cont., DBN[1920, 512, 512, 512, 48], 0 pre- epochs, 2 epochs, LR: 0.01, valid. size 0.1: accuracy=0.138335778663
100 utt., 7 cont., DBN[1920, 512, 512, 512, 48], 0 pre- epochs, 3 epochs, LR: 0.01, valid. size 0.1: accuracy=0.169985328023
100 utt., 7 cont., DBN[1920, 512, 512, 512, 48], 0 pre- epochs, 10 epochs, LR: 0.01, valid. size 0.1: accuracy=0.220572640509 (CV acc: ~0.38)

100 utt., 7 cont., DBN[1920, 512, 512, 512, 48], 0 pre- epochs, 10 epochs, LR: 0.01, valid. size 0.1: accuracy=0.247327604276

--- 13 MFCC + 13 delta features

100 utt., 7 cont., DBN[390, 512, 512, 512, 48], 0 pre- epochs, 10 epochs, LR: 0.01, valid. size 0.1: accuracy=0.267985096016
100 utt., 7 cont., DBN[390, 512, 512, 512, 48], 0 pre- epochs, 15 epochs, LR: 0.01, valid. size 0.1: accuracy=0.172231496939
100 utt., 7 cont., DBN[390, 512, 512, 512, 48], 0 pre- epochs, 15 epochs, LR: 0.05, valid. size 0.1: accuracy=0.189452565205

--- 13 MFCC + 13 delta + 13 delta-delta features
100 utt., 7 cont., DBN[585, 512, 512, 512, 48], 0 pre- epochs, 15 epochs, LR: 0.01, valid. size 0.1: accuracy=0.242125984252
100 utt., 7 cont., DBN[585, 512, 512, 512, 48], 0 pre- epochs, 15 epochs, LR: 0.01, valid. size 0.1: accuracy=0.173866090713
100 utt., 7 cont., DBN[585, 512, 512, 512, 48], 0 pre- epochs, 15 epochs, LR: 0.001, valid. size 0.1: accuracy=0.122840172786
100 utt., 7 cont., DBN[585, 512, 512, 512, 48], 0 pre- epochs, 15 epochs, LR: 0.01, valid. size 0.1: accuracy=0.12758289284
100 utt., 7 cont., DBN[585, 512, 512, 512, 48], 0 pre- epochs, 15 epochs, LR: 0.01, valid. size 0.1: accuracy=0.173866090713

 Further: l2_costs=0.001; excluded files with only once met phonemes

300 utt., 7 cont., DBN[585, 512, 512, 512, 56], 0 pretr. epochs, 15 epochs, LR: 0.01, valid. size 0.1: accuracy=0
300 utt., 7 cont., DBN[195, 512, 512, 512, 56], 0 pretr. epochs, 15 epochs, LR: 0.01, valid. size 0.1: accuracy=0
300 utt., 7 cont., DBN[585, 512, 512, 512, 56], 0 pretr. epochs, 7 epochs, LR: 0.01, valid. size 0.1: accuracy=0.200663099992

--- normalized spec features

300 utt., 7 cont., DBN[1920, 512, 512, 512, 56], 0 pretr. epochs, 15 epochs, LR: 0.1, valid. size 0.1: accuracy=0.383948
300 utt., 7 cont., DBN[1920, 512, 512, 512, 56], 0 pretr. epochs, 15 epochs, LR: 0.01, valid. size 0.1: accuracy=0.412216
100 utt., 7 cont., DBN[1920, 512, 512, 512, 43], 0 pretr. epochs, 10 epochs, LR: 0.01, valid. size 0.1: accuracy=0.352788

MFCC normalized per vector:
300 utt., 7 cont., DBN[585, 512, 512, 512, 56], 0 pretr. epochs, 10 epochs, LR: 0.01, valid. size 0.1: accuracy=0.193969
MFCC normalized per utterance:
300 utt., 7 cont., DBN[585, 512, 512, 512, 56], 0 pretr. epochs, 10 epochs, LR: 0.01, valid. size 0.1: accuracy=0.178799 // overfitted
MFCC normalized per training set:
??

spec normalized per utterance:
300 utt., 7 cont., DBN[1920, 512, 512, 512, 56], 0 pretr. epochs, 10 epochs, LR: 0.01, valid. size 0.1: accuracy=0.391111
spec - mean(spec) normalized per utterance:
300 utt., 7 cont., DBN[1920, 512, 512, 512, 56], 0 pretr. epochs, 10 epochs, LR: 0.01, valid. size 0.1: accuracy=0.399946

---

100 utt., 7 cont., DBN[1920, 512, 512, 512, 43], 0 pretr. epochs, 10 epochs, LR: 0.01, valid. size 0.1: accuracy=0.385381
100 utt., 7 cont., DBN[1920, 512, 512, 512, 43], 0 pretr. epochs, 10 epochs, LR: 0.01, valid. size 0.1: accuracy=0.369185


100 utt., 7 cont., DBN[1920, 1024, 43], 0 pretr. epochs, 10 epochs, LR: 0.01, valid. size 0.1: accuracy=0.340175
100 utt., 7 cont., DBN[1920, 1024, 43], 0 pretr. epochs, 10 epochs, LR: 0.1, valid. size 0.1: accuracy=0.407223
100 utt., 7 cont., DBN[1920, 1024, 43], 0 pretr. epochs, 10 epochs, LR: 0.1, L2: 0.01, valid. size 0.1: accuracy=0.297740

--- big layers:
100 utt., 7 cont., DBN[1920, 2048, 2048, 2048, 43], 0 pretr. epochs, 4 epochs, LR: 0.01, L2: 0.01, valid. size 0.1: accuracy=0.387760

--- ([spec]-mean)/(max-min)
100 utt., 7 cont., DBN[1920, 512, 512, 512, 43], 0 pretr. epochs, 10 epochs, LR: 0.01, L2: 0.01, valid. size 0.1: accuracy=0.286880

--- using dropout=0.3
100 utt., 7 cont., DBN[1920, 512, 512, 512, 43], 0 pretr. epochs, 10 epochs, LR: 0.01, valid. size 0.1: accuracy=0.231319

--- MFCC + d + dd
100 utt., 7 cont., DBN[585, 512, 512, 512, 43], 0 pretr. epochs, 10 epochs, LR: 0.01, valid. size 0.1: accuracy=0.181319

--- MFCC + d + dd with normalizing
100 utt., 7 cont., DBN[585, 512, 512, 512, 43], 0 pretr. epochs, 15 epochs, LR: 0.1, valid. size 0.1: accuracy=0.156187 (overfitted)
100 utt., 7 cont., DBN[585, 512, 512, 512, 43], 0 pretr. epochs, 15 epochs, LR: 0.01, valid. size 0.1: accuracy=0.166871

--- MFCC + d + dd with zero_mean normalizing
100 utt., 7 cont., DBN[585, 512, 512, 512, 43], 0 pretr. epochs, 15 epochs, LR: 0.01, valid. size 0.1: accuracy=0.161137
100 utt., 7 cont., DBN[585, 512, 512, 512, 43], 0 pretr. epochs, 15 epochs, LR: 0.03, valid. size 0.1: accuracy=0.133093
100 utt., 7 cont., DBN[585, 512, 512, 512, 43], 0 pretr. epochs, 15 epochs, LR: 0.0001, valid. size 0.1: accuracy=0.037510
100 utt., 7 cont., DBN[585, 512, 512, 512, 43], 0 pretr. epochs, 15 epochs, LR: 0.0001, valid. size 0.1: accuracy=0.059871
100 utt., 7 cont., DBN[585, 512, 512, 512, 43], 0 pretr. epochs, 15 epochs, LR: 0.001, valid. size 0.1: accuracy=0.113310
100 utt., 7 cont., DBN[585, 512, 512, 512, 43], 0 pretr. epochs, 15 epochs, LR: 0.001, L2: 0.0001, valid. size 0.1: accuracy=0.106136 (stuck at train err 0.85)
100 utt., 7 cont., DBN[585, 512, 512, 512, 43], 0 pretr. epochs, 15 epochs, LR: 0.001, L2: 0.01, valid. size 0.1: accuracy=0.104899 (stuck at train err 0.85)
100 utt., 7 cont., DBN[585, 512, 512, 512, 43], 0 pretr. epochs, 15 epochs, LR: 0.001, L2: 0.2, valid. size 0.1: accuracy=0.102919 (stuck at train err 0.89)
100 utt., 7 cont., DBN[585, 512, 512, 512, 43], 0 pretr. epochs, 15 epochs, LR: 0.5, LR: 0.0, valid. size 0.1: accuracy=0.128402, train err=0.048730
100 utt., 7 cont., DBN[585, 512, 512, 512, 43], 0 pretr. epochs, 6 epochs, LR: 0.5, LR: 0.0001, valid. size 0.1: accuracy=0.116279, train err=0.493652

300 utt., 7 cont., DBN[585, 1024, 1024, 1024, 60], 0 pretr. epochs, 15 epochs, LR: 0.001, LR: 0.0001, valid. size 0.4: accuracy=0.185, train err=0.803776
300 utt., 7 cont., DBN[585, 512, 512, 512, 60], 0 pretr. epochs, 15 epochs, LR: 0.01, LR: 0.0001, valid. size 0.4: accuracy=0.21, train err=0.719833
300 utt., 7 cont., DBN[585, 1024, 1024, 1024, 60], 0 pretr. epochs, 15 epochs, LR: 0.03, LR: 0.0001, valid. size 0.4: accuracy=0.18, train err=0.216178

--- spec features
100 utt., 7 cont., DBN[1920, 1024, 43], 0 pretr. epochs, 15 epochs, LR: 0.01, L2: 0.0001, valid. size 0.4: accuracy=0.30, train err=0.579621
100 utt., 7 cont., DBN[1920, 1024, 42], 0 pretr. epochs, 15 epochs, LR: 0.01, L2: 0.0001, valid. size 0.4: accuracy=0.28, train err=0.560268
100 utt., 7 cont., DBN[1920, 1024, 42], 0 pretr. epochs, 15 epochs, LR: 0.03, L2: 0.0001, valid. size 0.4: accuracy=0.31, train err=0.459129
100 utt., 7 cont., DBN[1920, 1024, 42], 0 pretr. epochs, 15 epochs, LR: 0.1, L2: 0.0001, valid. size 0.4: accuracy=0.28, train err=0.283402
100 utt., 7 cont., DBN[1920, 1024, 42], 0 pretr. epochs, 15 epochs, LR: 0.03, L2: 0.0001, valid. size 0.4: accuracy=0.28, train err=0.382972

--- setup as in papers
// 10-ms winstep, 25-ms winlen, 3x13 MFCC, context of 11 frames (= 5 cont.), normalization: zero mean and unit variance

100 utt., 7 cont., DBN[585, 1024, 42], 0 pretr. epochs, 15 epochs, LR: 0.03, L2: 0.0001, valid. size 0.4: accuracy=no, train err=0.717187
100 utt., 7 cont., DBN[585, 1024, 42], 0 pretr. epochs, 15 epochs, LR: 0.1, L2: 0.0001, valid. size 0.4: accuracy=no, train err=0.480655
100 utt., 7 cont., DBN[585, 1024, 42], 0 pretr. epochs, 15 epochs, LR: 0.1, L2: 0.0001, valid. size 0.4: accuracy=no, train err=0.153716
100 utt., 7 cont., DBN[585, 1024, 42], 0 pretr. epochs, 15 epochs, LR: 0.1, L2: 0.0001, valid. size 0.4: accuracy=no, train err=0.215234
100 utt., 7 cont., DBN[585, 1024, 42], 0 pretr. epochs, 15 epochs, LR: 0.01, L2: 0.0001, valid. size 0.4: accuracy=no, train err=0.716518
100 utt., 5 cont., DBN[429, 1024, 42], 0 pretr. epochs, 15 epochs, LR: 0.03, L2: 0.0001, valid. size 0.4: accuracy=no, train err=0.588315
300 utt., 5 cont., DBN[429, 2048, 55], 0 pretr. epochs, 15 epochs, LR: 0.03, L2: 0.0001, valid. size 0.2: accuracy=0.28, train err=0.613894
300 utt., 5 cont., DBN[429, 2048, 55], 0 pretr. epochs, 15 epochs, LR: 0.1, L2: 0.0001, valid. size 0.2: accuracy=no, train err=0.657227
300 utt., 5 cont., DBN[429, 2048, 55], 0 pretr. epochs, 6 epochs, LR: 0.1, L2: 0.0001, valid. size 0.2: accuracy=no, train err=0.714994

1000 utt., 5 cont., DBN[429, 2048, 157], 0 pretr. epochs, 15 epochs, LR: 0.1, L2: 0.0001, valid. size 0.3: accuracy=0.20, train err=0.685170


--- parameters varying tests
100 utt., 5 cont., DBN[429, 2048, 42], [3, 3] pretr. epochs, 15 epochs, LR: 0.1, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.84164663461538458, 0.78695913461538458, 0.73647836538461542, 0.69020432692307687, 0.65685096153846156, 0.64212740384615385, 0.63100961538461542, 0.63311298076923073, 0.61508413461538458, 0.59344951923076927, 0.5859375, 0.58503605769230771, 0.58683894230769229, 0.57481971153846156, 0.56971153846153844]
  valid.accur. [0.11635865845311433, 0.16700889801505814, 0.17932922655715267, 0.1649555099247091, 0.17727583846680361, 0.17932922655715267, 0.16700889801505814, 0.15879534565366182, 0.1649555099247091, 0.1765913757700205, 0.16837782340862428, 0.1731690622861054, 0.17180013689253937, 0.16700889801505814, 0.16769336071184116]
100 utt., 5 cont., DBN[429, 2048, 42], [15, 15] pretr. epochs, 15 epochs, LR: 0.1, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.89483173076923073, 0.88882211538461542, 0.88311298076923073, 0.86899038461538458, 0.84525240384615385, 0.85306490384615385, 0.84344951923076927, 0.84945913461538458, 0.82451923076923073, 0.79807692307692313, 0.79507211538461542, 0.78545673076923073, 0.79086538461538458, 0.76682692307692313, 0.76081730769230771]
  valid.accur. [0.10472279260780293, 0.10609171800136896, 0.107460643394935, 0.11635865845311433, 0.11704312114989734, 0.12114989733059545, 0.11362080766598215, 0.11567419575633131, 0.13689253935660506, 0.134839151266256, 0.14373716632443534, 0.14715947980835042, 0.17043121149897333, 0.15126625598904864, 0.16290212183436004]
100 utt., 5 cont., DBN[429, 1024, 1024, 1024, 42], [15, 15, 15, 15] pretr. epochs, 15 epochs, LR: 0.1, L2: 0.0001, LR-pre: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.88822115384615385, 0.88371394230769229, 0.88581730769230771, 0.88641826923076927, 0.88491586538461542, 0.89573317307692313, 0.87740384615384615, 0.89182692307692313, 0.89423076923076927, 0.88551682692307687, 0.88311298076923073, 0.88581730769230771, 0.88431490384615385, 0.88401442307692313, 0.88371394230769229]
  valid.accur. [0.0691307323750856, 0.10609171800136896, 0.10609171800136896, 0.10609171800136896, 0.10609171800136896, 0.10609171800136896, 0.10609171800136896, 0.10609171800136896, 0.10609171800136896, 0.10609171800136896, 0.10609171800136896, 0.10609171800136896, 0.10609171800136896, 0.10609171800136896, 0.10609171800136896]
100 utt., 5 cont., DBN[429, 1024, 1024, 1024, 42], [8, 8, 8, 8] pretr. epochs, 15 epochs, LR: 0.1, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.88822115384615385, 0.88972355769230771, 0.88100961538461542, 0.88191105769230771, 0.87560096153846156, 0.88521634615384615, 0.87860576923076927, 0.88762019230769229, 0.8828125, 0.88581730769230771, 0.87740384615384615, 0.89032451923076927, 0.89092548076923073, 0.88251201923076927, 0.89152644230769229]
  valid.accur. [0.10609171800136896, 0.10609171800136896, 0.10609171800136896, 0.10609171800136896, 0.10609171800136896, 0.10609171800136896, 0.10609171800136896, 0.10609171800136896, 0.10609171800136896, 0.10609171800136896, 0.10609171800136896, 0.10609171800136896, 0.10609171800136896, 0.10609171800136896, 0.10609171800136896]

1000 utt., 0 cont., DBN[39, 1024, 1024, 1024, 157], 0 pretr. epochs, 15 epochs, LR: 0.1, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.8562805623471883, 0.81234718826405872, 0.77762072127139359, 0.74621790953545231, 0.71217909535452317, 0.6749694376528117, 0.63808450488997559, 0.59594666870415647, 0.55793474938875309, 0.52238691931540338, 0.48662897310513448, 0.45455761002444989, 0.42176039119804398, 0.39182839242053791, 0.36558297677261614]
  valid.accur. [0.1456310679611651, 0.14550606275261468, 0.14804783532647192, 0.1493395558148256, 0.15292303845993582, 0.13917246551939666, 0.15213133880578356, 0.1547981165881912, 0.14829784574357263, 0.15433976415683992, 0.14867286136922375, 0.15542314263094292, 0.15117296554023085, 0.16675694820617526, 0.1614650610442102]
1000 utt., 1 cont., DBN[117, 1024, 1024, 1024, 157], 0 pretr. epochs, 15 epochs, LR: 0.1, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.84626256281407031, 0.79049544597989951, 0.7421875, 0.67955009422110557, 0.61787452889447236, 0.54467650753768848, 0.47927135678391958, 0.40768294597989951, 0.35544912060301509, 0.29838646356783921, 0.25076554648241206, 0.21451005025125627, 0.17580087939698494, 0.14327496859296482, 0.12058338567839195]
  valid.accur. [0.15321167571263727, 0.15316893884354033, 0.16235736569938886, 0.15227146459250396, 0.15799820505149798, 0.1644942091542374, 0.16688747382366764, 0.16620368391811613, 0.1715457925552374, 0.17282789862814651, 0.17688790119235864, 0.19043548869609817, 0.18184537800760714, 0.18846959271763752, 0.18975169879054665]
1000 utt., 2 cont., DBN[195, 1024, 1024, 1024, 157], 0 pretr. epochs, 15 epochs, LR: 0.1, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.84201388888888884, 0.77450742894056845, 0.71770025839793283, 0.64238129844961245, 0.56417554909560719, 0.47769299095607237, 0.39979005167958659, 0.33159722222222221, 0.26927890826873385, 0.21788194444444445, 0.17157218992248063, 0.13842458010335917, 0.11141392118863049, 0.089147286821705432, 0.071140180878552978]
  valid.accur. [0.1621123733497083, 0.1638668362647484, 0.1650949603052766, 0.17145488837229705, 0.1738234133076012, 0.17518312206675735, 0.17404272117198127, 0.1822009737269178, 0.19128031931225054, 0.19154348874950655, 0.19654370805737098, 0.19413132154919077, 0.1993069871485591, 0.1998771875959472, 0.19965787973156712]
1000 utt., 3 cont., DBN[273, 1024, 1024, 1024, 157], 0 pretr. epochs, 15 epochs, LR: 0.1, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.8379321808510638, 0.76346409574468088, 0.68953623670212771, 0.6045545212765957, 0.51437832446808507, 0.42037898936170215, 0.33963597074468083, 0.265625, 0.20807014627659576, 0.16188081781914893, 0.12506233377659576, 0.095266788563829793, 0.077584773936170207, 0.057056183510638299, 0.046521775265957445]
  valid.accur. [0.1730708590477048, 0.1680706338123339, 0.1746024595702509, 0.17126897608000358, 0.1778908959863057, 0.17928735528627415, 0.18523356907968824, 0.18757601693769987, 0.19663047885039864, 0.20577503491148252, 0.20212622190188745, 0.20771205910176138, 0.2062255056534078, 0.2089733771791522, 0.21190143700166675]
1000 utt., 4 cont., DBN[351, 1024, 1024, 1024, 157], 0 pretr. epochs, 15 epochs, LR: 0.1, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.82966398768809846, 0.74805489056087549, 0.66501367989056093, 0.57019493844049252, 0.46357729138166892, 0.37356788645690836, 0.28862431600547195, 0.21676214090287277, 0.16383806429548564, 0.1237388850889193, 0.10191518467852258, 0.075560020519835847, 0.059293775649794801, 0.04621238030095759, 0.036294459644322846]
  valid.accur. [0.16986897541552848, 0.18320292606139177, 0.19334228436501688, 0.1882031575535904, 0.18561044492800594, 0.2046391036622066, 0.20750960692624654, 0.20070373628408722, 0.2076022038057318, 0.21200055558127695, 0.221491735728506, 0.21338950877355434, 0.22019537941571365, 0.22408444835409047, 0.2208898560118524]
1000 utt., 5 cont., DBN[429, 1024, 1024, 1024, 157], 0 pretr. epochs, 15 epochs, LR: 0.1, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.83083568406205921, 0.7387826163610719, 0.64974876586741892, 0.54689703808180534, 0.430513928067701, 0.33451604372355431, 0.24938293370944992, 0.18441466854724964, 0.13668018335684062, 0.10785437235543019, 0.077816466854724958, 0.060119887165021153, 0.047381875881523275, 0.040043194640338502, 0.031712799717912556]
  valid.accur. [0.1777227487023192, 0.18800895280727659, 0.19000904804990715, 0.1963426829849041, 0.18800895280727659, 0.20353350159531403, 0.20324777370350966, 0.2136768417543693, 0.21948664222105818, 0.2175341682937283, 0.22253440640030475, 0.2235344540216201, 0.22472498690413834, 0.22920139054240674, 0.22982046764131625]
1000 utt., 6 cont., DBN[507, 1024, 1024, 1024, 157], 0 pretr. epochs, 15 epochs, LR: 0.1, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.83108169577874813, 0.72857532751091703, 0.64292212518195047, 0.52679221251819508, 0.40634097525473073, 0.30415302037845704, 0.22263919213973798, 0.16530203784570596, 0.125, 0.09163482532751091, 0.070596797671033482, 0.052356259097525476, 0.044577874818049493, 0.034547852983988353, 0.027451783114992721]
  valid.accur. [0.17799892151576058, 0.18054806608167062, 0.19780381391244672, 0.1971665277709692, 0.20074513456541987, 0.209323986469925, 0.2079023481543213, 0.21672631011324084, 0.2212363351144664, 0.2267268003333497, 0.2221187313103583, 0.2297171429972057, 0.22756017451835875, 0.23069758321486344, 0.23241335359576454]
1000 utt., 7 cont., DBN[585, 1024, 1024, 1024, 157], 0 pretr. epochs, 15 epochs, LR: 0.1, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.82669172932330826, 0.72272086466165408, 0.61966635338345866, 0.49370300751879698, 0.37008928571428573, 0.27408364661654133, 0.19579417293233084, 0.14558270676691729, 0.10765977443609022, 0.080263157894736842, 0.062875939849624057, 0.047415413533834584, 0.039732142857142855, 0.030451127819548871, 0.02368421052631579]
  valid.accur. [0.18910045961917266, 0.19304005252790546, 0.19364614374463351, 0.1989494418910046, 0.21152583463811303, 0.21228344865902316, 0.22501136421031365, 0.22384968937825145, 0.22384968937825145, 0.22647608465073998, 0.23516339209050963, 0.23329461083893122, 0.23359765644729535, 0.23329461083893122, 0.23915349260063634]
1000 utt., 8 cont., DBN[663, 1024, 1024, 1024, 157], 0 pretr. epochs, 15 epochs, LR: 0.1, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.82348367029548986, 0.71376846811819594, 0.6011615474339036, 0.4827225894245723, 0.35796559097978226, 0.25597783825816484, 0.18310167185069984, 0.1338452566096423, 0.097322122861586313, 0.074577177293934677, 0.054699650077760495, 0.044809486780715398, 0.035356726283048215, 0.029281687402799378, 0.023255248833592534]
  valid.accur. [0.18443668941090685, 0.18980155216417527, 0.20094796603989795, 0.20240637533204853, 0.20844835668524397, 0.21792801708422316, 0.23600187509766135, 0.23001197979061405, 0.2323558518672848, 0.22969946351372472, 0.23792905880514614, 0.2419396843585604, 0.2387103494973697, 0.23803323089744255, 0.24188759831241213]
1000 utt., 9 cont., DBN[741, 1024, 1024, 1024, 157], 0 pretr. epochs, 15 epochs, LR: 0.1, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.82596115136876003, 0.7156300322061192, 0.60404086151368763, 0.46708937198067635, 0.33607588566827695, 0.23955817230273752, 0.17227757648953301, 0.12273550724637682, 0.09420289855072464, 0.072589573268921098, 0.056587157809983898, 0.043553743961352656, 0.03477254428341385, 0.028935185185185185, 0.022041062801932368]
  valid.accur. [0.17456989247311827, 0.19446236559139785, 0.18838709677419352, 0.2076881720430107, 0.2084408602150538, 0.22102150537634413, 0.22333333333333338, 0.22989247311827954, 0.2323655913978495, 0.23037634408602148, 0.23446236559139788, 0.23596774193548387, 0.24139784946236564, 0.23897849462365595, 0.239247311827957]
1000 utt., 10 cont., DBN[819, 1024, 1024, 1024, 157], 0 pretr. epochs, 15 epochs, LR: 0.1, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.82809891485809684, 0.70695951585976624, 0.59176752921535891, 0.45980279632721199, 0.32898580968280466, 0.2314012938230384, 0.16496243739565944, 0.12129590984974958, 0.085246243739565949, 0.066047579298831385, 0.051126878130217025, 0.0419449081803005, 0.03430196160267112, 0.026424248747913187, 0.023424457429048414]
  valid.accur. [0.17018440346589647, 0.1822372806043101, 0.19162408353699178, 0.19073539213508106, 0.21067540546545216, 0.22106198622528328, 0.2235058875805377, 0.23339257942679403, 0.2322261719617863, 0.24039102421684067, 0.23272606087536107, 0.23716951788491447, 0.2380582092868252, 0.2345034436791824, 0.2362252832703844]

1000 utt., 5 cont., DBN[429, 1024, 1024, 1024, 157], 0 pretr. epochs, 15 epochs, LR: 0.1, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.8330835684062059, 0.73481576163610718, 0.64999118476727791, 0.54200458392101547, 0.43080042313117067, 0.32946932299012693, 0.2433885754583921, 0.18344499294781383, 0.13850934414668548, 0.10186001410437236, 0.078102961918194644, 0.059392630465444289, 0.047932827926657262, 0.036473025387870242, 0.03063293370944993]
  valid.accur. [0.185818372303443, 0.18738987570836707, 0.18977094147340345, 0.19791418638982805, 0.19619981903900185, 0.20181913424448783, 0.206343159198057, 0.21401019096147433, 0.2155816943663984, 0.2215819800942902, 0.22143911614838807, 0.22853469212819655, 0.22772512976808423, 0.2299157102719177, 0.22810610029049005]
1000 utt., 5 cont., DBN[429, 1024, 1024, 1024, 157], 0 pretr. epochs, 15 epochs, LR: 0.03, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.86003614245416082, 0.79680888575458397, 0.76441290550070518, 0.73455130465444285, 0.70321315232722148, 0.67094940056417485, 0.63672425952045131, 0.6049673836389281, 0.5700149858956276, 0.5408145275035261, 0.50676569111424541, 0.47062323695345559, 0.44951075458392104, 0.41773184062059238, 0.38868564880112833]
  valid.accur. [0.16215057859898085, 0.1740559074241631, 0.1971998666603172, 0.19281870565265014, 0.19143768750892898, 0.19881899138054193, 0.19581884851659603, 0.19743797323682077, 0.19515215010238585, 0.20410495737892276, 0.19086623172532025, 0.1950569074717844, 0.19734273060621932, 0.19896185532644417, 0.20191437687508929]
1000 utt., 5 cont., DBN[429, 1024, 1024, 1024, 157], 0 pretr. epochs, 15 epochs, LR: 0.01, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.90457510578279265, 0.8417445345557123, 0.81626851198871653, 0.80425775740479544, 0.78682563469675604, 0.77827485895627646, 0.76979019746121302, 0.75762517630465442, 0.75348201692524686, 0.7453940409026798, 0.7358295133991537, 0.73331717207334268, 0.72758727080394925, 0.72038081805359666, 0.72044693229901269]
  valid.accur. [0.12595837897042717, 0.15515024524977383, 0.17372255821705795, 0.178103719224725, 0.1841040049526168, 0.19034239725701219, 0.18653269203295397, 0.19229487118434208, 0.19410448116576984, 0.19491404352588215, 0.1911519596171246, 0.19553312062479167, 0.19662841087670846, 0.19705700271441495, 0.19991428163245872]
1000 utt., 5 cont., DBN[429, 1024, 1024, 1024, 157], 0 pretr. epochs, 15 epochs, LR: 0.003, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.94109220733427368, 0.88881787729196049, 0.86246033145275036, 0.84718794076163606, 0.84176657263751764, 0.83698430888575459, 0.83240038787023973, 0.82801480959097318, 0.82142542313117062, 0.81781117771509171, 0.81761283497884341, 0.81025211565585331, 0.81205923836389282, 0.80820257404795481, 0.80681417489421725]
  valid.accur. [0.08462307728939478, 0.1119577122720129, 0.13348254678794225, 0.144054478784704, 0.14653078718034196, 0.15024524977379872, 0.15534073051097674, 0.15762655364541167, 0.16234106386018377, 0.16562693461593414, 0.16576979856183627, 0.17115100719081866, 0.1661507690842421, 0.16938901852469168, 0.17143673508262303]
1000 utt., 5 cont., DBN[429, 1024, 1024, 1024, 157], 0 pretr. epochs, 15 epochs, LR: 0.001, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.95266220028208748, 0.93946138928067702, 0.94067348377997184, 0.93013928067700991, 0.90494975317348381, 0.89225581805359666, 0.88674629760225665, 0.88218441466854725, 0.87815144569816639, 0.87832775035260935, 0.87112129760225665, 0.86737482369534558, 0.86554566290550072, 0.86292313117066288, 0.86155677009873055]
  valid.accur. [0.06900328587075577, 0.06900328587075577, 0.07186056478879943, 0.08495642649649982, 0.09671889137577983, 0.10581456259821898, 0.10695747416543644, 0.11100528596599835, 0.11124339254250204, 0.11595790275727413, 0.11714843563979238, 0.11767227010810044, 0.11976760798133246, 0.12110100480975283, 0.12362493452069145]

--- using optimal context of 8

100 utt., 8 cont., DBN[663, 1024, 1024, 1024, 1024, 42], 0 pretr. epochs, 15 epochs, LR: 0.1, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.82114361702127658, 0.65126329787234039, 0.5029920212765957, 0.39727393617021278, 0.28922872340425532, 0.1735372340425532, 0.13131648936170212, 0.074468085106382975, 0.055851063829787231, 0.032579787234042555, 0.013297872340425532, 0.010970744680851064, 0.0076462765957446806, 0.0053191489361702126, 0.003324468085106383]
  valid.accur. [0.17035217035217032, 0.17035217035217032, 0.14414414414414412, 0.13677313677313674, 0.16298116298116294, 0.1515151515151515, 0.14905814905814907, 0.15315315315315314, 0.15233415233415237, 0.14250614250614246, 0.14660114660114665, 0.13759213759213762, 0.13923013923013927, 0.14905814905814907, 0.14332514332514334]
300 utt., 8 cont., DBN[663, 1024, 1024, 1024, 1024, 55], 0 pretr. epochs, 15 epochs, LR: 0.03, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.84174923780487809, 0.74333079268292679, 0.69293064024390238, 0.6519626524390244, 0.61309070121951215, 0.56335746951219512, 0.52515243902439024, 0.48799542682926828, 0.43635670731707316, 0.38062118902439024, 0.34536966463414637, 0.30049542682926828, 0.25895579268292684, 0.2345655487804878, 0.20255335365853658]
  valid.accur. [0.20481628599801394, 0.26812313803376364, 0.2437934458788481, 0.2351042701092354, 0.24329692154915594, 0.25695134061569014, 0.22418073485600798, 0.22070506454816285, 0.23336643495531284, 0.22194637537239326, 0.21946375372393245, 0.23088381330685204, 0.22318768619662366, 0.2174776564051638, 0.23212512413108244]
300 utt., 8 cont., DBN[663, 1024, 1024, 1024, 1024, 55], 0 pretr. epochs, 15 epochs, LR: 0.01, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.88424161585365857, 0.81507240853658536, 0.7652439024390244, 0.74818978658536583, 0.72427591463414631, 0.70903201219512191, 0.69226371951219512, 0.69455030487804881, 0.67568597560975607, 0.67473323170731703, 0.66520579268292679, 0.65958460365853655, 0.64576981707317072, 0.64253048780487809, 0.63557545731707321]
  valid.accur. [0.11295928500496522, 0.21325719960278056, 0.2177259185700099, 0.23212512413108244, 0.256454816285998, 0.2589374379344588, 0.25695134061569014, 0.25297914597815296, 0.25819265143992054, 0.2646474677259185, 0.2624131082423039, 0.25173783515392256, 0.2552135054617676, 0.26564051638530284, 0.2586891757696127]

--- minibatch size=10
300 utt., 8 cont., DBN[663, 1024, 1024, 1024, 1024, 55], 0 pretr. epochs, 15 epochs, LR: 0.001, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.88514285714285712, 0.83933333333333338, 0.80466666666666664, 0.78590476190476188, 0.76409523809523805, 0.74619047619047618, 0.73666666666666669, 0.72638095238095235, 0.71752380952380956, 0.710952380952381, 0.69980952380952377, 0.70799999999999996, 0.68666666666666665, 0.6907619047619048, 0.69133333333333336]
  valid.accur. [0.09705882352941175, 0.15955882352941175, 0.20294117647058818, 0.21666666666666667, 0.22083333333333333, 0.23897058823529416, 0.2517156862745098, 0.24411764705882355, 0.23578431372549025, 0.25049019607843137, 0.24926470588235294, 0.25392156862745097, 0.2551470588235294, 0.2602941176470588, 0.25416666666666665]
300 utt., 8 cont., DBN[663, 1024, 55], 0 pretr. epochs, 15 epochs, LR: 0.001, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.89838095238095239, 0.87866666666666671, 0.87047619047619051, 0.8726666666666667, 0.86095238095238091, 0.85819047619047617, 0.84866666666666668, 0.8449523809523809, 0.83799999999999997, 0.83904761904761904, 0.83476190476190482, 0.83542857142857141, 0.832952380952381, 0.83447619047619048, 0.83333333333333337]
  valid.accur. [0.06470588235294117, 0.08872549019607845, 0.09093137254901962, 0.1029411764705882, 0.10245098039215683, 0.11053921568627456, 0.1284313725490196, 0.13774509803921564, 0.13308823529411762, 0.14142156862745103, 0.14411764705882357, 0.14313725490196083, 0.14411764705882357, 0.14828431372549022, 0.1485294117647059]

--- minibatch size=20
300 utt., 8 cont., DBN[663, 1024, 55], 0 pretr. epochs, 15 epochs, LR: 0.001, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.91428571428571426, 0.88171428571428567, 0.88066666666666671, 0.87866666666666671, 0.87638095238095237, 0.87238095238095237, 0.86828571428571433, 0.86247619047619051, 0.86190476190476195, 0.85990476190476195, 0.85952380952380958, 0.85799999999999998, 0.85866666666666669, 0.85742857142857143, 0.85590476190476195]
  valid.accur. [0.07667809897109257, 0.07888290053895153, 0.08427241548260656, 0.0776580107790299, 0.08794708476237134, 0.09725624693777557, 0.09603135717785394, 0.09774620284174429, 0.09456148946594811, 0.09676629103380696, 0.10191082802547768, 0.10754532092111713, 0.11024007839294458, 0.10313571778539932, 0.10779029887310143]
300 utt., 8 cont., DBN[663, 1024, 55], 0 pretr. epochs, 15 epochs, LR: 0.01, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.86704761904761907, 0.83371428571428574, 0.80847619047619046, 0.79323809523809519, 0.78542857142857148, 0.77476190476190476, 0.76409523809523805, 0.75990476190476186, 0.75676190476190475, 0.74152380952380947, 0.73980952380952381, 0.74399999999999999, 0.73885714285714288, 0.73209523809523813, 0.73066666666666669]
  valid.accur. [0.13284313725490193, 0.18455882352941178, 0.1958333333333333, 0.20808823529411768, 0.22009803921568627, 0.2161764705882353, 0.23455882352941182, 0.23161764705882348, 0.2279411764705882, 0.23039215686274506, 0.23333333333333328, 0.23578431372549025, 0.23921568627450984, 0.23921568627450984, 0.24803921568627452]
300 utt., 8 cont., DBN[663, 1024, 55], 0 pretr. epochs, 15 epochs, LR: 0.01, momemtum=0.5, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.88180952380952382, 0.86428571428571432, 0.84780952380952379, 0.83161904761904759, 0.82923809523809522, 0.82599999999999996, 0.80666666666666664, 0.81114285714285717, 0.80676190476190479, 0.79752380952380952, 0.79190476190476189, 0.78942857142857148, 0.78609523809523807, 0.79438095238095241, 0.787047619047619]
  valid.accur. [0.09407153356197939, 0.1190592846643802, 0.1347378735913768, 0.14551690347868695, 0.14551690347868695, 0.15776580107790295, 0.17270945614894662, 0.17785399314061734, 0.1800587947084762, 0.18789808917197448, 0.18593826555609994, 0.19353258206761392, 0.18495835374816272, 0.19867711905928465, 0.19108280254777066]
300 utt., 8 cont., DBN[663, 1024, 55], 0 pretr. epochs, 15 epochs, LR: 0.01, momemtum=0.9, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.85314285714285709, 0.79628571428571426, 0.7648571428571429, 0.76104761904761908, 0.74771428571428566, 0.73504761904761906, 0.72361904761904761, 0.72199999999999998, 0.71971428571428575, 0.70428571428571429, 0.70285714285714285, 0.70438095238095233, 0.70657142857142852, 0.69771428571428573, 0.69857142857142862]
  valid.accur. [0.18936795688388042, 0.20700636942675155, 0.21460068593826553, 0.21533561979421856, 0.2337089661930426, 0.24718275355218033, 0.24228319451249392, 0.25183733463988245, 0.2579617834394905, 0.2628613424791769, 0.25624693777560015, 0.2572268495835375, 0.2616364527192553, 0.2545320921117099, 0.2616364527192553]
300 utt., 8 cont., DBN[663, 1024, 55], 0 pretr. epochs, 15 epochs, LR: 0.003, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.87952380952380949, 0.85638095238095235, 0.83209523809523811, 0.82199999999999995, 0.81695238095238099, 0.80600000000000005, 0.79561904761904767, 0.79076190476190478, 0.78857142857142859, 0.77228571428571424, 0.77142857142857146, 0.77247619047619043, 0.77238095238095239, 0.76723809523809527, 0.76704761904761909]
  valid.accur. [0.07916666666666672, 0.138235294117647, 0.15514705882352942, 0.16642156862745094, 0.17941176470588238, 0.19117647058823528, 0.2044117647058824, 0.21421568627450982, 0.2129901960784314, 0.2110294117647059, 0.216421568627451, 0.21691176470588236, 0.21495098039215688, 0.2264705882352941, 0.2230392156862745]
300 utt., 8 cont., DBN[663, 1024, 55], 0 pretr. epochs, 15 epochs, LR: 0.001, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.89942857142857147, 0.8793333333333333, 0.87104761904761907, 0.87295238095238092, 0.86085714285714288, 0.85828571428571432, 0.84885714285714287, 0.84476190476190471, 0.83799999999999997, 0.83866666666666667, 0.83457142857142852, 0.83571428571428574, 0.83276190476190481, 0.834952380952381, 0.83371428571428574]
  valid.accur. [0.06446078431372548, 0.08872549019607845, 0.09093137254901962, 0.10269607843137252, 0.10147058823529409, 0.11029411764705888, 0.12745098039215685, 0.1384803921568627, 0.13259803921568625, 0.14093137254901966, 0.14460784313725494, 0.14485294117647063, 0.14313725490196083, 0.14754901960784317, 0.14828431372549022]
300 utt., 8 cont., DBN[663, 1024, 55], 0 pretr. epochs, 15 epochs, LR: 0.001, L2: 0.0, valid. size 0.3: accuracy=no,
  train errors [0.89609523809523806, 0.87419047619047618, 0.8671428571428571, 0.85999999999999999, 0.85809523809523813, 0.85104761904761905, 0.8376190476190476, 0.8376190476190476, 0.83790476190476193, 0.82790476190476192, 0.82876190476190481, 0.82876190476190481, 0.82447619047619047, 0.83019047619047615, 0.82457142857142862]
  valid.accur. [0.08157765801077899, 0.09211170994610485, 0.09603135717785394, 0.11268985791278785, 0.11415972562469379, 0.1190592846643802, 0.14086232239098484, 0.13277804997550224, 0.13865752082312588, 0.14012738853503182, 0.143312101910828, 0.14968152866242035, 0.14551690347868695, 0.14086232239098484, 0.14625183733463987]

--- learn_rate_decays varying
300 utt., 8 cont., DBN[663, 1024, 55], 0 pretr. epochs, 15 epochs, LR: 0.01, L2: 0.0001, LR_decay=0.8, valid. size 0.3: accuracy=no,
  train errors [0.85314285714285709, 0.79742857142857138, 0.76838095238095239, 0.7655238095238095, 0.75847619047619053, 0.75390476190476186, 0.73685714285714288, 0.74095238095238092, 0.74247619047619051, 0.72761904761904761, 0.72352380952380957, 0.72752380952380957, 0.72619047619047616, 0.72457142857142853, 0.72790476190476194]
  valid.accur. [0.18936795688388042, 0.20382165605095537, 0.20823125918667318, 0.21092601665850075, 0.22390984811366976, 0.23248407643312097, 0.23199412052915236, 0.2339539441450269, 0.23468887800097993, 0.24252817246447822, 0.23958843704066635, 0.25183733463988245, 0.2413032827045566, 0.25232729054385106, 0.24914257716805488]
300 utt., 8 cont., DBN[663, 1024, 55], 0 pretr. epochs, 15 epochs, LR: 0.01, momemtum=0.9, LR_decay=0.9, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.85314285714285709, 0.79628571428571426, 0.7648571428571429, 0.76104761904761908, 0.74771428571428566, 0.73504761904761906, 0.72361904761904761, 0.72199999999999998, 0.71971428571428575, 0.70428571428571429, 0.70285714285714285, 0.70438095238095233, 0.70657142857142852, 0.69771428571428573, 0.69857142857142862]
  valid.accur. [0.18936795688388042, 0.20700636942675155, 0.21460068593826553, 0.21533561979421856, 0.2337089661930426, 0.24718275355218033, 0.24228319451249392, 0.25183733463988245, 0.2579617834394905, 0.2628613424791769, 0.25624693777560015, 0.2572268495835375, 0.2616364527192553, 0.2545320921117099, 0.2616364527192553]
300 utt., 8 cont., DBN[663, 1024, 55], 0 pretr. epochs, 15 epochs, LR: 0.01, L2: 0.0001, LR_decay=0.99, valid. size 0.3: accuracy=no,
  train errors [0.85314285714285709, 0.79542857142857137, 0.76304761904761909, 0.75723809523809527, 0.74057142857142855, 0.72419047619047616, 0.71038095238095234, 0.70971428571428574, 0.70857142857142852, 0.68552380952380954, 0.68600000000000005, 0.67828571428571427, 0.67304761904761901, 0.66276190476190477, 0.65047619047619043]
  valid.accur. [0.18936795688388042, 0.20994610485056342, 0.2170504654581088, 0.21950024497795195, 0.23860852523272902, 0.2582067613914748, 0.24889759921607058, 0.26384125428711414, 0.25575698187163154, 0.27290543851053406, 0.2457128858402744, 0.26016658500734935, 0.26384125428711414, 0.26090151886330226, 0.2628613424791769]
300 utt., 8 cont., DBN[663, 1024, 55], 0 pretr. epochs, 15 epochs, LR: 0.01, L2: 0.0001, LR_decay=1.0, valid. size 0.3: accuracy=no,
  train errors [0.85314285714285709, 0.79552380952380952, 0.76276190476190475, 0.75742857142857145, 0.73999999999999999, 0.72323809523809524, 0.71047619047619048, 0.7082857142857143, 0.70676190476190481, 0.68466666666666665, 0.68361904761904757, 0.67447619047619045, 0.66714285714285715, 0.6570476190476191, 0.6428571428571429]
  valid.accur. [0.18936795688388042, 0.21043606075453214, 0.2177853993140617, 0.22072513473787359, 0.23934345908868204, 0.25673689367956887, 0.24865262126408627, 0.26384125428711414, 0.25600195982361584, 0.2714355707986281, 0.24350808427241544, 0.2589416952474277, 0.26408623223909844, 0.26090151886330226, 0.2623713865752082]


--- On spec features:

100 utt., 3 cont., DBN[896, 1024, 42], 0 pretr. epochs, 15 epochs, LR: 0.003, LR_decay: 0.9, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.82431192660550456, 0.74954128440366974, 0.72273918741808652, 0.7068807339449541, 0.69370904325032767, 0.68676277850589773, 0.68204456094364352, 0.67804718217562254, 0.67477064220183491, 0.67326343381389253, 0.66788990825688077, 0.66402359108781128, 0.66874180865006549, 0.66487549148099612, 0.66559633027522935]
  valid.accur. [0.20834665813879116, 0.27390470099136555, 0.2735849056603774, 0.2745442916533418, 0.28829549088583306, 0.2945314998401023, 0.2860569235689159, 0.29101375119923245, 0.2903741605372562, 0.2906939558682443, 0.291973137192197, 0.2966101694915254, 0.29645027182603134, 0.30492484809721776, 0.3004477134633834]
300 utt., 8 cont., DBN[2176, 1024, 55], 0 pretr. epochs, 15 epochs, LR: 0.01, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.71782077393075361, 0.66160896130346236, 0.64311608961303457, 0.63543788187372707, 0.62370672097759672, 0.61441955193482689, 0.61162932790224034, 0.60486761710794301, 0.59869653767820774, 0.59796334012219954, 0.59480651731160894, 0.59672097759674136, 0.59138492871690429, 0.59205702647657843, 0.59109979633401222]
  valid.accur. [0.35284134739007456, 0.3794291591668809, 0.3925430701979944, 0.40730264849575726, 0.3961429673437902, 0.41074826433530476, 0.4172280791977372, 0.41712522499357163, 0.4141424530727693, 0.4154281306248393, 0.41702237078940607, 0.41373103625610697, 0.417536641810234, 0.42278220622267937, 0.42345075854975567]
300 utt., 3 cont., DBN[896, 1024, 55], 0 pretr. epochs, 15 epochs, LR: 0.001, LR_decay: 0.9, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.87661195779601409, 0.77745212973817901, 0.74726455646737011, 0.73726064869089492, 0.72917155138726064, 0.72284095349745991, 0.71631496678389994, 0.71162563501367726, 0.70691676436107853, 0.70513872606486905, 0.70422039859320051, 0.70382962094568191, 0.70338022665103561, 0.69790933958577572, 0.6964439234075811]
  valid.accur. [0.17110882049771758, 0.2468954007755363, 0.26402591665439556, 0.2759043832523438, 0.2710940951259019, 0.2814018553968488, 0.29401659058557894, 0.3032935748294311, 0.30535512688362043, 0.30525695773818284, 0.31237422078240806, 0.3122269670642517, 0.31561380258184857, 0.31909880724488293, 0.31654640946350565]
1000 utt., 0 cont., DBN[128, 1024, 1024, 1024, 157], 0 pretr. epochs, 15 epochs, LR: 0.01, LR_decay: 0.99, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.83257232133857473, 0.80157746194940027, 0.78886704969257126, 0.78053623626650537, 0.77298155427880255, 0.76512952323354499, 0.76226186876322954, 0.75699526257433725, 0.75390585626448947, 0.7511389980848705, 0.74562544098377181, 0.74363975405705074, 0.74203709303497634, 0.73824715250478778, 0.73792964418909379]
  valid.accur. [0.19238129857911113, 0.20416323650476298, 0.21357168058332354, 0.21133717511466543, 0.21927020409908804, 0.21821175414024996, 0.21640490522061728, 0.22648690836389296, 0.22776987801096937, 0.22476559075406544, 0.22573850940309836, 0.23394951514438755, 0.23043204002865303, 0.2293522072423636, 0.23830092053072183]
1000 utt., 1 cont., DBN[384, 1024, 1024, 1024, 157], 0 pretr. epochs, 15 epochs, LR: 0.01, LR_decay: 0.99, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.80576083646330321, 0.75983656481575479, 0.74048827530199979, 0.72585016749568576, 0.71301390721754132, 0.70261394782255604, 0.69334077758603185, 0.68528575779108725, 0.67854532534768042, 0.66929245761851586, 0.6639732006902852, 0.65719216323215912, 0.65125875545629885, 0.64444726423713328, 0.637681453659527]
  valid.accur. [0.21957754511314598, 0.2133580106097942, 0.24576845684525406, 0.23792409585400232, 0.2405496432914035, 0.2523215649984397, 0.2513746462505245, 0.24134591587487764, 0.258067640127834, 0.26374915261532506, 0.25564654105646, 0.2546781014279105, 0.26089763593126236, 0.2642548933102342, 0.25803535880688233]
1000 utt., 2 cont., DBN[640, 1024, 1024, 1024, 157], 0 pretr. epochs, 15 epochs, LR: 0.01, LR_decay: 0.99, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.79694816480932418, 0.7446528984766384, 0.72008485839893677, 0.70351702279930473, 0.68761374092628569, 0.67723136693589614, 0.66134342091810649, 0.65115530109395769, 0.64000102239034862, 0.62927103568142317, 0.62006952254370717, 0.60970759636029037, 0.60052653102954712, 0.58915243840098153, 0.58222063183723549]
  valid.accur. [0.2402391344373085, 0.23691421268668844, 0.2564196982660587, 0.2610117726056773, 0.2681923039433355, 0.26958942090043647, 0.27218870826248476, 0.26301538994725615, 0.26923201888815484, 0.2805605796410817, 0.2737699414077307, 0.281437839125773, 0.26194318391041127, 0.28396131393976154, 0.28364723338351405]
1000 utt., 3 cont., DBN[896, 1024, 1024, 1024, 157], 0 pretr. epochs, 15 epochs, LR: 0.01, LR_decay: 0.99, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.79133456904541244, 0.73882195448460508, 0.71135825352692827, 0.69089177221707343, 0.67256719184430025, 0.65713623725671921, 0.64277108433734942, 0.62494078879621051, 0.61249613839975281, 0.60081351045206466, 0.58834311605395939, 0.57357120790855731, 0.5650550921635259, 0.55030377921944185, 0.54268355473174745]
  valid.accur. [0.24116730075327308, 0.24086206708599955, 0.24872183401829218, 0.2594813207896831, 0.26280618752248375, 0.26635997950573953, 0.2736092791034851, 0.28107660274928326, 0.26100748912605065, 0.27905988030479767, 0.2764871965377781, 0.2874429049524162, 0.27817688291018494, 0.285764119782412, 0.2909203885188536]
1000 utt., 4 cont., DBN[1152, 1024, 1024, 1024, 157], 0 pretr. epochs, 15 epochs, LR: 0.01, LR_decay: 0.99, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors 0.5432
  valid.accur. 0.2944

minibatch_size=128
100 utt., 7 cont., DBN[1920, 1024, 1024, 1024, 42], 0 pretr. epochs, 15 epochs, LR: 0.01, LR_decay: 0.99, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.8279903017241379, 0.7188846982758621, 0.69241648706896552, 0.67746497844827591, 0.66123383620689657, 0.64412715517241381, 0.62991648706896552, 0.61139547413793105, 0.61126077586206895, 0.60243803879310343, 0.58869881465517238, 0.58492726293103448, 0.572265625, 0.57280441810344829, 0.57253502155172409]
  valid.accur. [0.17049974061905582, 0.2284281514784714, 0.2370741829500259, 0.22687186581359153, 0.25540376966972156, 0.26526024554729377, 0.26197475358810307, 0.265779007435587, 0.2647414836590005, 0.2726958326128307, 0.277018848348608, 0.2896420542970777, 0.28237938786097183, 0.2851461179318693, 0.2792668165312122]

minibatch_size=20
100 utt., 7 cont., DBN[1920, 1024, 1024, 1024, 42], 0 pretr. epochs, 15 epochs, LR: 0.01, LR_decay: 0.99, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors 0.5508
  valid.accur. 0.2828 at epoch 4, then falls

minibatch_size=32
100 utt., 7 cont., DBN[1920, 1024, 42], 0 pretr. epochs, 10 epochs, LR: 0.01, LR_decay: 0.99, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.80411748927038629, 0.71372049356223177, 0.68441523605150212, 0.68682939914163088, 0.6758986051502146, 0.66268776824034337, 0.64940987124463523, 0.64531920600858372, 0.63492489270386265, 0.61869635193133043]
  valid.accur. [0.18485215286183643, 0.24243472246238973, 0.23102196091993776, 0.22756354833131598, 0.22652602455472937, 0.23102196091993776, 0.2659519280650181, 0.2493515476396334, 0.26526024554729377, 0.26318519799412066]
100 utt., 8 cont., DBN[2176, 1024, 42], 0 pretr. epochs, 10 epochs, LR: 0.01, LR_decay: 0.99, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.79599567099567103, 0.71347402597402598, 0.69771374458874458, 0.67681277056277056, 0.67140151515151514, 0.66152597402597402, 0.64353354978354982, 0.63345508658008653, 0.61965638528138534, 0.62716450216450215]
  valid.accur. [0.1991962257557225, 0.23012406080726888, 0.22068845011357685, 0.2199895159881181, 0.22750305783679892, 0.24934474925738248, 0.24899528219465317, 0.2526646863533112, 0.215795911235366, 0.240083872095055]
100 utt., 7 cont., DBN[1920, 1024, 42], 0 pretr. epochs, 10 epochs, LR: 0.001, LR_decay: 0.99, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.87614002145922742, 0.80907993562231761, 0.80565987124463523, 0.80706813304721026, 0.81048819742489275, 0.80498927038626611, 0.80552575107296143, 0.79379023605150212, 0.7816523605150214, 0.74818937768240346]
  valid.accur. [0.14144907487463254, 0.13349472592080236, 0.13487809095625103, 0.1487117413107384, 0.15666609026456857, 0.15701193152343074, 0.15822237592944843, 0.15649316963513749, 0.19090437489192458, 0.21528618364170848]

3 x 512 layers is better than 1 x 1024:
100 utt., 7 cont., DBN[1920, 512, 512, 512, 42], 0 pretr. epochs, 10 epochs, LR: 0.01, LR_decay: 0.99, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.78860294117647056, 0.69029139433551201, 0.65066721132897598, 0.6158088235294118, 0.59545206971677556, 0.55834694989106759, 0.53696895424836599, 0.50605936819172115, 0.48318355119825707, 0.47011165577342046]
  valid.accur. [0.273029597605587, 0.3077818423678085, 0.277851679414699, 0.29331559694047227, 0.31526438310608584, 0.3282341203857665, 0.2956434985034918, 0.303292317924842, 0.3044562687063519, 0.32540738277352843]

momentum=0.5 then 0.9 after 4 epochs
100 utt., 8 cont., DBN[2176, 1024, 42], 0 pretr. epochs, 10 epochs, LR: 0.01, LR_decay: 0.99, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.83914835164835166, 0.8072802197802198, 0.76256868131868127, 0.75006868131868132, 0.73152472527472523, 0.72081043956043955, 0.71483516483516485, 0.70109890109890105, 0.69635989010989008, 0.68523351648351649]
  valid.accur. [0.18760497144776622, 0.19146792072556262, 0.2075915351024521, 0.2720859926100101, 0.26788713469936176, 0.2761168962042324, 0.28938528720188106, 0.2877057440376217, 0.28401074907625123, 0.29207255626469597]
100 utt., 7 cont., DBN[1920, 512, 512, 512, 42], 0 pretr. epochs, 10 epochs, LR: 0.01, LR_decay: 0.99, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.8586601307189542, 0.80984477124183007, 0.75599128540305016, 0.72147331154684091, 0.70329520697167758, 0.68178104575163401, 0.68307461873638342, 0.66966230936819171, 0.66033496732026142, 0.6540713507625272]
  valid.accur. [0.18922514133688062, 0.18689723977386097, 0.2620552045227802, 0.27253076155636846, 0.3049551047555703, 0.31360159627535755, 0.28965746591287, 0.2773528433654805, 0.31908879281676095, 0.33272364482873296]

less LR (LR=0.001) fails: at 2nd epoch acc falls, error is not stable
less start momentum (0.0) fails: after 4 epochs acc falls, error is not stable

100 utt., 7 cont., DBN[1920, 512, 512, 512, 42], 0 pretr. epochs, 20 epochs, LR: 0.001, LR_decay: 0.99, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.88133169934640521, 0.83619281045751637, 0.8195806100217865, 0.80221949891067534, 0.76640795206971679, 0.74203431372549022, 0.72923474945533773, 0.71718409586056642, 0.69846132897603486, 0.69641884531590414, 0.68688725490196079, 0.68314270152505452, 0.68055555555555558, 0.68001089324618735, 0.67408769063180829, 0.67102396514161222, 0.66537309368191722, 0.65502450980392157, 0.66033496732026142, 0.6527096949891068]
  valid.accur. [0.12304622547389421, 0.18373794479547723, 0.18124376454938473, 0.1917193215829731, 0.24492850016627865, 0.2685400731626205, 0.27452610575324243, 0.27884935151313606, 0.2951446624542734, 0.30512138343864315, 0.3027934818756235, 0.3036248752909877, 0.2976388427003658, 0.306285334220153, 0.2948121050881277, 0.3006318589956768, 0.2959760558696375, 0.296474891918856, 0.29913535084802123, 0.3177585633521782]

const momentum=0.9, big LR (0.1): acc is instable
100 utt., 7 cont., DBN[1920, 512, 512, 512, 42], 0 pretr. epochs, 15 epochs, LR: 0.1, LR_decay: 0.99, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.70213779956427014, 0.596609477124183, 0.55010893246187365, 0.48665577342047928, 0.45506535947712418, 0.40475217864923746, 0.37908496732026142, 0.34572440087145967, 0.32536764705882354, 0.31032135076252726, 0.29479847494553379, 0.28370098039215685, 0.26668028322440085, 0.25231481481481483, 0.23359204793028324]
  valid.accur. [0.27153308945793153, 0.2855004988360492, 0.2959760558696375, 0.2645493847688726, 0.2874958430329232, 0.2560691719321583, 0.25207848353841034, 0.29747256401729294, 0.2825074825407383, 0.31110741602926506, 0.273029597605587, 0.27502494180246095, 0.2791819088792816, 0.2590621882274693, 0.2863318922514134]

momentum=0.5 then 0.9 after 4 epochs: acc is instable
100 utt., 7 cont., DBN[1920, 512, 512, 512, 42], 0 pretr. epochs, 15 epochs, LR: 0.1, LR_decay: 0.99, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.74625544662309373, 0.65938180827886705, 0.62472766884531594, 0.576729302832244, 0.55344498910675377, 0.51273148148148151, 0.49571078431372551, 0.46282679738562094, 0.43899782135076254, 0.41516884531590414, 0.38405501089324617, 0.36288126361655776, 0.34817538126361658, 0.32475490196078433, 0.30344498910675383]
  valid.accur. [0.28566677751912206, 0.29331559694047227, 0.30295976055869633, 0.29714000665114737, 0.31326903890921187, 0.29580977718656465, 0.2909876953774526, 0.2396075823079481, 0.29447954772198204, 0.30861323578317257, 0.2628865979381443, 0.2816760891253741, 0.3027934818756235, 0.2938144329896907, 0.27884935151313606]

--- more training data (300 utt.)

LR=0.03, const momentum=0.9
300 utt., 7 cont., DBN[1920, 512, 512, 512, 55], 0 pretr. epochs, 15 epochs, LR: 0.03, LR_decay: 0.99, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors 0.5547
  valid.accur. 0.40141 at epoch=3, then falls (maybe overfitted)

l2_costs=0.001:
300 utt., 7 cont., DBN[1920, 512, 512, 512, 55], 0 pretr. epochs, 15 epochs, LR: 0.03, LR_decay: 0.99, L2: 0.001, valid. size 0.3: accuracy=no,
  train errors [0.69911522301228179, 0.63116111829347121, 0.61011231415643186, 0.59831528765352293, 0.58682126696832582, 0.57581205559146731, 0.56363122171945701, 0.56144957983193278, 0.54904654169360056, 0.54837992889463483, 0.54440045248868774, 0.53759292178409823, 0.53549208144796379, 0.53005817711700065, 0.52345265029088561]
  valid.accur. [0.36045859872611463, 0.38481528662420383, 0.37192356687898087, 0.3934777070063694, 0.4146242038216561, 0.3985222929936306, 0.408968152866242, 0.4130955414012739, 0.41294267515923566, 0.40585987261146494, 0.4128407643312102, 0.40132484076433117, 0.43052229299363054, 0.39245859872611466, 0.3908789808917198]

momentum=0.8:
300 utt., 7 cont., DBN[1920, 512, 512, 512, 55], 0 pretr. epochs, 15 epochs, LR: 0.03, LR_decay: 0.99, L2: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.70784179056237884, 0.62633322559793148, 0.58676066580478348, 0.56385342598577892, 0.53462346477052358, 0.50917097608274076, 0.48979880413703941, 0.46222527472527475, 0.44503474466709758, 0.42158209437621202, 0.4056439883645766, 0.37869667097608273, 0.36275856496444731, 0.34104314802844216, 0.32086296056884295]
  valid.accur. [0.3473261079733374, 0.38497939245916657, 0.41642497328652117, 0.4042639800539358, 0.3993792296341525, 0.4003968859716074, 0.40406044878644487, 0.37826286063196457, 0.3918994555538594, 0.390016791329568, 0.3753116572533456, 0.3741922352821452, 0.38910090062585867, 0.3850302752760393, 0.38009464203938326]

minibatch_size=20: acc decreases

momentum=0.95: acc decreases

l2_costs=0.01: acc [0.253, 0.247, 0.231]

l2_costs=0.003: error is instable after 4 epochs
300 utt., 7 cont., DBN[1920, 512, 512, 512, 55], 0 pretr. epochs, 15 epochs, LR: 0.03, LR_decay: 0.99, L2: 0.003, valid. size 0.3: accuracy=no,
  train errors [0.70804210013003899, 0.65366953836150843, 0.64176284135240569, 0.63099398569570875, 0.6335541287386216, 0.62963263979193762, 0.63079079973992203, 0.62713345253576069, 0.62640198309492845, 0.62132233420026006, 0.62609720416124837, 0.6246749024707412, 0.61941238621586481, 0.62221635240572171, 0.6233541937581274]
  valid.accur. [0.32296266559614617, 0.32717784022480934, 0.3108189482135688, 0.33786631874749096, 0.3281312725812926, 0.34735046166198313, 0.3527197912484946, 0.3522681653954235, 0.339622641509434, 0.333701324769169, 0.33129265355279003, 0.329084704937776, 0.3390204737053393, 0.33796668004817343, 0.34599558410277]

on 1000 utt. acc grew up to 0.25 then fell


--- pretraining experiments, 3x13 MFCC

no pretraining:
100 utt., 7 cont., DBN[585, 512, 512, 512, 42], 0 pretr. epochs, 15 epochs, LR: 0.1, LR_decay: 0.99, L2: 0.001, valid. size 0.3: accuracy=no,
  train errors [0.87367021276595747, 0.83543882978723405, 0.77992021276595747, 0.74867021276595747, 0.68517287234042556, 0.6582446808510638, 0.63031914893617025, 0.59308510638297873, 0.55186170212765961, 0.54355053191489366, 0.49035904255319152, 0.44913563829787234, 0.40625, 0.37433510638297873, 0.34441489361702127]
  valid.accur. [0.06837606837606836, 0.1858974358974359, 0.23076923076923073, 0.23219373219373218, 0.2656695156695157, 0.24643874643874641, 0.25142450142450146, 0.23005698005698005, 0.2257834757834758, 0.24643874643874641, 0.24928774928774933, 0.25997150997151, 0.24216524216524216, 0.25, 0.2343304843304843]

on spec features it doesn't learn:
100 utt., 7 cont., DBN[1920, 512, 512, 512, 42], [5, 5, 5, 5] pretr. epochs, 15 epochs, LR: 0.1, LR_decay: 0.99, L2: 0.001, valid. size 0.3: accuracy=no,
  train errors [0.90553489702517165, 0.89974256292906174, 0.90424771167048057, 0.89623855835240274, 0.90174485125858128, 0.89459382151029754, 0.90410469107551483, 0.89781178489702518, 0.89709668192219683, 0.89416475972540044, 0.9023169336384439, 0.89666762013729973, 0.89752574370709381, 0.89945652173913049, 0.90095823798627006]
  valid.accur. [0.12273402674591383, 0.12273402674591383, 0.12273402674591383, 0.12273402674591383, 0.12273402674591383, 0.12273402674591383, 0.12273402674591383, 0.12273402674591383, 0.12273402674591383, 0.12273402674591383, 0.12273402674591383, 0.12273402674591383, 0.12273402674591383, 0.12273402674591383, 0.12273402674591383]

LR_pre=0.001:
100 utt., 7 cont., DBN[585, 512, 512, 512, 42], [5, 5, 5, 5] pretr. epochs, 15 epochs, LR: 0.1, LR_decay: 0.99, L2: 0.001, valid. size 0.3: accuracy=no,
  train errors [0.89290364583333337, 0.87467447916666663, 0.86100260416666663, 0.8095703125, 0.763671875, 0.74153645833333337, 0.69401041666666663, 0.67024739583333337, 0.62565104166666663, 0.61328125, 0.5673828125, 0.56966145833333337, 0.54850260416666663, 0.5419921875, 0.49934895833333331]
  valid.accur. [0.10380881254667662, 0.10380881254667662, 0.12173263629574305, 0.15683345780433156, 0.1560866318147871, 0.17550410754294254, 0.18297236743838685, 0.1777445855115758, 0.18745332337565346, 0.19790888722927558, 0.17027632561613149, 0.17027632561613149, 0.186706497386109, 0.19268110530246452, 0.17251680358476473]

lower LR_pre=0.0001:
100 utt., 7 cont., DBN[585, 512, 512, 512, 42], [5, 5, 5, 5] pretr. epochs, LR_pretr: 0.0001, 10 epochs, LR: 0.1, LR_decay: 0.99, L2: 0.001, valid. size 0.3: accuracy=no,
  train errors [0.88983585858585856, 0.88383838383838387, 0.87910353535353536, 0.82481060606060608, 0.8017676767676768, 0.78787878787878785, 0.74747474747474751, 0.71590909090909094, 0.67708333333333337, 0.63478535353535348]
  valid.accur. [0.13026211278792688, 0.13026211278792688, 0.12787926926131854, 0.1469420174741859, 0.15806195393169187, 0.23193010325655283, 0.1667990468625894, 0.17791898332009526, 0.2382843526608419, 0.1834789515488483]

lower LR_pre=0.00001:
100 utt., 7 cont., DBN[585, 512, 512, 512, 42], 10 epochs, LR: 0.1, LR_decay: 0.99, L2: 0.001, [5, 5, 5, 5] pretr. epochs, LR_pretr: 1e-05, valid. size 0.3: accuracy=no,
  train errors [0.86192602040816324, 0.80867346938775508, 0.72704081632653061, 0.6986607142857143, 0.66677295918367352, 0.64572704081632648, 0.59375, 0.57684948979591832, 0.52487244897959184, 0.484375]
  valid.accur. [0.07775211701308704, 0.16320246343341027, 0.16397228637413397, 0.20323325635103928, 0.21247113163972287, 0.18937644341801385, 0.19707467282525015, 0.20323325635103928, 0.21478060046189373, 0.23248652809853732]

lower LR_pre=0.000001:
100 utt., 7 cont., DBN[585, 512, 512, 512, 42], 10 epochs, LR: 0.1, LR_decay: 0.99, L2: 0.001, [5, 5, 5, 5] pretr. epochs, LR_pretr: 1e-06, valid. size 0.3: accuracy=no,
  train errors [0.85460526315789476, 0.79967105263157889, 0.74078947368421055, 0.69506578947368425, 0.65164473684210522, 0.60855263157894735, 0.57138157894736841, 0.54868421052631577, 0.51875000000000004, 0.4888157894736842]
  valid.accur. [0.16485900216919736, 0.1315979754157628, 0.2147505422993492, 0.18365871294287783, 0.22125813449023857, 0.22270426608821403, 0.2270426608821403, 0.20173535791757047, 0.20679681851048448, 0.20173535791757047]

LR_pre=0.001, more 15 epochs: it doesn't learn
100 utt., 7 cont., DBN[585, 512, 512, 512, 42], 10 epochs, LR: 0.1, LR_decay: 0.99, L2: 0.001, [15, 15, 15, 15] pretr. epochs, LR_pretr: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.88598901098901095, 0.8928571428571429, 0.87534340659340659, 0.8794642857142857, 0.89217032967032972, 0.88152472527472525, 0.87843406593406592, 0.88461538461538458, 0.87912087912087911, 0.87774725274725274]
  valid.accur. [0.04768211920529797, 0.04768211920529797, 0.04768211920529797, 0.10794701986754962, 0.04768211920529797, 0.10794701986754962, 0.04768211920529797, 0.04768211920529797, 0.10794701986754962, 0.04768211920529797]

lower LR=0.01: it doesn't learn
100 utt., 7 cont., DBN[585, 512, 512, 512, 42], 10 epochs, LR: 0.01, LR_decay: 0.99, L2: 0.001, [15, 15, 15, 15] pretr. epochs, LR_pretr: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.89701704545454541, 0.89204545454545459, 0.88991477272727271, 0.89559659090909094, 0.88849431818181823, 0.89453125, 0.89382102272727271, 0.890625, 0.89098011363636365, 0.89240056818181823]
  valid.accur. [0.06832298136645965, 0.06832298136645965, 0.06832298136645965, 0.06832298136645965, 0.06832298136645965, 0.06832298136645965, 0.06832298136645965, 0.06832298136645965, 0.06832298136645965, 0.06832298136645965]

higher minibatch_size=128: it doesn't learn

100 utt., 7 cont., DBN[585, 512, 512, 512, 42], 10 epochs, LR: 1.1, LR_decay: 0.99, L2: 0.001, [5, 5, 5, 5] pretr. epochs, LR_pretr: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.896484375, 0.86979166666666663, 0.84114583333333337, 0.84407552083333337, 0.78548177083333337, 0.79459635416666663, 0.8037109375, 0.80143229166666663, 0.7578125, 0.75748697916666663]
  valid.accur. [0.1402439024390244, 0.1257621951219512, 0.14405487804878048, 0.1875, 0.15625, 0.1554878048780488, 0.2042682926829268, 0.19664634146341464, 0.2210365853658537, 0.16158536585365857]
100 utt., 7 cont., DBN[585, 512, 512, 512, 512, 512, 42], 10 epochs, LR: 0.1, LR_decay: 0.99, L2: 0.0, [5, 5, 5, 5, 5, 5] pretr. epochs, LR_pretr: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.86653645833333337, 0.8681640625, 0.87662760416666663, 0.86881510416666663, 0.86360677083333337, 0.8642578125, 0.8701171875, 0.86979166666666663, 0.869140625, 0.86848958333333337]
  valid.accur. [0.07850330154071905, 0.07850330154071905, 0.07850330154071905, 0.07850330154071905, 0.07850330154071905, 0.07850330154071905, 0.07850330154071905, 0.07850330154071905, 0.07850330154071905, 0.07850330154071905]
100 utt., 7 cont., DBN[585, 512, 512, 512, 512, 512, 42], 10 epochs, LR: 0.1, LR_decay: 0.99, L2: 0.0, [25, 25, 25, 25, 25, 25] pretr. epochs, LR_pretr: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.90980113636363635, 0.89595170454545459, 0.90092329545454541, 0.90163352272727271, 0.89737215909090906, 0.89985795454545459, 0.89417613636363635, 0.90021306818181823, 0.89595170454545459, 0.88742897727272729]
  valid.accur. [0.12960609911054632, 0.12960609911054632, 0.12960609911054632, 0.12960609911054632, 0.12960609911054632, 0.12960609911054632, 0.12960609911054632, 0.12960609911054632, 0.12960609911054632, 0.12960609911054632]
100 utt., 7 cont., DBN[585, 512, 512, 512, 512, 512, 42], 10 epochs, LR: 0.1, LR_decay: 0.99, L2: 0.0, [5, 5, 5, 5, 5, 5] pretr. epochs, LR_pretr: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.89875000000000005, 0.88937500000000003, 0.88062499999999999, 0.88062499999999999, 0.88906249999999998, 0.88218750000000001, 0.8878125, 0.88718750000000002, 0.890625, 0.87468749999999995]
  valid.accur. [0.11194029850746268, 0.11194029850746268, 0.11194029850746268, 0.11194029850746268, 0.11194029850746268, 0.11194029850746268, 0.11194029850746268, 0.11194029850746268, 0.13598673300165842, 0.14179104477611937]
100 utt., 7 cont., DBN[585, 512, 512, 512, 512, 512, 42], 10 epochs, LR: 2.1, LR_decay: 0.99, L2: 0.0, [5, 5, 5, 5, 5, 5] pretr. epochs, LR_pretr: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.88009510869565222, 0.87873641304347827, 0.87533967391304346, 0.85292119565217395, 0.85971467391304346, 0.87330163043478259, 0.85767663043478259, 0.85665760869565222, 0.86141304347826086, 0.85699728260869568]
  valid.accur. [0.05207600281491909, 0.06192821956368755, 0.059113300492610876, 0.06192821956368755, 0.06192821956368755, 0.05207600281491909, 0.10767065446868407, 0.06192821956368755, 0.06192821956368755, 0.06826178747361011]
100 utt., 7 cont., DBN[585, 512, 512, 512, 512, 512, 42], 10 epochs, LR: 0.1, LR_decay: 0.99, L2: 0.0, [15, 15, 15, 15, 15, 15] pretr. epochs, LR_pretr: 0.01, valid. size 0.3: accuracy=no,
  train errors [0.90299479166666663, 0.87858072916666663, 0.88639322916666663, 0.88541666666666663, 0.8818359375, 0.88151041666666663, 0.87532552083333337, 0.875, 0.88216145833333337, 0.88118489583333337]
  valid.accur. [0.10965250965250961, 0.10965250965250961, 0.10965250965250961, 0.10965250965250961, 0.10965250965250961, 0.10965250965250961, 0.10965250965250961, 0.10965250965250961, 0.10965250965250961, 0.10965250965250961]

low LR=0.001: it doesn't learn at all
100 utt., 7 cont., DBN[585, 512, 512, 512, 512, 512, 42], 10 epochs, LR: 0.001, LR_decay: 0.99, L2: 0.0, [15, 15, 15, 15, 15, 15] pretr. epochs, LR_pretr: 0.01, valid. size 0.3: accuracy=no,
  train errors [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.91718750000000004, 0.90218750000000003, 0.90531249999999996]
  valid.accur. [0.018363939899833093, 0.018363939899833093, 0.018363939899833093, 0.018363939899833093, 0.018363939899833093, 0.018363939899833093, 0.018363939899833093, 0.10601001669449084, 0.10601001669449084, 0.10601001669449084]
100 utt., 7 cont., DBN[585, 512, 512, 512, 512, 512, 42], 10 epochs, LR: 0.001, LR_decay: 0.99, L2: 0.001, [15, 15, 15, 15, 15, 15] pretr. epochs, LR_pretr: 0.01, valid. size 0.3: accuracy=no,
  train errors [0.99396306818181823, 0.99325284090909094, 0.99076704545454541, 0.98863636363636365, 0.99112215909090906, 0.99396306818181823, 0.99289772727272729, 0.99467329545454541, 0.92649147727272729, 0.89879261363636365]
  valid.accur. [0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.09999999999999998, 0.09999999999999998]

100 utt., 7 cont., DBN[585, 512, 512, 512, 42], 10 epochs, LR: 0.01, LR_decay: 0.99, L2: 0.001, [5, 5, 5, 5] pretr. epochs, LR_pretr: 0.01, valid. size 0.3: accuracy=no,
  train errors [0.99781249999999999, 0.90781250000000002, 0.86406249999999996, 0.87281249999999999, 0.8671875, 0.87031250000000004, 0.87031250000000004, 0.875, 0.87468749999999995, 0.86906249999999996]
  valid.accur. [0.0, 0.0707885304659498, 0.0707885304659498, 0.0707885304659498, 0.0707885304659498, 0.0707885304659498, 0.0707885304659498, 0.0707885304659498, 0.0707885304659498, 0.0707885304659498]
100 utt., 7 cont., DBN[585, 512, 512, 512, 42], 10 epochs, LR: 0.01, LR_decay: 0.99, L2: 0.001, [5, 5, 5, 5] pretr. epochs, LR_pretr: 0.01, valid. size 0.3: accuracy=no,
  train errors [0.93999999999999995, 0.87656250000000002, 0.88218750000000001, 0.87406249999999996, 0.87062499999999998, 0.864375, 0.88468749999999996, 0.87843749999999998, 0.88187499999999996, 0.87562499999999999]
  valid.accur. [0.08108108108108103, 0.08108108108108103, 0.08108108108108103, 0.08108108108108103, 0.08108108108108103, 0.08108108108108103, 0.08108108108108103, 0.08108108108108103, 0.08108108108108103, 0.08108108108108103]
100 utt., 7 cont., DBN[585, 512, 512, 512, 42], 10 epochs, LR: 0.01, LR_decay: 0.99, L2: 0.0, [5, 5, 5, 5] pretr. epochs, LR_pretr: 0.01, valid. size 0.3: accuracy=no,
  train errors [0.9501953125, 0.88802083333333337, 0.87760416666666663, 0.88444010416666663, 0.87760416666666663, 0.8681640625, 0.87467447916666663, 0.87890625, 0.880859375, 0.880859375]
  valid.accur. [0.09368029739776951, 0.09368029739776951, 0.09368029739776951, 0.09368029739776951, 0.09368029739776951, 0.09368029739776951, 0.09368029739776951, 0.09368029739776951, 0.09368029739776951, 0.09368029739776951]
100 utt., 7 cont., DBN[585, 512, 512, 512, 42], 10 epochs, LR: 0.1, LR_decay: 0.99, L2: 0.0, [5, 5, 5, 5] pretr. epochs, LR_pretr: 0.01, valid. size 0.3: accuracy=no,
  train errors [0.91145833333333337, 0.8857421875, 0.88216145833333337, 0.87955729166666663, 0.87369791666666663, 0.88411458333333337, 0.88671875, 0.89127604166666663, 0.880859375, 0.88899739583333337]
  valid.accur. [0.049848942598187285, 0.049848942598187285, 0.049848942598187285, 0.049848942598187285, 0.049848942598187285, 0.049848942598187285, 0.049848942598187285, 0.049848942598187285, 0.049848942598187285, 0.049848942598187285]
100 utt., 7 cont., DBN[585, 512, 512, 512, 42], 10 epochs, LR: 1.1, LR_decay: 0.99, L2: 0.0, [5, 5, 5, 5] pretr. epochs, LR_pretr: 0.01, valid. size 0.3: accuracy=no,
  train errors [0.89029947916666663, 0.88802083333333337, 0.8916015625, 0.87923177083333337, 0.8837890625, 0.88606770833333337, 0.88606770833333337, 0.88932291666666663, 0.89029947916666663, 0.89225260416666663]
  valid.accur. [0.057764441110277565, 0.057764441110277565, 0.1230307576894224, 0.057764441110277565, 0.057764441110277565, 0.057764441110277565, 0.1230307576894224, 0.057764441110277565, 0.057764441110277565, 0.057764441110277565]
100 utt., 7 cont., DBN[585, 512, 512, 512, 42], 10 epochs, LR: 1.1, LR_decay: 0.99, L2: 0.001, [5, 5, 5, 5] pretr. epochs, LR_pretr: 0.01, valid. size 0.3: accuracy=no,
  train errors [0.89095052083333337, 0.892578125, 0.8828125, 0.89095052083333337, 0.89290364583333337, 0.88997395833333337, 0.90006510416666663, 0.88932291666666663, 0.88899739583333337, 0.8916015625]
  valid.accur. [0.11726907630522088, 0.11726907630522088, 0.11726907630522088, 0.11726907630522088, 0.11726907630522088, 0.11726907630522088, 0.11726907630522088, 0.11726907630522088, 0.11726907630522088, 0.11726907630522088]


100 utt., 7 cont., DBN[585, 512, 512, 512, 42], 10 epochs, LR: 0.01, LR_decay: 0.99, L2: 0.001, [5, 5, 5, 5] pretr. epochs, LR_pretr: 0.01, valid. size 0.3: accuracy=no,
  train errors [0.9716796875, 0.87369791666666663, 0.86848958333333337, 0.87727864583333337, 0.87109375, 0.875, 0.876953125, 0.86002604166666663, 0.87955729166666663, 0.86295572916666663]
  valid.accur. [0.06874500399680261, 0.06874500399680261, 0.06874500399680261, 0.06874500399680261, 0.06874500399680261, 0.06874500399680261, 0.06874500399680261, 0.06874500399680261, 0.06874500399680261, 0.06874500399680261]
100 utt., 7 cont., DBN[585, 512, 512, 512, 42], 10 epochs, LR: 0.1, LR_decay: 0.99, L2: 0.001, [15, 15, 15, 15] pretr. epochs, LR_pretr: 0.001, valid. size 0.3: accuracy=no,
  train errors [0.90494791666666663, 0.89518229166666663, 0.8935546875, 0.900390625, 0.89583333333333337, 0.880859375, 0.900390625, 0.9013671875, 0.89029947916666663, 0.8935546875]
  valid.accur. [0.12490650710546003, 0.12490650710546003, 0.12490650710546003, 0.12490650710546003, 0.12490650710546003, 0.12490650710546003, 0.12490650710546003, 0.12490650710546003, 0.12490650710546003, 0.12490650710546003]
100 utt., 7 cont., DBN[585, 512, 512, 512, 42], 10 epochs, LR: 0.1, LR_decay: 0.99, L2: 0.0001, [5, 5, 5, 5] pretr. epochs, LR_pretr: 0.001, valid. size 0.3: accuracy=no,
  train errors [0.91066576086956519, 0.88586956521739135, 0.89741847826086951, 0.89809782608695654, 0.89198369565217395, 0.89979619565217395, 0.89707880434782605, 0.89911684782608692, 0.89470108695652173, 0.89436141304347827]
  valid.accur. [0.13347763347763353, 0.13347763347763353, 0.0800865800865801, 0.0800865800865801, 0.0800865800865801, 0.0800865800865801, 0.0800865800865801, 0.0800865800865801, 0.0800865800865801, 0.0800865800865801]
100 utt., 7 cont., DBN[585, 512, 512, 512, 42], 15 epochs, LR: 0.1, mom: 0.9, LR_decay: 0.99, L2: 0.001, [15, 15, 15, 15] pretr. epochs, LR_pretr: 0.001, valid. size 0.3: accuracy=no,
  train errors [0.90489130434782605, 0.88926630434782605, 0.89707880434782605, 0.89707880434782605, 0.90319293478260865, 0.89198369565217395, 0.89334239130434778, 0.8984375, 0.89809782608695654, 0.89028532608695654, 0.89402173913043481, 0.890625, 0.89673913043478259, 0.89809782608695654, 0.89639945652173914]
  valid.accur. [0.07866761162296243, 0.07866761162296243, 0.1296952515946137, 0.07866761162296243, 0.1296952515946137, 0.1296952515946137, 0.1296952515946137, 0.07866761162296243, 0.1296952515946137, 0.1296952515946137, 0.07866761162296243, 0.07866761162296243, 0.1296952515946137, 0.1296952515946137, 0.07866761162296243]
100 utt., 7 cont., DBN[585, 512, 512, 512, 42], 15 epochs, LR: 0.1, mom: 0.9, LR_decay: 0.99, L2: 0.001, [1, 1, 1, 1] pretr. epochs, LR_pretr: 1e-05, valid. size 0.3: accuracy=no,
  train errors [0.88994565217391308, 0.83491847826086951, 0.77377717391304346, 0.73811141304347827, 0.66677989130434778, 0.63213315217391308, 0.56759510869565222, 0.55230978260869568, 0.4891304347826087, 0.45686141304347827, 0.42730978260869568, 0.4110054347826087, 0.32846467391304346, 0.30842391304347827, 0.27139945652173914]
  valid.accur. [0.05061460592913958, 0.15039768618944327, 0.18727404193781638, 0.23210412147505421, 0.19884309472161965, 0.1973969631236443, 0.1973969631236443, 0.23861171366594358, 0.2241503976861895, 0.20679681851048448, 0.18944323933477947, 0.21981200289226321, 0.2147505422993492, 0.163412870571222, 0.17498192335502527]
100 utt., 7 cont., DBN[585, 512, 512, 512, 42], 15 epochs, LR: 0.1, mom: 0.9, LR_decay: 0.99, L2: 0.0, [1, 1, 1, 1] pretr. epochs, LR_pretr: 0.001, valid. size 0.3: accuracy=no,
  train errors [0.86345108695652173, 0.85699728260869568, 0.85699728260869568, 0.85326086956521741, 0.86514945652173914, 0.85801630434782605, 0.85665760869565222, 0.85529891304347827, 0.85224184782608692, 0.84884510869565222, 0.85427989130434778, 0.83763586956521741, 0.83865489130434778, 0.80842391304347827, 0.79925271739130432]
  valid.accur. [0.04693877551020409, 0.04693877551020409, 0.04693877551020409, 0.04693877551020409, 0.04693877551020409, 0.04693877551020409, 0.04693877551020409, 0.04693877551020409, 0.04693877551020409, 0.04693877551020409, 0.04693877551020409, 0.04693877551020409, 0.06598639455782318, 0.07891156462585036, 0.11360544217687074]
100 utt., 7 cont., DBN[585, 512, 512, 512, 42], 25 epochs, LR: 0.1, mom: 0.9, LR_decay: 0.99, L2: 0.0, [1, 1, 1, 1] pretr. epochs, LR_pretr: 0.001, valid. size 0.3: accuracy=no,
  train errors [0.9140625, 0.90592447916666663, 0.90266927083333337, 0.89453125, 0.8955078125, 0.90657552083333337, 0.89192708333333337, 0.9033203125, 0.89713541666666663, 0.89908854166666663, 0.89290364583333337, 0.90071614583333337, 0.88997395833333337, 0.900390625, 0.89322916666666663, 0.87467447916666663, 0.88932291666666663, 0.88411458333333337, 0.873046875, 0.83268229166666663, 0.81412760416666663, 0.80436197916666663, 0.7705078125, 0.75553385416666663, 0.74739583333333337]
  valid.accur. [0.1456310679611651, 0.1456310679611651, 0.07916355489171023, 0.07916355489171023, 0.1456310679611651, 0.07916355489171023, 0.07916355489171023, 0.07916355489171023, 0.1456310679611651, 0.1456310679611651, 0.07916355489171023, 0.07916355489171023, 0.07916355489171023, 0.07916355489171023, 0.1456310679611651, 0.08289768483943238, 0.16728902165795367, 0.17027632561613149, 0.17326362957430919, 0.157580283793876, 0.18147871545929795, 0.15235250186706495, 0.16355489171023152, 0.17326362957430919, 0.20089619118745328]

100 utt., 7 cont., DBN[585, 512, 512, 512, 42], 30 epochs, LR: 0.3, mom: 0.9, LR_decay: 0.99, L2: 0.0, [1, 1, 1, 1] pretr. epochs, LR_pretr: 0.001, valid. size 0.3: accuracy=no,
  train errors [0.8896484375, 0.88639322916666663, 0.90625, 0.88541666666666663, 0.89388020833333337, 0.8720703125, 0.87630208333333337, 0.81673177083333337, 0.77278645833333337, 0.72721354166666663, 0.69466145833333337, 0.65169270833333337, 0.59016927083333337, 0.51822916666666663, 0.50423177083333337, 0.419921875, 0.35514322916666669, 0.32942708333333331, 0.2509765625, 0.21256510416666666, 0.1591796875, 0.13053385416666666, 0.11458333333333333, 0.087565104166666671, 0.097330729166666671, 0.080729166666666671, 0.046223958333333336, 0.032877604166666664, 0.041015625, 0.046223958333333336]
  valid.accur. [0.045112781954887216, 0.045112781954887216, 0.045112781954887216, 0.045112781954887216, 0.045112781954887216, 0.045112781954887216, 0.10300751879699244, 0.11729323308270678, 0.12706766917293233, 0.1819548872180451, 0.16992481203007515, 0.19097744360902258, 0.175187969924812, 0.1428571428571429, 0.1473684210526316, 0.16165413533834583, 0.11879699248120301, 0.15939849624060154, 0.15939849624060154, 0.17067669172932332, 0.1556390977443609, 0.15939849624060154, 0.14210526315789473, 0.14887218045112782, 0.1578947368421053, 0.15939849624060154, 0.17819548872180446, 0.15037593984962405, 0.17819548872180446, 0.17368421052631577]
100 utt., 7 cont., DBN[585, 512, 512, 512, 42], 30 epochs, LR: 0.1, mom: 0.9, LR_decay: 0.99, L2: 0.001, [5, 5, 5, 5] pretr. epochs, LR_pretr: 0.001, valid. size 0.3: accuracy=no,
  train errors [0.91474184782608692, 0.89402173913043481, 0.90658967391304346, 0.91032608695652173, 0.90149456521739135, 0.90013586956521741, 0.89538043478260865, 0.90047554347826086, 0.91372282608695654, 0.89741847826086951, 0.90251358695652173, 0.90047554347826086, 0.90081521739130432, 0.90251358695652173, 0.90455163043478259, 0.90319293478260865, 0.89809782608695654, 0.90387228260869568, 0.90692934782608692, 0.89504076086956519, 0.89572010869565222, 0.89130434782608692, 0.89605978260869568, 0.89164402173913049, 0.90183423913043481, 0.91134510869565222, 0.89572010869565222, 0.90421195652173914, 0.90013586956521741, 0.88960597826086951]
  valid.accur. [0.13714285714285712, 0.13714285714285712, 0.11142857142857143, 0.11142857142857143, 0.13714285714285712, 0.13714285714285712, 0.13714285714285712, 0.13714285714285712, 0.13714285714285712, 0.13714285714285712, 0.13714285714285712, 0.13714285714285712, 0.13714285714285712, 0.13714285714285712, 0.13714285714285712, 0.13714285714285712, 0.13714285714285712, 0.13714285714285712, 0.13714285714285712, 0.13714285714285712, 0.13714285714285712, 0.13714285714285712, 0.13714285714285712, 0.13714285714285712, 0.13714285714285712, 0.11142857142857143, 0.13714285714285712, 0.13714285714285712, 0.13714285714285712, 0.13714285714285712]
100 utt., 7 cont., DBN[585, 512, 512, 512, 42], 30 epochs, LR: 1.1, mom: 0.5, LR_decay: 0.99, L2: 0.001, [5, 5, 5, 5] pretr. epochs, LR_pretr: 0.001, valid. size 0.3: accuracy=no,
  train errors [0.91779891304347827, 0.91745923913043481, 0.91610054347826086, 0.90625, 0.90625, 0.90183423913043481, 0.90523097826086951, 0.90183423913043481, 0.90862771739130432, 0.89775815217391308, 0.90964673913043481, 0.91202445652173914, 0.90387228260869568, 0.90794836956521741, 0.89911684782608692, 0.91168478260869568, 0.91270380434782605, 0.91100543478260865, 0.90081521739130432, 0.90930706521739135, 0.90828804347826086, 0.90692934782608692, 0.91440217391304346, 0.91032608695652173, 0.90625, 0.91032608695652173, 0.91677989130434778, 0.90013586956521741, 0.91202445652173914, 0.90896739130434778]
  valid.accur. [0.15319148936170213, 0.15319148936170213, 0.15319148936170213, 0.15319148936170213, 0.15319148936170213, 0.15319148936170213, 0.15319148936170213, 0.15319148936170213, 0.15319148936170213, 0.15319148936170213, 0.15319148936170213, 0.15319148936170213, 0.15319148936170213, 0.15319148936170213, 0.15319148936170213, 0.12411347517730498, 0.15319148936170213, 0.15319148936170213, 0.15319148936170213, 0.12411347517730498, 0.15319148936170213, 0.15319148936170213, 0.15319148936170213, 0.15319148936170213, 0.15319148936170213, 0.15319148936170213, 0.12411347517730498, 0.15319148936170213, 0.15319148936170213, 0.15319148936170213]

less minibatch size=32 during fine-tuning:
100 utt., 7 cont., DBN[585, 512, 512, 512, 42], 30 epochs, LR: 1.1, mom: 0.9, LR_decay: 0.99, L2: 0.001, [5, 5, 5, 5] pretr. epochs, LR_pretr: 0.001, valid. size 0.3: accuracy=no,
  train errors [0.93359375, 0.91015625, 0.91015625, 0.91145833333333337, 0.91796875, 0.91536458333333337, 0.88020833333333337, 0.921875, 0.90625, 0.91536458333333337, 0.9140625, 0.91927083333333337, 0.93489583333333337, 0.89192708333333337, 0.92317708333333337, 0.92317708333333337, 0.88932291666666663, 0.9140625, 0.91666666666666663, 0.9140625, 0.89453125, 0.91536458333333337, 0.90755208333333337, 0.921875, 0.91666666666666663, 0.90104166666666663, 0.91145833333333337, 0.92317708333333337, 0.93359375, 0.90625]
  valid.accur. [0.12481426448736999, 0.1329866270430906, 0.024517087667161985, 0.12481426448736999, 0.12481426448736999, 0.024517087667161985, 0.01634472511144136, 0.1329866270430906, 0.12481426448736999, 0.024517087667161985, 0.01634472511144136, 0.024517087667161985, 0.12481426448736999, 0.024517087667161985, 0.024517087667161985, 0.024517087667161985, 0.12481426448736999, 0.12481426448736999, 0.12481426448736999, 0.024517087667161985, 0.12481426448736999, 0.12481426448736999, 0.024517087667161985, 0.12481426448736999, 0.12481426448736999, 0.024517087667161985, 0.1329866270430906, 0.024517087667161985, 0.12481426448736999, 0.1329866270430906]

momentum=0.0, o L2=0:
100 utt., 7 cont., DBN[585, 512, 512, 512, 42], 30 epochs, LR: 1.1, mom: 0.0, LR_decay: 0.99, L2: 0.0, [5, 5, 5, 5] pretr. epochs, LR_pretr: 0.001, valid. size 0.3: accuracy=no,
  train errors [0.91576086956521741, 0.89504076086956519, 0.89707880434782605, 0.86684782608695654, 0.83491847826086951, 0.82846467391304346, 0.80264945652173914, 0.80095108695652173, 0.76800271739130432, 0.74864130434782605, 0.70652173913043481, 0.6796875, 0.62601902173913049, 0.61413043478260865, 0.57982336956521741, 0.57269021739130432, 0.51222826086956519, 0.49354619565217389, 0.44870923913043476, 0.39911684782608697, 0.43002717391304346, 0.36345108695652173, 0.30842391304347827, 0.28736413043478259, 0.24082880434782608, 0.1827445652173913, 0.1796875, 0.090353260869565216, 0.090692934782608689, 0.10699728260869565]
  valid.accur. [0.09553695955369601, 0.09832635983263593, 0.08647140864714087, 0.11645746164574622, 0.16317991631799167, 0.16945606694560666, 0.1701534170153417, 0.13249651324965128, 0.1555090655509066, 0.1345885634588564, 0.17573221757322177, 0.23779637377963736, 0.1910739191073919, 0.18131101813110184, 0.2259414225941423, 0.16108786610878656, 0.1764295676429568, 0.15062761506276146, 0.20432357043235705, 0.1659693165969317, 0.18828451882845187, 0.1659693165969317, 0.09623430962343094, 0.09274755927475598, 0.17503486750348674, 0.1764295676429568, 0.1806136680613668, 0.17712691771269173, 0.17154811715481166, 0.10948396094839608]

// lower LR=0.1, momentum=0.0, then 0.9 after 1st epoch:
300 utt., 7 cont., DBN[585, 512, 512, 512, 55], 30 epochs, LR: 0.1, mom: 0.0, LR_decay: 0.99, L2: 0.0, [5, 5, 5, 5] pretr. epochs, LR_pretr: 0.001, valid. size 0.3: accuracy=no,
  train errors [0.92083960843373491, 0.91199171686746983, 0.91208584337349397, 0.91566265060240959, 0.91283885542168675, 0.91745105421686746, 0.9162274096385542, 0.91566265060240959, 0.90945030120481929, 0.9140625, 0.90907379518072284, 0.91161521084337349, 0.91349774096385539, 0.90775602409638556, 0.91340361445783136, 0.91415662650602414, 0.91321536144578308, 0.9178275602409639, 0.90766189759036142, 0.91274472891566261, 0.91462725903614461, 0.90756777108433739, 0.91415662650602414, 0.91519201807228912, 0.91312123493975905, 0.91500376506024095, 0.91556852409638556, 0.91829819277108438, 0.91321536144578308, 0.90954442771084343]
  valid.accur. [0.0934887813462385, 0.0934887813462385, 0.0934887813462385, 0.0934887813462385, 0.0934887813462385, 0.0934887813462385, 0.07853057633084026, 0.07853057633084026, 0.07853057633084026, 0.07853057633084026, 0.07853057633084026, 0.07853057633084026, 0.07853057633084026, 0.07853057633084026, 0.0934887813462385, 0.0934887813462385, 0.0934887813462385, 0.07853057633084026, 0.0934887813462385, 0.0934887813462385, 0.0934887813462385, 0.0934887813462385, 0.0934887813462385, 0.0934887813462385, 0.0934887813462385, 0.07853057633084026, 0.0934887813462385, 0.0934887813462385, 0.0934887813462385, 0.07853057633084026]

--- if use many epochs of fine-tuning, it starts to learn after 30-40 epochs

fine-tune momentum=0.9: (acc up to 0.25)
100 utt., 7 cont., DBN[585, 512, 512, 512, 42], 300 epochs, LR: 0.03, mom: 0.0, LR_decay: 0.99, L2: 0.0, [15, 15, 15, 15] pretr. epochs, LR_pretr: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.888671875, 0.86783854166666663, 0.87174479166666663, 0.88411458333333337, 0.875, 0.8837890625, 0.88020833333333337, 0.87272135416666663, 0.87467447916666663, 0.8701171875, 0.876953125, 0.88736979166666663, 0.88411458333333337, 0.87955729166666663, 0.86165364583333337, 0.88606770833333337, 0.88509114583333337, 0.87141927083333337, 0.873046875, 0.86751302083333337, 0.87141927083333337, 0.876953125, 0.873046875, 0.87272135416666663, 0.86328125, 0.8701171875, 0.87434895833333337, 0.88248697916666663, 0.87369791666666663, 0.87760416666666663, 0.8671875, 0.875, 0.87141927083333337, 0.8740234375, 0.8798828125, 0.88671875, 0.86686197916666663, 0.876953125, 0.86686197916666663, 0.85904947916666663, 0.8759765625, 0.85970052083333337, 0.8564453125, 0.8486328125, 0.84016927083333337, 0.85286458333333337, 0.84016927083333337, 0.83951822916666663, 0.8369140625, 0.8408203125, 0.85026041666666663, 0.83854166666666663, 0.83723958333333337, 0.84147135416666663, 0.818359375, 0.82649739583333337, 0.82942708333333337, 0.81575520833333337, 0.82649739583333337, 0.81477864583333337, 0.81803385416666663, 0.8017578125, 0.80826822916666663, 0.79654947916666663, 0.7998046875, 0.79036458333333337, 0.80631510416666663, 0.79361979166666663, 0.7900390625, 0.783203125, 0.79296875, 0.78125, 0.78743489583333337, 0.80501302083333337, 0.7919921875, 0.77864583333333337, 0.77799479166666663, 0.78059895833333337, 0.77278645833333337, 0.78483072916666663, 0.78743489583333337, 0.7822265625, 0.76529947916666663, 0.76822916666666663, 0.77278645833333337, 0.77115885416666663, 0.77115885416666663, 0.76595052083333337, 0.76236979166666663, 0.78548177083333337, 0.77180989583333337, 0.7548828125, 0.75455729166666663, 0.74934895833333337, 0.76009114583333337, 0.76627604166666663, 0.76399739583333337, 0.75748697916666663, 0.75618489583333337, 0.7666015625, 0.76595052083333337, 0.771484375, 0.76106770833333337, 0.75423177083333337, 0.75065104166666663, 0.7333984375, 0.74967447916666663, 0.74446614583333337, 0.75325520833333337, 0.75162760416666663, 0.74739583333333337, 0.751953125, 0.736328125, 0.74251302083333337, 0.74967447916666663, 0.7392578125, 0.7314453125, 0.74055989583333337, 0.724609375, 0.73014322916666663, 0.7294921875, 0.72005208333333337, 0.73307291666666663, 0.724609375, 0.7265625, 0.74186197916666663, 0.7216796875, 0.73958333333333337, 0.74088541666666663, 0.7275390625, 0.73209635416666663, 0.73014322916666663, 0.7314453125, 0.72688802083333337, 0.73111979166666663, 0.72005208333333337, 0.71647135416666663, 0.71940104166666663, 0.720703125, 0.71516927083333337, 0.7236328125, 0.71419270833333337, 0.7158203125, 0.71126302083333337, 0.7109375, 0.71321614583333337, 0.7197265625, 0.71158854166666663, 0.7177734375, 0.72591145833333337, 0.7216796875, 0.70279947916666663, 0.72005208333333337, 0.7216796875, 0.70670572916666663, 0.71256510416666663, 0.71907552083333337, 0.72493489583333337, 0.71484375, 0.71907552083333337, 0.7177734375, 0.70052083333333337, 0.70670572916666663, 0.6923828125, 0.71451822916666663, 0.69954427083333337, 0.71647135416666663, 0.71516927083333337, 0.70572916666666663, 0.7255859375, 0.70572916666666663, 0.7138671875, 0.728515625, 0.72037760416666663, 0.69596354166666663, 0.70247395833333337, 0.720703125, 0.716796875, 0.693359375, 0.69205729166666663, 0.70279947916666663, 0.72005208333333337, 0.69075520833333337, 0.70475260416666663, 0.7138671875, 0.70540364583333337, 0.69856770833333337, 0.71516927083333337, 0.71223958333333337, 0.7099609375, 0.70345052083333337, 0.70638020833333337, 0.6923828125, 0.7099609375, 0.71158854166666663, 0.705078125, 0.7060546875, 0.70703125, 0.70735677083333337, 0.70670572916666663, 0.6962890625, 0.69108072916666663, 0.69694010416666663, 0.69563802083333337, 0.68001302083333337, 0.69498697916666663, 0.68391927083333337, 0.69205729166666663, 0.69921875, 0.69954427083333337, 0.67903645833333337, 0.69205729166666663, 0.6904296875, 0.703125, 0.69368489583333337, 0.6884765625, 0.69596354166666663, 0.69075520833333337, 0.68619791666666663, 0.68977864583333337, 0.6826171875, 0.68684895833333337, 0.697265625, 0.693359375, 0.6748046875, 0.68131510416666663, 0.69401041666666663, 0.6875, 0.67838541666666663, 0.69791666666666663, 0.68880208333333337, 0.69108072916666663, 0.6875, 0.69108072916666663, 0.7001953125, 0.6904296875, 0.69140625, 0.6806640625, 0.69661458333333337, 0.69368489583333337, 0.67903645833333337, 0.68359375, 0.67903645833333337, 0.6865234375, 0.68815104166666663, 0.6875, 0.7041015625, 0.685546875, 0.68391927083333337, 0.689453125, 0.6962890625, 0.68098958333333337, 0.68033854166666663, 0.66764322916666663, 0.68424479166666663, 0.67350260416666663, 0.6650390625, 0.6875, 0.67708333333333337, 0.67252604166666663, 0.68587239583333337, 0.6875, 0.6748046875, 0.67740885416666663, 0.68912760416666663, 0.69010416666666663, 0.67220052083333337, 0.67024739583333337, 0.66438802083333337, 0.67350260416666663, 0.68326822916666663, 0.69596354166666663, 0.6875, 0.66471354166666663, 0.66569010416666663, 0.68880208333333337, 0.67936197916666663, 0.66959635416666663, 0.65690104166666663, 0.6767578125, 0.658203125, 0.6572265625, 0.6953125, 0.669921875, 0.67154947916666663, 0.67740885416666663, 0.68098958333333337, 0.66959635416666663, 0.68196614583333337, 0.6845703125, 0.66080729166666663, 0.67610677083333337, 0.66471354166666663, 0.66731770833333337, 0.68294270833333337, 0.6630859375, 0.6640625, 0.66666666666666663, 0.67578125, 0.67447916666666663]
  valid.accur. [0.08615384615384614, 0.08615384615384614, 0.08615384615384614, 0.08615384615384614, 0.08615384615384614, 0.08615384615384614, 0.08615384615384614, 0.08615384615384614, 0.08615384615384614, 0.08615384615384614, 0.08615384615384614, 0.08615384615384614, 0.08615384615384614, 0.08615384615384614, 0.08615384615384614, 0.08615384615384614, 0.08615384615384614, 0.08615384615384614, 0.08615384615384614, 0.08615384615384614, 0.08615384615384614, 0.08615384615384614, 0.08615384615384614, 0.08615384615384614, 0.08615384615384614, 0.08615384615384614, 0.08615384615384614, 0.08615384615384614, 0.08615384615384614, 0.08615384615384614, 0.08615384615384614, 0.08615384615384614, 0.08615384615384614, 0.08615384615384614, 0.08615384615384614, 0.08846153846153848, 0.08615384615384614, 0.09615384615384615, 0.09615384615384615, 0.08769230769230774, 0.0953846153846154, 0.09999999999999998, 0.10076923076923072, 0.09999999999999998, 0.09615384615384615, 0.10615384615384615, 0.10076923076923072, 0.10230769230769232, 0.10384615384615381, 0.10153846153846158, 0.12615384615384617, 0.11076923076923073, 0.11384615384615382, 0.12923076923076926, 0.11615384615384616, 0.12307692307692308, 0.12846153846153852, 0.12846153846153852, 0.13461538461538458, 0.13769230769230767, 0.13615384615384618, 0.13384615384615384, 0.13461538461538458, 0.14769230769230768, 0.1430769230769231, 0.1446153846153846, 0.1461538461538462, 0.15230769230769226, 0.15692307692307694, 0.1530769230769231, 0.1561538461538462, 0.16692307692307695, 0.15538461538461534, 0.15692307692307694, 0.16538461538461535, 0.15923076923076918, 0.1661538461538462, 0.16846153846153844, 0.16307692307692312, 0.1761538461538461, 0.17307692307692313, 0.1792307692307692, 0.17538461538461536, 0.18153846153846154, 0.18999999999999995, 0.1892307692307692, 0.1892307692307692, 0.18307692307692303, 0.18846153846153846, 0.19153846153846155, 0.18846153846153846, 0.1923076923076923, 0.18999999999999995, 0.18999999999999995, 0.19461538461538463, 0.19538461538461538, 0.19846153846153847, 0.19307692307692303, 0.19153846153846155, 0.19846153846153847, 0.19615384615384612, 0.19307692307692303, 0.1992307692307692, 0.19615384615384612, 0.19538461538461538, 0.19615384615384612, 0.1938461538461539, 0.1938461538461539, 0.1938461538461539, 0.1923076923076923, 0.19538461538461538, 0.19615384615384612, 0.19538461538461538, 0.1992307692307692, 0.19307692307692303, 0.19615384615384612, 0.19307692307692303, 0.18461538461538463, 0.19307692307692303, 0.1876923076923077, 0.19153846153846155, 0.1876923076923077, 0.18692307692307697, 0.1907692307692308, 0.19538461538461538, 0.18999999999999995, 0.19307692307692303, 0.19461538461538463, 0.18999999999999995, 0.1876923076923077, 0.18230769230769228, 0.18999999999999995, 0.18538461538461537, 0.19307692307692303, 0.19846153846153847, 0.19461538461538463, 0.19153846153846155, 0.18846153846153846, 0.19846153846153847, 0.19538461538461538, 0.19153846153846155, 0.19769230769230772, 0.19461538461538463, 0.2007692307692308, 0.1992307692307692, 0.19692307692307698, 0.19153846153846155, 0.1923076923076923, 0.19846153846153847, 0.2007692307692308, 0.2038461538461539, 0.20153846153846156, 0.20307692307692304, 0.2038461538461539, 0.19615384615384612, 0.19769230769230772, 0.1992307692307692, 0.2038461538461539, 0.1992307692307692, 0.20307692307692304, 0.20769230769230773, 0.20461538461538464, 0.20153846153846156, 0.20461538461538464, 0.20615384615384613, 0.20615384615384613, 0.21076923076923082, 0.21307692307692305, 0.20846153846153848, 0.20846153846153848, 0.20999999999999996, 0.21307692307692305, 0.21307692307692305, 0.21692307692307689, 0.21615384615384614, 0.21461538461538465, 0.20999999999999996, 0.20692307692307688, 0.21153846153846156, 0.2123076923076923, 0.2138461538461538, 0.2138461538461538, 0.21307692307692305, 0.21461538461538465, 0.21615384615384614, 0.21769230769230774, 0.21461538461538465, 0.21846153846153848, 0.21076923076923082, 0.21461538461538465, 0.22230769230769232, 0.21923076923076923, 0.21999999999999997, 0.21615384615384614, 0.21923076923076923, 0.21923076923076923, 0.21153846153846156, 0.20923076923076922, 0.20846153846153848, 0.21692307692307689, 0.21307692307692305, 0.2138461538461538, 0.21692307692307689, 0.21615384615384614, 0.21076923076923082, 0.21769230769230774, 0.21461538461538465, 0.21923076923076923, 0.22230769230769232, 0.22615384615384615, 0.22153846153846157, 0.22923076923076924, 0.22461538461538466, 0.2269230769230769, 0.22461538461538466, 0.22307692307692306, 0.22230769230769232, 0.22230769230769232, 0.22153846153846157, 0.2284615384615385, 0.2253846153846154, 0.22615384615384615, 0.22769230769230764, 0.2269230769230769, 0.22923076923076924, 0.22615384615384615, 0.2269230769230769, 0.2238461538461538, 0.2238461538461538, 0.2253846153846154, 0.2284615384615385, 0.22615384615384615, 0.22769230769230764, 0.22615384615384615, 0.2253846153846154, 0.22461538461538466, 0.22307692307692306, 0.22230769230769232, 0.2253846153846154, 0.22923076923076924, 0.2253846153846154, 0.2269230769230769, 0.23076923076923073, 0.2284615384615385, 0.23230769230769233, 0.22923076923076924, 0.23076923076923073, 0.23538461538461541, 0.23538461538461541, 0.23076923076923073, 0.23230769230769233, 0.22999999999999998, 0.23076923076923073, 0.22769230769230764, 0.23230769230769233, 0.2253846153846154, 0.22615384615384615, 0.22615384615384615, 0.22461538461538466, 0.22307692307692306, 0.2238461538461538, 0.2269230769230769, 0.22999999999999998, 0.2269230769230769, 0.23307692307692307, 0.22461538461538466, 0.22230769230769232, 0.2238461538461538, 0.22307692307692306, 0.23153846153846158, 0.23153846153846158, 0.23384615384615381, 0.23153846153846158, 0.2284615384615385, 0.2238461538461538, 0.22999999999999998, 0.22999999999999998, 0.23384615384615381, 0.23461538461538467, 0.2284615384615385, 0.23384615384615381, 0.23230769230769233, 0.23076923076923073, 0.23076923076923073, 0.23307692307692307, 0.23307692307692307, 0.22923076923076924, 0.2284615384615385, 0.2253846153846154, 0.23230769230769233, 0.22999999999999998, 0.23076923076923073, 0.23153846153846158, 0.2284615384615385, 0.23538461538461541, 0.23230769230769233, 0.2284615384615385, 0.22923076923076924, 0.22769230769230764, 0.22923076923076924]

fine-tune momentum=0.5: slightly better (acc up to 0.26)
100 utt., 7 cont., DBN[585, 512, 512, 512, 42], 300 epochs, LR: 0.03, mom: 0.0, LR_decay: 0.99, L2: 0.0, [15, 15, 15, 15] pretr. epochs, LR_pretr: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.8984375, 0.89656250000000004, 0.90468749999999998, 0.89749999999999996, 0.88656250000000003, 0.89281250000000001, 0.88906249999999998, 0.90593749999999995, 0.89749999999999996, 0.90281250000000002, 0.90749999999999997, 0.88906249999999998, 0.89468749999999997, 0.89812499999999995, 0.90656250000000005, 0.89937500000000004, 0.91437500000000005, 0.89812499999999995, 0.89593750000000005, 0.895625, 0.89968749999999997, 0.90062500000000001, 0.89968749999999997, 0.89593750000000005, 0.89906249999999999, 0.90281250000000002, 0.90187499999999998, 0.89656250000000004, 0.90375000000000005, 0.89031249999999995, 0.90375000000000005, 0.8984375, 0.90093749999999995, 0.89000000000000001, 0.88906249999999998, 0.89718750000000003, 0.88218750000000001, 0.89937500000000004, 0.88875000000000004, 0.88124999999999998, 0.86468750000000005, 0.88531249999999995, 0.86312500000000003, 0.86156250000000001, 0.85624999999999996, 0.84562499999999996, 0.8565625, 0.84687500000000004, 0.86124999999999996, 0.85562499999999997, 0.8409375, 0.85343749999999996, 0.84468750000000004, 0.84562499999999996, 0.83281249999999996, 0.83875, 0.83468750000000003, 0.83937499999999998, 0.84218749999999998, 0.83656249999999999, 0.84468750000000004, 0.83750000000000002, 0.84406250000000005, 0.84062499999999996, 0.833125, 0.83218749999999997, 0.82999999999999996, 0.823125, 0.82437499999999997, 0.828125, 0.81843750000000004, 0.83374999999999999, 0.82281249999999995, 0.81656249999999997, 0.82687500000000003, 0.81968750000000001, 0.81906250000000003, 0.82125000000000004, 0.81374999999999997, 0.81687500000000002, 0.81625000000000003, 0.80625000000000002, 0.81156249999999996, 0.81281250000000005, 0.8253125, 0.80718749999999995, 0.80406250000000001, 0.80687500000000001, 0.7890625, 0.80374999999999996, 0.80031249999999998, 0.79000000000000004, 0.796875, 0.78468749999999998, 0.79781250000000004, 0.79249999999999998, 0.79156249999999995, 0.78343750000000001, 0.79562500000000003, 0.79531249999999998, 0.7784375, 0.79437500000000005, 0.78093749999999995, 0.78000000000000003, 0.78843750000000001, 0.78812499999999996, 0.77781250000000002, 0.77749999999999997, 0.76968749999999997, 0.78968749999999999, 0.78468749999999998, 0.77937500000000004, 0.78187499999999999, 0.77281250000000001, 0.77156250000000004, 0.77968749999999998, 0.7684375, 0.77375000000000005, 0.7628125, 0.77687499999999998, 0.77656250000000004, 0.76812499999999995, 0.78093749999999995, 0.77093750000000005, 0.77156250000000004, 0.77562500000000001, 0.77093750000000005, 0.76718750000000002, 0.7734375, 0.76593750000000005, 0.77000000000000002, 0.76187499999999997, 0.75687499999999996, 0.76593750000000005, 0.76875000000000004, 0.75718750000000001, 0.73281249999999998, 0.76656250000000004, 0.75656250000000003, 0.75687499999999996, 0.75875000000000004, 0.74531250000000004, 0.75187499999999996, 0.77093750000000005, 0.7471875, 0.74343749999999997, 0.74281249999999999, 0.75656250000000003, 0.734375, 0.73750000000000004, 0.74624999999999997, 0.73656250000000001, 0.72250000000000003, 0.729375, 0.72031250000000002, 0.72406250000000005, 0.72499999999999998, 0.71687500000000004, 0.73312500000000003, 0.71875, 0.72687500000000005, 0.72187500000000004, 0.72062499999999996, 0.72968750000000004, 0.71531250000000002, 0.71906250000000005, 0.7159375, 0.71812500000000001, 0.72031250000000002, 0.71781249999999996, 0.69593749999999999, 0.7109375, 0.72375, 0.7215625, 0.70343750000000005, 0.70125000000000004, 0.72406250000000005, 0.72312500000000002, 0.70937499999999998, 0.70968750000000003, 0.69968750000000002, 0.70093749999999999, 0.7109375, 0.70843750000000005, 0.70656249999999998, 0.69718749999999996, 0.69656249999999997, 0.70843750000000005, 0.70250000000000001, 0.69281250000000005, 0.68687500000000001, 0.6875, 0.69718749999999996, 0.6846875, 0.68218749999999995, 0.70468750000000002, 0.69499999999999995, 0.68812499999999999, 0.68625000000000003, 0.70062500000000005, 0.68593749999999998, 0.69687500000000002, 0.67656249999999996, 0.67749999999999999, 0.70125000000000004, 0.6903125, 0.69218749999999996, 0.6875, 0.69499999999999995, 0.6953125, 0.68999999999999995, 0.671875, 0.68593749999999998, 0.66625000000000001, 0.70874999999999999, 0.69093749999999998, 0.68687500000000001, 0.67906250000000001, 0.66125, 0.68656249999999996, 0.69312499999999999, 0.68093749999999997, 0.69437499999999996, 0.67812499999999998, 0.71187500000000004, 0.68906250000000002, 0.68656249999999996, 0.69156249999999997, 0.68281250000000004, 0.69468750000000001, 0.69312499999999999, 0.67656249999999996, 0.69750000000000001, 0.69343750000000004, 0.68999999999999995, 0.68625000000000003, 0.67031249999999998, 0.69187500000000002, 0.67437499999999995, 0.67937499999999995, 0.69593749999999999, 0.67062500000000003, 0.67249999999999999, 0.67531249999999998, 0.67812499999999998, 0.68531249999999999, 0.68687500000000001, 0.68125000000000002, 0.69218749999999996, 0.68999999999999995, 0.6825, 0.68000000000000005, 0.67625000000000002, 0.671875, 0.68406250000000002, 0.68093749999999997, 0.69343750000000004, 0.67749999999999999, 0.66718750000000004, 0.67843750000000003, 0.68781250000000005, 0.676875, 0.66937500000000005, 0.67937499999999995, 0.67812499999999998, 0.68656249999999996, 0.6825, 0.68281250000000004, 0.67125000000000001, 0.67937499999999995, 0.66781250000000003, 0.68562500000000004, 0.66874999999999996, 0.67218750000000005, 0.68031249999999999, 0.69437499999999996, 0.68093749999999997, 0.68187500000000001, 0.67781250000000004, 0.67843750000000003, 0.67000000000000004, 0.6953125, 0.67000000000000004, 0.68281250000000004, 0.68000000000000005, 0.66874999999999996, 0.67343750000000002, 0.66562500000000002, 0.68218749999999995, 0.67000000000000004, 0.67312499999999997, 0.6690625, 0.66093749999999996, 0.68343750000000003, 0.66031249999999997, 0.67062500000000003, 0.66500000000000004, 0.671875, 0.66843750000000002, 0.67625000000000002]
  valid.accur. [0.14479254868755287, 0.14479254868755287, 0.14479254868755287, 0.14479254868755287, 0.14479254868755287, 0.14479254868755287, 0.14479254868755287, 0.14479254868755287, 0.14479254868755287, 0.14479254868755287, 0.14479254868755287, 0.14479254868755287, 0.14479254868755287, 0.14479254868755287, 0.14479254868755287, 0.14479254868755287, 0.14479254868755287, 0.14479254868755287, 0.14479254868755287, 0.14479254868755287, 0.14479254868755287, 0.14479254868755287, 0.14479254868755287, 0.14479254868755287, 0.14479254868755287, 0.14479254868755287, 0.14479254868755287, 0.14479254868755287, 0.14479254868755287, 0.14479254868755287, 0.14479254868755287, 0.14479254868755287, 0.14817950889077058, 0.1456392887383573, 0.14479254868755287, 0.15410668924640136, 0.14479254868755287, 0.14987298899237933, 0.14479254868755287, 0.16934801016088064, 0.16342082980524975, 0.1549534292972058, 0.17866215071972902, 0.19813717188823032, 0.2040643522438611, 0.1718882303132938, 0.20152413209144793, 0.19559695173581715, 0.2040643522438611, 0.20575783234546996, 0.19136325148179512, 0.20321761219305678, 0.21253175275190517, 0.209991532599492, 0.20237087214225236, 0.20491109229466553, 0.2066045723962744, 0.20829805249788313, 0.20321761219305678, 0.2074513124470787, 0.20321761219305678, 0.21168501270110074, 0.21930567315834038, 0.2133784928027096, 0.21845893310753595, 0.21507197290431834, 0.21507197290431834, 0.21422523285351402, 0.21422523285351402, 0.21507197290431834, 0.21507197290431834, 0.21845893310753595, 0.21253175275190517, 0.21422523285351402, 0.22777307366638444, 0.2294665537679932, 0.2294665537679932, 0.22777307366638444, 0.21930567315834038, 0.2294665537679932, 0.22861981371718887, 0.22777307366638444, 0.22523285351397127, 0.22184589331075355, 0.23031329381879762, 0.2294665537679932, 0.22777307366638444, 0.21253175275190517, 0.22269263336155798, 0.2201524132091448, 0.22438611346316684, 0.22861981371718887, 0.22438611346316684, 0.23454699407281965, 0.23116003386960204, 0.23454699407281965, 0.23793395427603725, 0.22777307366638444, 0.22861981371718887, 0.22607959356477558, 0.22184589331075355, 0.23031329381879762, 0.22184589331075355, 0.2294665537679932, 0.2328535139712108, 0.23370025402201522, 0.2430143945808637, 0.23708721422523282, 0.23454699407281965, 0.23200677392040647, 0.23370025402201522, 0.23539373412362408, 0.23539373412362408, 0.24132091447925486, 0.24132091447925486, 0.23708721422523282, 0.22692633361558, 0.22861981371718887, 0.24047417442845043, 0.23370025402201522, 0.24132091447925486, 0.2362404741744285, 0.24132091447925486, 0.24386113463166803, 0.23370025402201522, 0.23878069432684168, 0.24386113463166803, 0.24386113463166803, 0.24724809483488575, 0.24978831498729892, 0.25486875529212527, 0.2455546147332769, 0.2531752751905165, 0.2557154953429297, 0.24470787468247246, 0.23878069432684168, 0.24978831498729892, 0.2531752751905165, 0.25063505503810335, 0.2531752751905165, 0.2455546147332769, 0.24470787468247246, 0.24047417442845043, 0.2523285351397121, 0.24809483488569006, 0.23878069432684168, 0.24386113463166803, 0.24216765453005928, 0.24216765453005928, 0.24640135478408132, 0.24724809483488575, 0.25740897544453856, 0.25148179508890767, 0.2489415749364945, 0.24640135478408132, 0.24470787468247246, 0.24132091447925486, 0.24470787468247246, 0.2489415749364945, 0.24386113463166803, 0.2455546147332769, 0.2489415749364945, 0.2489415749364945, 0.24640135478408132, 0.24386113463166803, 0.24640135478408132, 0.24470787468247246, 0.24386113463166803, 0.24386113463166803, 0.2430143945808637, 0.24470787468247246, 0.24640135478408132, 0.24724809483488575, 0.24470787468247246, 0.24809483488569006, 0.24470787468247246, 0.2455546147332769, 0.24640135478408132, 0.24640135478408132, 0.2455546147332769, 0.2455546147332769, 0.2489415749364945, 0.25063505503810335, 0.24640135478408132, 0.24724809483488575, 0.24724809483488575, 0.24978831498729892, 0.24724809483488575, 0.24809483488569006, 0.25402201524132095, 0.2523285351397121, 0.2523285351397121, 0.2523285351397121, 0.2489415749364945, 0.25063505503810335, 0.24470787468247246, 0.24640135478408132, 0.24640135478408132, 0.25402201524132095, 0.25148179508890767, 0.25402201524132095, 0.25402201524132095, 0.2616426756985606, 0.25994919559695173, 0.2582557154953429, 0.25486875529212527, 0.2591024555461473, 0.2557154953429297, 0.25486875529212527, 0.24724809483488575, 0.24809483488569006, 0.25148179508890767, 0.25656223539373413, 0.2624894157493649, 0.2531752751905165, 0.25486875529212527, 0.25656223539373413, 0.25656223539373413, 0.2616426756985606, 0.2624894157493649, 0.2624894157493649, 0.2582557154953429, 0.25486875529212527, 0.25486875529212527, 0.2523285351397121, 0.24978831498729892, 0.25148179508890767, 0.2531752751905165, 0.2523285351397121, 0.2455546147332769, 0.24724809483488575, 0.25063505503810335, 0.24809483488569006, 0.2531752751905165, 0.2557154953429297, 0.2557154953429297, 0.26079593564775616, 0.2531752751905165, 0.2523285351397121, 0.25994919559695173, 0.2591024555461473, 0.25740897544453856, 0.25994919559695173, 0.2616426756985606, 0.25486875529212527, 0.25656223539373413, 0.25656223539373413, 0.25486875529212527, 0.25402201524132095, 0.25740897544453856, 0.25994919559695173, 0.2582557154953429, 0.2624894157493649, 0.2624894157493649, 0.25656223539373413, 0.26079593564775616, 0.26079593564775616, 0.2591024555461473, 0.2624894157493649, 0.2591024555461473, 0.2582557154953429, 0.25402201524132095, 0.26079593564775616, 0.25740897544453856, 0.2582557154953429, 0.25486875529212527, 0.25740897544453856, 0.2582557154953429, 0.25740897544453856, 0.25486875529212527, 0.2591024555461473, 0.2582557154953429, 0.2557154953429297, 0.2531752751905165, 0.25486875529212527, 0.25486875529212527, 0.25486875529212527, 0.2582557154953429, 0.2591024555461473, 0.25656223539373413, 0.2557154953429297, 0.25486875529212527, 0.2523285351397121, 0.25402201524132095, 0.2523285351397121, 0.2531752751905165, 0.25486875529212527, 0.2557154953429297, 0.25740897544453856, 0.2557154953429297, 0.25740897544453856, 0.25656223539373413, 0.25656223539373413, 0.25740897544453856, 0.25486875529212527, 0.2582557154953429, 0.2582557154953429, 0.2582557154953429, 0.2582557154953429, 0.25656223539373413]

both momentum=0.5: starts to learn later, after 80 epochs (acc up to 0.17)
higher LR=0.1: learns immediately, overfits (acc up to 0.24)

previous LR=0.03, LR_decay=1.0: (acc up to 0.24)
100 utt., 7 cont., DBN[585, 512, 512, 512, 42], 300 epochs, LR: 0.03, mom: 0.0, LR_decay: 1.0, L2: 0.0, [15, 15, 15, 15] pretr. epochs, LR_pretr: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.8720703125, 0.857421875, 0.87337239583333337, 0.86393229166666663, 0.85904947916666663, 0.8544921875, 0.8583984375, 0.8623046875, 0.8662109375, 0.87076822916666663, 0.85872395833333337, 0.8642578125, 0.84765625, 0.85807291666666663, 0.85286458333333337, 0.86002604166666663, 0.86067708333333337, 0.85579427083333337, 0.86588541666666663, 0.85872395833333337, 0.85677083333333337, 0.85188802083333337, 0.86848958333333337, 0.85546875, 0.85904947916666663, 0.857421875, 0.86881510416666663, 0.85872395833333337, 0.85904947916666663, 0.8642578125, 0.84537760416666663, 0.857421875, 0.85481770833333337, 0.84407552083333337, 0.83821614583333337, 0.83235677083333337, 0.84375, 0.84700520833333337, 0.83756510416666663, 0.8447265625, 0.830078125, 0.826171875, 0.8310546875, 0.822265625, 0.82486979166666663, 0.81217447916666663, 0.8232421875, 0.78743489583333337, 0.80826822916666663, 0.7880859375, 0.7900390625, 0.78743489583333337, 0.7861328125, 0.78873697916666663, 0.79361979166666663, 0.77376302083333337, 0.755859375, 0.76985677083333337, 0.77213541666666663, 0.75032552083333337, 0.763671875, 0.76627604166666663, 0.77408854166666663, 0.74609375, 0.75846354166666663, 0.74479166666666663, 0.75065104166666663, 0.74576822916666663, 0.751953125, 0.73600260416666663, 0.75358072916666663, 0.72395833333333337, 0.74674479166666663, 0.73079427083333337, 0.72493489583333337, 0.74055989583333337, 0.7236328125, 0.71744791666666663, 0.71223958333333337, 0.7080078125, 0.7099609375, 0.71419270833333337, 0.70345052083333337, 0.703125, 0.7216796875, 0.70703125, 0.71516927083333337, 0.69270833333333337, 0.68359375, 0.68131510416666663, 0.70052083333333337, 0.68912760416666663, 0.6953125, 0.6904296875, 0.68229166666666663, 0.67643229166666663, 0.67220052083333337, 0.65885416666666663, 0.67578125, 0.67838541666666663, 0.66764322916666663, 0.66796875, 0.654296875, 0.64876302083333337, 0.65983072916666663, 0.65104166666666663, 0.65071614583333337, 0.66536458333333337, 0.6435546875, 0.64029947916666663, 0.64453125, 0.64485677083333337, 0.626953125, 0.62044270833333337, 0.615234375, 0.63541666666666663, 0.6181640625, 0.62239583333333337, 0.6240234375, 0.62467447916666663, 0.61783854166666663, 0.6171875, 0.61686197916666663, 0.59993489583333337, 0.6181640625, 0.61783854166666663, 0.62890625, 0.603515625, 0.59895833333333337, 0.58235677083333337, 0.60709635416666663, 0.58951822916666663, 0.59244791666666663, 0.56770833333333337, 0.607421875, 0.591796875, 0.59993489583333337, 0.607421875, 0.5927734375, 0.58626302083333337, 0.580078125, 0.60221354166666663, 0.58821614583333337, 0.57259114583333337, 0.5849609375, 0.56673177083333337, 0.59147135416666663, 0.56868489583333337, 0.58072916666666663, 0.57649739583333337, 0.587890625, 0.572265625, 0.5615234375, 0.56119791666666663, 0.5615234375, 0.55794270833333337, 0.55013020833333337, 0.5498046875, 0.5478515625, 0.560546875, 0.544921875, 0.53190104166666663, 0.54720052083333337, 0.53743489583333337, 0.53092447916666663, 0.53157552083333337, 0.54427083333333337, 0.53776041666666663, 0.52213541666666663, 0.52213541666666663, 0.5400390625, 0.5244140625, 0.52473958333333337, 0.50520833333333337, 0.52083333333333337, 0.49967447916666669, 0.51432291666666663, 0.51920572916666663, 0.50162760416666663, 0.515625, 0.51432291666666663, 0.50846354166666663, 0.5078125, 0.49934895833333331, 0.5126953125, 0.490234375, 0.494140625, 0.50260416666666663, 0.50065104166666663, 0.49479166666666669, 0.48893229166666669, 0.4912109375, 0.48209635416666669, 0.48795572916666669, 0.48307291666666669, 0.48404947916666669, 0.48828125, 0.4501953125, 0.45768229166666669, 0.46842447916666669, 0.48209635416666669, 0.46744791666666669, 0.470703125, 0.470703125, 0.4423828125, 0.45345052083333331, 0.443359375, 0.44759114583333331, 0.44075520833333331, 0.4384765625, 0.44173177083333331, 0.447265625, 0.42578125, 0.42024739583333331, 0.42220052083333331, 0.43294270833333331, 0.416015625, 0.42415364583333331, 0.42740885416666669, 0.42447916666666669, 0.427734375, 0.4111328125, 0.40462239583333331, 0.39388020833333331, 0.4013671875, 0.400390625, 0.39583333333333331, 0.396484375, 0.3974609375, 0.38020833333333331, 0.3837890625, 0.38248697916666669, 0.376953125, 0.37923177083333331, 0.37467447916666669, 0.38118489583333331, 0.36067708333333331, 0.37369791666666669, 0.3603515625, 0.36263020833333331, 0.369140625, 0.3427734375, 0.37467447916666669, 0.35416666666666669, 0.3369140625, 0.37239583333333331, 0.36197916666666669, 0.3515625, 0.34505208333333331, 0.34928385416666669, 0.33138020833333331, 0.33333333333333331, 0.34016927083333331, 0.31868489583333331, 0.33463541666666669, 0.3193359375, 0.32259114583333331, 0.31966145833333331, 0.3212890625, 0.33170572916666669, 0.30143229166666669, 0.3115234375, 0.30794270833333331, 0.30501302083333331, 0.30859375, 0.31380208333333331, 0.29947916666666669, 0.2861328125, 0.279296875, 0.310546875, 0.28125, 0.28938802083333331, 0.25813802083333331, 0.27897135416666669, 0.26888020833333331, 0.2685546875, 0.27734375, 0.28125, 0.28352864583333331, 0.26790364583333331, 0.2880859375, 0.25227864583333331, 0.25130208333333331, 0.2451171875, 0.2412109375, 0.26041666666666669, 0.22721354166666666, 0.2421875, 0.26106770833333331, 0.24576822916666666, 0.25911458333333331, 0.220703125, 0.244140625, 0.2119140625, 0.25162760416666669, 0.20768229166666666, 0.22200520833333334, 0.2197265625, 0.19921875, 0.21940104166666666]
  valid.accur. [0.04475308641975306, 0.04475308641975306, 0.04475308641975306, 0.04475308641975306, 0.04475308641975306, 0.04475308641975306, 0.04475308641975306, 0.04475308641975306, 0.04475308641975306, 0.04475308641975306, 0.04475308641975306, 0.04475308641975306, 0.04475308641975306, 0.04475308641975306, 0.04475308641975306, 0.04475308641975306, 0.04475308641975306, 0.04475308641975306, 0.04475308641975306, 0.04475308641975306, 0.04475308641975306, 0.04475308641975306, 0.04475308641975306, 0.04475308641975306, 0.04475308641975306, 0.04475308641975306, 0.047067901234567944, 0.04475308641975306, 0.04475308641975306, 0.054012345679012363, 0.04475308641975306, 0.04552469135802473, 0.047067901234567944, 0.06172839506172845, 0.06172839506172845, 0.04629629629629628, 0.0570987654320988, 0.07561728395061729, 0.06327160493827155, 0.07561728395061729, 0.07253086419753085, 0.0864197530864198, 0.09336419753086422, 0.08564814814814814, 0.09259259259259256, 0.10416666666666663, 0.12037037037037035, 0.1304012345679012, 0.12808641975308643, 0.12268518518518523, 0.13503086419753085, 0.13503086419753085, 0.12654320987654322, 0.13348765432098764, 0.13580246913580252, 0.1304012345679012, 0.13580246913580252, 0.13888888888888884, 0.13657407407407407, 0.13580246913580252, 0.14120370370370372, 0.14120370370370372, 0.13657407407407407, 0.13503086419753085, 0.13888888888888884, 0.13888888888888884, 0.15200617283950613, 0.14197530864197527, 0.13734567901234573, 0.1396604938271605, 0.14429012345679015, 0.14120370370370372, 0.1527777777777778, 0.14969135802469136, 0.158179012345679, 0.15509259259259256, 0.15586419753086422, 0.15586419753086422, 0.1728395061728395, 0.17129629629629628, 0.17052469135802473, 0.1782407407407407, 0.17361111111111116, 0.18132716049382713, 0.17746913580246915, 0.18441358024691357, 0.17901234567901236, 0.18132716049382713, 0.1820987654320988, 0.17592592592592593, 0.1875, 0.17746913580246915, 0.17978395061728392, 0.18441358024691357, 0.18672839506172845, 0.17361111111111116, 0.1875, 0.1743827160493827, 0.18132716049382713, 0.18518518518518523, 0.18827160493827155, 0.1875, 0.18827160493827155, 0.17901234567901236, 0.183641975308642, 0.19444444444444442, 0.2021604938271605, 0.1967592592592593, 0.2021604938271605, 0.19907407407407407, 0.20833333333333337, 0.2021604938271605, 0.20447530864197527, 0.19753086419753085, 0.20524691358024694, 0.20447530864197527, 0.20679012345679015, 0.2060185185185185, 0.21064814814814814, 0.21219135802469136, 0.21373456790123457, 0.19984567901234573, 0.21759259259259256, 0.2152777777777778, 0.21219135802469136, 0.2006172839506173, 0.216820987654321, 0.2098765432098766, 0.21990740740740744, 0.20679012345679015, 0.220679012345679, 0.21373456790123457, 0.2260802469135802, 0.22145061728395066, 0.2299382716049383, 0.22145061728395066, 0.21836419753086422, 0.220679012345679, 0.2260802469135802, 0.2276234567901234, 0.22916666666666663, 0.2276234567901234, 0.22685185185185186, 0.2260802469135802, 0.220679012345679, 0.2260802469135802, 0.2245370370370371, 0.22685185185185186, 0.220679012345679, 0.22916666666666663, 0.21990740740740744, 0.22299382716049387, 0.2222222222222222, 0.2260802469135802, 0.21913580246913578, 0.2114197530864198, 0.22530864197530864, 0.22145061728395066, 0.21450617283950613, 0.22839506172839508, 0.22299382716049387, 0.21604938271604934, 0.21759259259259256, 0.2260802469135802, 0.21990740740740744, 0.22530864197530864, 0.2222222222222222, 0.21604938271604934, 0.22299382716049387, 0.22299382716049387, 0.22376543209876543, 0.2276234567901234, 0.2245370370370371, 0.22145061728395066, 0.21990740740740744, 0.22299382716049387, 0.22530864197530864, 0.23302469135802473, 0.22145061728395066, 0.2245370370370371, 0.2260802469135802, 0.22299382716049387, 0.2353395061728395, 0.2222222222222222, 0.21373456790123457, 0.23456790123456794, 0.2276234567901234, 0.22299382716049387, 0.23302469135802473, 0.22685185185185186, 0.21759259259259256, 0.22376543209876543, 0.220679012345679, 0.23070987654320985, 0.2260802469135802, 0.2353395061728395, 0.22916666666666663, 0.23302469135802473, 0.2314814814814815, 0.22685185185185186, 0.220679012345679, 0.23225308641975306, 0.23225308641975306, 0.22530864197530864, 0.22839506172839508, 0.23070987654320985, 0.21990740740740744, 0.220679012345679, 0.23225308641975306, 0.2276234567901234, 0.2314814814814815, 0.2299382716049383, 0.22376543209876543, 0.23765432098765427, 0.2353395061728395, 0.2299382716049383, 0.23302469135802473, 0.22916666666666663, 0.22299382716049387, 0.23379629629629628, 0.23225308641975306, 0.2222222222222222, 0.23070987654320985, 0.21990740740740744, 0.2299382716049383, 0.22145061728395066, 0.22299382716049387, 0.2260802469135802, 0.2353395061728395, 0.24537037037037035, 0.2353395061728395, 0.23070987654320985, 0.2353395061728395, 0.2353395061728395, 0.2299382716049383, 0.22376543209876543, 0.23919753086419748, 0.21604938271604934, 0.22299382716049387, 0.22916666666666663, 0.23379629629629628, 0.21759259259259256, 0.22839506172839508, 0.2245370370370371, 0.1820987654320988, 0.23302469135802473, 0.21836419753086422, 0.20833333333333337, 0.2245370370370371, 0.21219135802469136, 0.2114197530864198, 0.23611111111111116, 0.22916666666666663, 0.2098765432098766, 0.2114197530864198, 0.21836419753086422, 0.2222222222222222, 0.2129629629629629, 0.2021604938271605, 0.20447530864197527, 0.21990740740740744, 0.21913580246913578, 0.2114197530864198, 0.2075617283950617, 0.21759259259259256, 0.21990740740740744, 0.21990740740740744, 0.22685185185185186, 0.21836419753086422, 0.21604938271604934, 0.22299382716049387, 0.21450617283950613, 0.21759259259259256, 0.2075617283950617, 0.2114197530864198, 0.2152777777777778, 0.2114197530864198, 0.21373456790123457, 0.20910493827160492, 0.21759259259259256, 0.2114197530864198, 0.21064814814814814, 0.2060185185185185, 0.2114197530864198, 0.22145061728395066, 0.20524691358024694, 0.216820987654321, 0.21373456790123457, 0.21990740740740744, 0.2129629629629629, 0.2098765432098766, 0.20679012345679015, 0.216820987654321, 0.2075617283950617, 0.2021604938271605, 0.20679012345679015, 0.20447530864197527, 0.20833333333333337, 0.20447530864197527, 0.20679012345679015]


n_epochs_pretrain=15:  (acc up to 0.24)
100 utt., 7 cont., DBN[585, 512, 512, 512, 42], 300 epochs, LR: 0.03, mom: 0.5, LR_decay: 1.0, L2: 0.0, [15, 15, 15, 15] pretr. epochs, LR_pretr: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.89876302083333337, 0.8837890625, 0.884765625, 0.89225260416666663, 0.89192708333333337, 0.89127604166666663, 0.88932291666666663, 0.88932291666666663, 0.8984375, 0.896484375, 0.88053385416666663, 0.88118489583333337, 0.880859375, 0.87630208333333337, 0.87858072916666663, 0.86946614583333337, 0.88248697916666663, 0.84407552083333337, 0.84147135416666663, 0.83040364583333337, 0.830078125, 0.83170572916666663, 0.81217447916666663, 0.818359375, 0.80013020833333337, 0.7958984375, 0.8056640625, 0.787109375, 0.77897135416666663, 0.77994791666666663, 0.75911458333333337, 0.76953125, 0.77115885416666663, 0.76139322916666663, 0.75846354166666663, 0.74186197916666663, 0.72526041666666663, 0.73307291666666663, 0.73307291666666663, 0.74641927083333337, 0.71419270833333337, 0.70735677083333337, 0.71158854166666663, 0.69108072916666663, 0.69368489583333337, 0.67740885416666663, 0.67415364583333337, 0.68684895833333337, 0.67708333333333337, 0.64778645833333337, 0.67057291666666663, 0.65169270833333337, 0.64876302083333337, 0.65006510416666663, 0.634765625, 0.62825520833333337, 0.63346354166666663, 0.63606770833333337, 0.61002604166666663, 0.62076822916666663, 0.62239583333333337, 0.60286458333333337, 0.595703125, 0.58333333333333337, 0.57779947916666663, 0.59016927083333337, 0.568359375, 0.580078125, 0.58040364583333337, 0.56510416666666663, 0.56770833333333337, 0.56608072916666663, 0.5634765625, 0.5537109375, 0.552734375, 0.556640625, 0.55598958333333337, 0.54915364583333337, 0.5263671875, 0.5283203125, 0.5263671875, 0.51692708333333337, 0.52897135416666663, 0.51302083333333337, 0.52311197916666663, 0.50846354166666663, 0.50651041666666663, 0.5009765625, 0.48404947916666669, 0.4970703125, 0.49055989583333331, 0.451171875, 0.46419270833333331, 0.45768229166666669, 0.47037760416666669, 0.44856770833333331, 0.44563802083333331, 0.44889322916666669, 0.43098958333333331, 0.42447916666666669, 0.43229166666666669, 0.42513020833333331, 0.416015625, 0.40559895833333331, 0.40234375, 0.39973958333333331, 0.390625, 0.38509114583333331, 0.3671875, 0.37825520833333331, 0.36979166666666669, 0.35970052083333331, 0.36295572916666669, 0.35774739583333331, 0.35546875, 0.35709635416666669, 0.34212239583333331, 0.33138020833333331, 0.34342447916666669, 0.34309895833333331, 0.31803385416666669, 0.33723958333333331, 0.3173828125, 0.31575520833333331, 0.31119791666666669, 0.31022135416666669, 0.310546875, 0.2724609375, 0.3017578125, 0.27994791666666669, 0.27408854166666669, 0.27311197916666669, 0.251953125, 0.26171875, 0.27864583333333331, 0.26009114583333331, 0.21875, 0.265625, 0.2255859375, 0.24283854166666666, 0.24153645833333334, 0.22786458333333334, 0.21809895833333334, 0.2138671875, 0.21256510416666666, 0.20182291666666666, 0.19368489583333334, 0.20572916666666666, 0.17903645833333334, 0.19368489583333334, 0.18131510416666666, 0.19498697916666666, 0.1787109375, 0.17220052083333334, 0.1767578125, 0.15625, 0.15169270833333334, 0.15364583333333334, 0.1513671875, 0.15201822916666666, 0.15950520833333334, 0.1474609375, 0.13444010416666666, 0.13151041666666666, 0.13411458333333334, 0.13899739583333334, 0.11458333333333333, 0.115234375, 0.1171875, 0.1240234375, 0.12662760416666666, 0.10026041666666667, 0.092122395833333329, 0.091471354166666671, 0.0986328125, 0.096354166666666671, 0.0927734375, 0.10709635416666667, 0.080078125, 0.080078125, 0.071614583333333329, 0.080403645833333329, 0.0966796875, 0.0732421875, 0.061197916666666664, 0.064453125, 0.0615234375, 0.055013020833333336, 0.0546875, 0.078125, 0.047526041666666664, 0.0458984375, 0.05078125, 0.055013020833333336, 0.048502604166666664, 0.14453125, 0.051106770833333336, 0.039388020833333336, 0.033528645833333336, 0.033203125, 0.037760416666666664, 0.038736979166666664, 0.034505208333333336, 0.032552083333333336, 0.030924479166666668, 0.025390625, 0.0244140625, 0.018880208333333332, 0.021809895833333332, 0.0224609375, 0.017252604166666668, 0.021484375, 0.019205729166666668, 0.046223958333333336, 0.016276041666666668, 0.017252604166666668, 0.021158854166666668, 0.014322916666666666, 0.011393229166666666, 0.014322916666666666, 0.010416666666666666, 0.011067708333333334, 0.011067708333333334, 0.010416666666666666, 0.013020833333333334, 0.0081380208333333339, 0.0094401041666666661, 0.0078125, 0.0084635416666666661, 0.0048828125, 0.0107421875, 0.005533854166666667, 0.006510416666666667, 0.0084635416666666661, 0.006510416666666667, 0.0081380208333333339, 0.0029296875, 0.005859375, 0.0048828125, 0.0091145833333333339, 0.005533854166666667, 0.0087890625, 0.0048828125, 0.00390625, 0.005533854166666667, 0.001953125, 0.0026041666666666665, 0.00390625, 0.004231770833333333, 0.0029296875, 0.00390625, 0.0026041666666666665, 0.00390625, 0.0032552083333333335, 0.0032552083333333335, 0.0032552083333333335, 0.0032552083333333335, 0.001953125, 0.0026041666666666665, 0.001953125, 0.0016276041666666667, 0.001953125, 0.0029296875, 0.0013020833333333333, 0.0029296875, 0.0022786458333333335, 0.00065104166666666663, 0.0016276041666666667, 0.0016276041666666667, 0.00032552083333333332, 0.0013020833333333333, 0.00065104166666666663, 0.00032552083333333332, 0.0009765625, 0.00032552083333333332, 0.0013020833333333333, 0.0, 0.00065104166666666663, 0.0013020833333333333, 0.00065104166666666663, 0.00032552083333333332, 0.00065104166666666663, 0.00032552083333333332, 0.0009765625, 0.00032552083333333332, 0.0009765625, 0.00065104166666666663, 0.00032552083333333332, 0.0, 0.0, 0.0, 0.0, 0.0, 0.00032552083333333332, 0.0, 0.00032552083333333332, 0.00032552083333333332, 0.0, 0.0, 0.0]
  valid.accur. [0.12547241118669694, 0.12169312169312174, 0.11866969009826156, 0.11866969009826156, 0.11866969009826156, 0.11866969009826156, 0.11866969009826156, 0.11866969009826156, 0.11866969009826156, 0.11866969009826156, 0.1201814058956916, 0.11866969009826156, 0.14361300075585792, 0.11942554799697658, 0.1315192743764172, 0.11942554799697658, 0.13378684807256236, 0.13378684807256236, 0.14210128495842778, 0.1315192743764172, 0.13378684807256236, 0.15721844293272869, 0.17838246409674985, 0.18367346938775508, 0.19727891156462585, 0.19349962207105065, 0.1844293272864701, 0.2033257747543462, 0.19803476946334087, 0.19727891156462585, 0.20408163265306123, 0.18896447467876043, 0.18669690098261527, 0.19274376417233563, 0.19274376417233563, 0.20786092214663643, 0.19803476946334087, 0.19652305366591083, 0.20786092214663643, 0.20483749055177625, 0.2146636432350718, 0.21315192743764177, 0.20786092214663643, 0.2146636432350718, 0.2101284958427816, 0.20483749055177625, 0.22297808012093723, 0.22751322751322756, 0.22297808012093723, 0.23204837490551777, 0.22751322751322756, 0.23960695389266817, 0.21995464852607705, 0.22297808012093723, 0.23129251700680276, 0.22373393801965236, 0.23053665910808763, 0.22071050642479217, 0.2297808012093726, 0.2290249433106576, 0.2214663643235072, 0.22448979591836737, 0.218442932728647, 0.2146636432350718, 0.21315192743764177, 0.22071050642479217, 0.21164021164021163, 0.22297808012093723, 0.23129251700680276, 0.2101284958427816, 0.21239606953892665, 0.2108843537414966, 0.21617535903250185, 0.2222222222222222, 0.23129251700680276, 0.2139077853363568, 0.20408163265306123, 0.20786092214663643, 0.20030234315948603, 0.218442932728647, 0.23053665910808763, 0.21995464852607705, 0.22373393801965236, 0.20937263794406646, 0.22448979591836737, 0.2214663643235072, 0.20105820105820105, 0.22373393801965236, 0.21995464852607705, 0.2108843537414966, 0.21919879062736203, 0.2108843537414966, 0.20861678004535145, 0.23053665910808763, 0.2025699168556312, 0.20937263794406646, 0.23204837490551777, 0.22751322751322756, 0.2063492063492064, 0.2108843537414966, 0.21239606953892665, 0.20937263794406646, 0.20483749055177625, 0.217687074829932, 0.20559334845049126, 0.22071050642479217, 0.237339380196523, 0.2146636432350718, 0.21164021164021163, 0.20105820105820105, 0.2063492063492064, 0.2108843537414966, 0.20483749055177625, 0.20786092214663643, 0.2146636432350718, 0.2108843537414966, 0.2033257747543462, 0.2071050642479214, 0.20483749055177625, 0.19349962207105065, 0.2025699168556312, 0.20105820105820105, 0.20559334845049126, 0.20105820105820105, 0.2025699168556312, 0.199546485260771, 0.19879062736205588, 0.21315192743764177, 0.2108843537414966, 0.19727891156462585, 0.20181405895691606, 0.199546485260771, 0.20181405895691606, 0.19425547996976567, 0.1844293272864701, 0.20030234315948603, 0.1957671957671958, 0.18140589569161003, 0.18745275888133028, 0.18669690098261527, 0.19501133786848068, 0.18745275888133028, 0.18216175359032505, 0.19803476946334087, 0.2025699168556312, 0.2063492063492064, 0.1919879062736206, 0.19879062736205588, 0.19047619047619047, 0.18216175359032505, 0.19349962207105065, 0.19274376417233563, 0.19349962207105065, 0.19349962207105065, 0.18140589569161003, 0.18518518518518523, 0.19123204837490548, 0.18669690098261527, 0.18896447467876043, 0.18594104308390025, 0.18291761148904007, 0.18367346938775508, 0.17762660619803472, 0.19123204837490548, 0.18972033257747545, 0.17082388510959945, 0.1844293272864701, 0.17989417989417988, 0.16704459561602414, 0.18291761148904007, 0.19047619047619047, 0.18291761148904007, 0.16250944822373392, 0.1806500377928949, 0.17838246409674985, 0.17384731670445952, 0.17384731670445952, 0.1655328798185941, 0.17006802721088432, 0.17762660619803472, 0.17384731670445952, 0.17233560090702948, 0.16780045351473927, 0.17157974300831447, 0.18367346938775508, 0.17384731670445952, 0.17233560090702948, 0.1730914588057445, 0.1617535903250189, 0.16477702191987909, 0.16855631141345429, 0.17233560090702948, 0.16099773242630389, 0.16477702191987909, 0.16099773242630389, 0.17838246409674985, 0.17157974300831447, 0.16855631141345429, 0.17006802721088432, 0.1730914588057445, 0.15873015873015872, 0.16780045351473927, 0.16402116402116407, 0.15873015873015872, 0.16402116402116407, 0.16099773242630389, 0.16477702191987909, 0.1655328798185941, 0.16024187452758887, 0.1579743008314437, 0.15721844293272869, 0.1617535903250189, 0.16855631141345429, 0.1617535903250189, 0.16402116402116407, 0.16099773242630389, 0.1655328798185941, 0.1655328798185941, 0.16704459561602414, 0.16780045351473927, 0.16780045351473927, 0.17384731670445952, 0.1693121693121693, 0.17611489040060468, 0.16477702191987909, 0.16855631141345429, 0.16250944822373392, 0.16326530612244894, 0.1655328798185941, 0.16477702191987909, 0.16250944822373392, 0.1617535903250189, 0.16326530612244894, 0.16402116402116407, 0.1655328798185941, 0.16780045351473927, 0.16099773242630389, 0.16704459561602414, 0.16704459561602414, 0.16326530612244894, 0.16704459561602414, 0.16704459561602414, 0.17006802721088432, 0.1655328798185941, 0.1655328798185941, 0.16855631141345429, 0.1693121693121693, 0.16477702191987909, 0.16250944822373392, 0.16402116402116407, 0.16099773242630389, 0.1617535903250189, 0.16099773242630389, 0.16402116402116407, 0.15873015873015872, 0.16402116402116407, 0.16628873771730912, 0.16477702191987909, 0.1579743008314437, 0.16704459561602414, 0.16477702191987909, 0.16402116402116407, 0.16628873771730912, 0.1579743008314437, 0.16024187452758887, 0.1655328798185941, 0.16780045351473927, 0.16477702191987909, 0.16250944822373392, 0.16402116402116407, 0.16477702191987909, 0.16250944822373392, 0.16402116402116407, 0.16326530612244894, 0.1617535903250189, 0.16402116402116407, 0.1655328798185941, 0.16477702191987909, 0.1617535903250189, 0.15948601662887374, 0.16099773242630389, 0.16477702191987909, 0.1617535903250189, 0.1655328798185941, 0.16024187452758887, 0.1617535903250189, 0.16250944822373392, 0.1617535903250189, 0.1655328798185941, 0.1655328798185941, 0.16099773242630389, 0.16402116402116407, 0.1693121693121693, 0.1617535903250189, 0.16628873771730912, 0.16402116402116407, 0.16250944822373392, 0.16402116402116407, 0.16704459561602414, 0.16628873771730912]

on 300 utt.: (acc up to 0.28 at 45)

n_epochs_pretrain=45: (acc up to 0.22 at 64)
100 utt., 7 cont., DBN[585, 512, 512, 512, 42], 300 epochs, LR: 0.03, mom: 0.5, LR_decay: 1.0, L2: 0.0, [45, 45, 45, 45] pretr. epochs, LR_pretr: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.90589488636363635, 0.90056818181818177, 0.88707386363636365, 0.89133522727272729, 0.90376420454545459, 0.90198863636363635, 0.88991477272727271, 0.89346590909090906, 0.88600852272727271, 0.90056818181818177, 0.89417613636363635, 0.88849431818181823, 0.89559659090909094, 0.89346590909090906, 0.88636363636363635, 0.89311079545454541, 0.89453125, 0.89630681818181823, 0.90625, 0.89382102272727271, 0.87819602272727271, 0.89240056818181823, 0.89666193181818177, 0.89275568181818177, 0.88849431818181823, 0.89950284090909094, 0.87819602272727271, 0.89026988636363635, 0.89275568181818177, 0.88884943181818177, 0.89666193181818177, 0.89630681818181823, 0.88387784090909094, 0.88494318181818177, 0.88920454545454541, 0.88991477272727271, 0.88387784090909094, 0.86257102272727271, 0.83522727272727271, 0.83416193181818177, 0.83238636363636365, 0.83416193181818177, 0.83629261363636365, 0.82599431818181823, 0.83309659090909094, 0.80433238636363635, 0.80610795454545459, 0.79758522727272729, 0.78053977272727271, 0.78338068181818177, 0.78018465909090906, 0.77485795454545459, 0.78267045454545459, 0.78160511363636365, 0.76100852272727271, 0.77911931818181823, 0.74680397727272729, 0.75035511363636365, 0.72585227272727271, 0.74573863636363635, 0.74715909090909094, 0.72904829545454541, 0.71910511363636365, 0.71981534090909094, 0.70667613636363635, 0.71910511363636365, 0.70205965909090906, 0.71519886363636365, 0.68607954545454541, 0.68359375, 0.67862215909090906, 0.66193181818181823, 0.671875, 0.66583806818181823, 0.65482954545454541, 0.66690340909090906, 0.66761363636363635, 0.65447443181818177, 0.63210227272727271, 0.65376420454545459, 0.63139204545454541, 0.63210227272727271, 0.62713068181818177, 0.62748579545454541, 0.61008522727272729, 0.61434659090909094, 0.60262784090909094, 0.61825284090909094, 0.59375, 0.59730113636363635, 0.60973011363636365, 0.60333806818181823, 0.59197443181818177, 0.58771306818181823, 0.58877840909090906, 0.56924715909090906, 0.56178977272727271, 0.57208806818181823, 0.56853693181818177, 0.57066761363636365, 0.56285511363636365, 0.55681818181818177, 0.54723011363636365, 0.55362215909090906, 0.56285511363636365, 0.56001420454545459, 0.51988636363636365, 0.53231534090909094, 0.51811079545454541, 0.52201704545454541, 0.51846590909090906, 0.51811079545454541, 0.50568181818181823, 0.51988636363636365, 0.49786931818181818, 0.50035511363636365, 0.50071022727272729, 0.48615056818181818, 0.48508522727272729, 0.47301136363636365, 0.48295454545454547, 0.48153409090909088, 0.47052556818181818, 0.45490056818181818, 0.46164772727272729, 0.43607954545454547, 0.43607954545454547, 0.45276988636363635, 0.44673295454545453, 0.44673295454545453, 0.42151988636363635, 0.42933238636363635, 0.41796875, 0.42365056818181818, 0.40731534090909088, 0.40625, 0.40376420454545453, 0.40944602272727271, 0.40696022727272729, 0.390625, 0.36967329545454547, 0.38458806818181818, 0.39026988636363635, 0.37642045454545453, 0.36612215909090912, 0.36221590909090912, 0.36186079545454547, 0.36079545454545453, 0.35582386363636365, 0.35333806818181818, 0.35227272727272729, 0.34446022727272729, 0.33096590909090912, 0.30610795454545453, 0.33487215909090912, 0.3359375, 0.33238636363636365, 0.3046875, 0.328125, 0.29794034090909088, 0.31001420454545453, 0.29438920454545453, 0.30823863636363635, 0.29545454545454547, 0.30504261363636365, 0.29936079545454547, 0.2890625, 0.28835227272727271, 0.27166193181818182, 0.28835227272727271, 0.27414772727272729, 0.26811079545454547, 0.25248579545454547, 0.25532670454545453, 0.26100852272727271, 0.24893465909090909, 0.24396306818181818, 0.23508522727272727, 0.22798295454545456, 0.22585227272727273, 0.234375, 0.22301136363636365, 0.20632102272727273, 0.20276988636363635, 0.20703125, 0.19779829545454544, 0.20809659090909091, 0.20632102272727273, 0.19389204545454544, 0.18430397727272727, 0.19105113636363635, 0.17045454545454544, 0.17009943181818182, 0.17294034090909091, 0.17436079545454544, 0.16761363636363635, 0.16335227272727273, 0.16867897727272727, 0.15873579545454544, 0.15767045454545456, 0.13884943181818182, 0.13813920454545456, 0.13565340909090909, 0.13813920454545456, 0.13742897727272727, 0.13387784090909091, 0.11008522727272728, 0.13529829545454544, 0.12748579545454544, 0.11576704545454546, 0.13245738636363635, 0.10759943181818182, 0.10404829545454546, 0.094460227272727279, 0.10120738636363637, 0.10298295454545454, 0.088423295454545456, 0.092684659090909088, 0.089488636363636367, 0.094815340909090912, 0.083451704545454544, 0.087357954545454544, 0.082386363636363633, 0.079190340909090912, 0.078835227272727279, 0.068536931818181823, 0.068536931818181823, 0.05823863636363636, 0.052201704545454544, 0.069602272727272721, 0.06640625, 0.049360795454545456, 0.060369318181818184, 0.050071022727272728, 0.046164772727272728, 0.044744318181818184, 0.041903409090909088, 0.046875, 0.03941761363636364, 0.046875, 0.044744318181818184, 0.0390625, 0.033735795454545456, 0.03480113636363636, 0.033735795454545456, 0.02911931818181818, 0.032670454545454544, 0.026633522727272728, 0.02947443181818182, 0.022727272727272728, 0.025923295454545456, 0.03125, 0.02166193181818182, 0.024147727272727272, 0.016690340909090908, 0.020596590909090908, 0.019176136363636364, 0.015625, 0.018465909090909092, 0.015625, 0.01278409090909091, 0.014204545454545454, 0.014204545454545454, 0.011008522727272728, 0.014914772727272728, 0.011363636363636364, 0.0088778409090909099, 0.008167613636363636, 0.009588068181818182, 0.005681818181818182, 0.007102272727272727, 0.007102272727272727, 0.007457386363636364, 0.007102272727272727, 0.006747159090909091, 0.004971590909090909, 0.00390625, 0.0053267045454545451, 0.006036931818181818, 0.0035511363636363635, 0.00390625, 0.0063920454545454549, 0.0035511363636363635, 0.0035511363636363635, 0.0017755681818181818, 0.0035511363636363635, 0.004261363636363636, 0.002130681818181818, 0.002130681818181818, 0.002130681818181818, 0.0017755681818181818, 0.001065340909090909, 0.0014204545454545455, 0.00071022727272727275, 0.00035511363636363637, 0.0017755681818181818, 0.002130681818181818, 0.00071022727272727275, 0.00071022727272727275, 0.00071022727272727275]
  valid.accur. [0.11922304085733426, 0.11922304085733426, 0.11922304085733426, 0.11922304085733426, 0.11922304085733426, 0.11922304085733426, 0.11922304085733426, 0.11922304085733426, 0.11922304085733426, 0.11922304085733426, 0.11922304085733426, 0.11922304085733426, 0.11922304085733426, 0.11922304085733426, 0.11922304085733426, 0.11922304085733426, 0.11922304085733426, 0.11922304085733426, 0.11922304085733426, 0.11922304085733426, 0.11922304085733426, 0.11922304085733426, 0.11922304085733426, 0.11922304085733426, 0.11922304085733426, 0.11922304085733426, 0.11922304085733426, 0.11922304085733426, 0.11922304085733426, 0.11922304085733426, 0.11922304085733426, 0.11922304085733426, 0.11922304085733426, 0.11922304085733426, 0.11922304085733426, 0.11788345612860018, 0.1265907568653717, 0.1386470194239786, 0.14936369725385135, 0.1399866041527127, 0.14266577361018085, 0.14668452779638308, 0.14936369725385135, 0.1486939048894843, 0.15606162089752174, 0.1808439383791025, 0.17280643000669793, 0.18017414601473547, 0.19022103148024117, 0.20495646349631613, 0.19156061620897524, 0.2143335565974548, 0.2163429336905559, 0.1942397856664434, 0.20830542531815133, 0.2129939718687207, 0.2143335565974548, 0.21902210314802406, 0.2143335565974548, 0.2210314802411253, 0.20897521768251837, 0.19892833221701267, 0.21165438713998663, 0.21567314132618887, 0.22505023442732752, 0.21902210314802406, 0.2129939718687207, 0.2210314802411253, 0.2230408573342264, 0.20830542531815133, 0.21768251841928998, 0.2230408573342264, 0.21165438713998663, 0.21768251841928998, 0.21567314132618887, 0.20361687876758205, 0.21902210314802406, 0.22036168787675825, 0.20562625586068317, 0.19892833221701267, 0.21701272605492294, 0.20026791694574686, 0.21232417950435367, 0.21902210314802406, 0.20294708640321502, 0.2042866711319491, 0.2163429336905559, 0.21500334896182183, 0.20964501004688552, 0.2042866711319491, 0.20227729403884798, 0.19825853985264563, 0.19959812458137982, 0.18821165438713994, 0.20294708640321502, 0.20227729403884798, 0.18955123911587413, 0.19290020093770932, 0.20830542531815133, 0.19223040857334228, 0.1942397856664434, 0.19156061620897524, 0.1875418620227729, 0.19825853985264563, 0.20160750167448094, 0.17615539182853313, 0.19223040857334228, 0.18955123911587413, 0.19624916275954452, 0.1942397856664434, 0.19691895512391155, 0.18821165438713994, 0.18553248492967178, 0.18821165438713994, 0.19022103148024117, 0.1908908238446082, 0.19959812458137982, 0.1975887474882786, 0.19156061620897524, 0.19490957803081044, 0.17816476892163424, 0.20160750167448094, 0.1774949765572672, 0.19223040857334228, 0.1774949765572672, 0.19825853985264563, 0.18285331547220363, 0.1908908238446082, 0.19022103148024117, 0.18553248492967178, 0.1875418620227729, 0.17481580709979905, 0.18352310783657066, 0.1942397856664434, 0.20361687876758205, 0.20160750167448094, 0.1821835231078366, 0.19290020093770932, 0.18017414601473547, 0.18955123911587413, 0.17950435365036843, 0.18821165438713994, 0.1888814467515071, 0.1808439383791025, 0.1788345612860014, 0.20294708640321502, 0.19022103148024117, 0.17950435365036843, 0.19290020093770932, 0.16677829872739447, 0.1721366376423309, 0.18821165438713994, 0.18352310783657066, 0.18151373074346955, 0.1808439383791025, 0.18017414601473547, 0.18687206965840586, 0.1774949765572672, 0.17280643000669793, 0.1841929002009377, 0.18151373074346955, 0.18285331547220363, 0.18687206965840586, 0.1821835231078366, 0.20696584058941725, 0.1788345612860014, 0.18553248492967178, 0.17816476892163424, 0.1841929002009377, 0.16811788345612855, 0.17280643000669793, 0.17079705291359681, 0.17682518419290016, 0.1721366376423309, 0.15941058271935704, 0.1788345612860014, 0.174146014735432, 0.17280643000669793, 0.1553918285331547, 0.16476892163429335, 0.174146014735432, 0.18620227729403882, 0.17950435365036843, 0.16476892163429335, 0.18285331547220363, 0.17146684527796385, 0.17682518419290016, 0.1808439383791025, 0.18017414601473547, 0.16811788345612855, 0.16945746818486274, 0.1620897521768252, 0.1774949765572672, 0.16945746818486274, 0.1754855994641661, 0.1774949765572672, 0.17950435365036843, 0.17615539182853313, 0.1774949765572672, 0.18620227729403882, 0.1674480910917615, 0.17012726054922978, 0.1654387139986604, 0.1721366376423309, 0.1788345612860014, 0.17615539182853313, 0.1841929002009377, 0.1721366376423309, 0.17816476892163424, 0.17280643000669793, 0.1687876758204957, 0.1654387139986604, 0.17682518419290016, 0.1754855994641661, 0.18352310783657066, 0.17682518419290016, 0.18486269256530474, 0.1841929002009377, 0.16677829872739447, 0.16677829872739447, 0.16677829872739447, 0.1654387139986604, 0.16342933690555927, 0.1721366376423309, 0.16476892163429335, 0.1687876758204957, 0.17481580709979905, 0.17280643000669793, 0.16811788345612855, 0.16141995981245816, 0.1640991292699263, 0.1774949765572672, 0.16342933690555927, 0.16811788345612855, 0.16342933690555927, 0.16141995981245816, 0.16476892163429335, 0.17615539182853313, 0.1674480910917615, 0.16275954454119224, 0.16075016744809112, 0.1654387139986604, 0.1620897521768252, 0.15606162089752174, 0.15941058271935704, 0.16008037508372408, 0.1654387139986604, 0.17280643000669793, 0.1520428667113195, 0.1687876758204957, 0.15338245144005358, 0.1574012056262558, 0.1721366376423309, 0.16945746818486274, 0.1640991292699263, 0.1654387139986604, 0.16677829872739447, 0.16811788345612855, 0.15807099799062285, 0.1620897521768252, 0.1640991292699263, 0.16075016744809112, 0.1574012056262558, 0.15405224380442062, 0.16677829872739447, 0.16342933690555927, 0.15874079035499, 0.16677829872739447, 0.16275954454119224, 0.1574012056262558, 0.1620897521768252, 0.16476892163429335, 0.16275954454119224, 0.15941058271935704, 0.1687876758204957, 0.1620897521768252, 0.1654387139986604, 0.16342933690555927, 0.16008037508372408, 0.16677829872739447, 0.1620897521768252, 0.16075016744809112, 0.1654387139986604, 0.1620897521768252, 0.16141995981245816, 0.1620897521768252, 0.16275954454119224, 0.16008037508372408, 0.16075016744809112, 0.16342933690555927, 0.16275954454119224, 0.16677829872739447, 0.16342933690555927, 0.16342933690555927, 0.16141995981245816, 0.16141995981245816, 0.15405224380442062, 0.16141995981245816, 0.1620897521768252, 0.16476892163429335]

LR_pre=0.001: it doesn't learn
LR_pre=0.01: it doesn't learn
LR_pre=0.1: can't pretrain, err=NaN

LR_pre=0.00001: worse (acc up to 0.19)

on spec features: it doesn't learn

LR=0.1: worse (acc up to 0.19)

LR=0.01: (acc up to 0.21 at 200)

LR=0.003: it doesn't learn

bigger layer, 3 x 1024 layers, LR=0.03: (acc up to 0.21 at 50)

more layers, 4 x 512: better (acc up to 0.25 at 60)

more layers, 5 x 512: worse (acc up to 0.18 at 110)

l2_costs=0.0001, 4 x 512: (acc up to 0.25 at 56)
100 utt., 7 cont., DBN[585, 512, 512, 512, 512, 42], 300 epochs, LR: 0.03, mom: 0.5, LR_decay: 1.0, L2: 0.0001, [15, 15, 15, 15, 15] pretr. epochs, LR_pretr: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.8984375, 0.89028532608695654, 0.89096467391304346, 0.88077445652173914, 0.88349184782608692, 0.89572010869565222, 0.89198369565217395, 0.88451086956521741, 0.88790760869565222, 0.89232336956521741, 0.88688858695652173, 0.88824728260869568, 0.8984375, 0.890625, 0.89096467391304346, 0.89538043478260865, 0.89707880434782605, 0.88383152173913049, 0.89504076086956519, 0.89164402173913049, 0.89130434782608692, 0.88756793478260865, 0.88892663043478259, 0.89572010869565222, 0.88858695652173914, 0.87737771739130432, 0.859375, 0.85190217391304346, 0.84137228260869568, 0.84782608695652173, 0.81351902173913049, 0.81997282608695654, 0.82846467391304346, 0.82167119565217395, 0.80604619565217395, 0.80163043478260865, 0.79076086956521741, 0.7890625, 0.78396739130434778, 0.77173913043478259, 0.76120923913043481, 0.76120923913043481, 0.74830163043478259, 0.73811141304347827, 0.73709239130434778, 0.72486413043478259, 0.7421875, 0.72622282608695654, 0.71399456521739135, 0.71365489130434778, 0.70380434782608692, 0.71637228260869568, 0.68410326086956519, 0.68648097826086951, 0.67866847826086951, 0.66202445652173914, 0.66508152173913049, 0.64775815217391308, 0.66610054347826086, 0.65013586956521741, 0.63552989130434778, 0.61684782608695654, 0.60835597826086951, 0.60835597826086951, 0.60903532608695654, 0.59714673913043481, 0.58322010869565222, 0.56963315217391308, 0.58220108695652173, 0.57982336956521741, 0.57336956521739135, 0.56487771739130432, 0.56657608695652173, 0.55434782608695654, 0.54042119565217395, 0.54042119565217395, 0.53125, 0.51154891304347827, 0.53362771739130432, 0.50611413043478259, 0.50815217391304346, 0.48607336956521741, 0.48233695652173914, 0.49116847826086957, 0.48403532608695654, 0.49150815217391303, 0.4718070652173913, 0.45380434782608697, 0.47418478260869568, 0.46807065217391303, 0.45516304347826086, 0.46535326086956524, 0.39707880434782611, 0.42561141304347827, 0.43138586956521741, 0.4093070652173913, 0.41474184782608697, 0.40251358695652173, 0.39707880434782611, 0.38247282608695654, 0.39911684782608697, 0.3624320652173913, 0.37058423913043476, 0.38688858695652173, 0.34239130434782611, 0.35292119565217389, 0.34510869565217389, 0.34952445652173914, 0.31080163043478259, 0.35733695652173914, 0.3125, 0.30706521739130432, 0.28940217391304346, 0.35427989130434784, 0.27547554347826086, 0.26426630434782611, 0.3077445652173913, 0.24864130434782608, 0.27173913043478259, 0.25237771739130432, 0.24830163043478262, 0.29653532608695654, 0.25577445652173914, 0.20889945652173914, 0.2469429347826087, 0.21059782608695651, 0.22282608695652173, 0.24252717391304349, 0.21773097826086957, 0.21467391304347827, 0.16610054347826086, 0.16576086956521738, 0.20991847826086957, 0.15828804347826086, 0.15183423913043478, 0.20889945652173914, 0.14639945652173914, 0.1436820652173913, 0.14707880434782608, 0.14402173913043478, 0.14232336956521738, 0.18987771739130435, 0.10563858695652174, 0.092051630434782608]
  valid.accur. [0.06764295676429566, 0.06764295676429566, 0.06764295676429566, 0.06764295676429566, 0.06764295676429566, 0.06764295676429566, 0.06764295676429566, 0.06764295676429566, 0.06764295676429566, 0.06764295676429566, 0.06764295676429566, 0.06764295676429566, 0.06764295676429566, 0.06764295676429566, 0.06764295676429566, 0.06764295676429566, 0.06764295676429566, 0.06764295676429566, 0.06764295676429566, 0.06764295676429566, 0.06764295676429566, 0.06764295676429566, 0.06764295676429566, 0.06764295676429566, 0.06764295676429566, 0.0704323570432357, 0.09902370990237097, 0.09205020920502094, 0.07112970711297073, 0.13528591352859132, 0.13807531380753135, 0.13737796373779643, 0.1827057182705718, 0.18967921896792195, 0.1764295676429568, 0.1952580195258019, 0.19804741980474194, 0.21269177126917715, 0.21269177126917715, 0.20920502092050208, 0.22454672245467222, 0.21408647140864712, 0.20920502092050208, 0.22105997210599726, 0.22384937238493718, 0.2259414225941423, 0.22524407252440726, 0.2364016736401674, 0.23082287308228733, 0.23361227336122736, 0.24128312412831243, 0.24198047419804747, 0.23500697350069732, 0.2405857740585774, 0.2447698744769874, 0.23291492329149233, 0.2510460251046025, 0.2405857740585774, 0.2280334728033473, 0.2364016736401674, 0.22454672245467222, 0.22245467224546722, 0.21059972105997216, 0.22384937238493718, 0.21199442119944212, 0.23291492329149233, 0.23152022315202236, 0.22942817294281725, 0.2364016736401674, 0.2175732217573222, 0.21408647140864712, 0.22245467224546722, 0.22454672245467222, 0.21896792189679215, 0.2154811715481172, 0.19665271966527198, 0.21827057182705722, 0.22105997210599726, 0.22454672245467222, 0.2322175732217573, 0.21827057182705722, 0.19804741980474194, 0.21199442119944212, 0.19874476987447698, 0.2175732217573222, 0.19665271966527198, 0.21617852161785212, 0.20920502092050208, 0.21199442119944212, 0.21896792189679215, 0.20432357043235705, 0.19874476987447698, 0.20781032078103212, 0.22315202231520226, 0.20502092050209209, 0.20781032078103212, 0.20432357043235705, 0.19735006973500702, 0.19804741980474194, 0.18619246861924688, 0.21269177126917715, 0.20711297071129708, 0.19037656903765687, 0.20641562064156205, 0.20083682008368198, 0.20223152022315205, 0.19037656903765687, 0.19595536959553694, 0.19944211994421202, 0.20292887029288698, 0.21199442119944212, 0.20990237099023712, 0.19595536959553694, 0.201534170153417, 0.20711297071129708, 0.19246861924686187, 0.20781032078103212, 0.21199442119944212, 0.19386331938633194, 0.20850767085076705, 0.20711297071129708, 0.1910739191073919, 0.20711297071129708, 0.1827057182705718, 0.20432357043235705, 0.20990237099023712, 0.21199442119944212, 0.18549511854951184, 0.19874476987447698, 0.20641562064156205, 0.19456066945606698, 0.201534170153417, 0.19037656903765687, 0.19386331938633194, 0.20502092050209209, 0.20502092050209209, 0.1889818688981869, 0.19665271966527198, 0.1931659693165969, 0.21338912133891208, 0.1785216178521618, 0.20711297071129708, 0.205718270571827, 0.1910739191073919]


1000 utt., 7 cont., 4 x 512: it doesn't learn
1000 utt., 7 cont., 4 x 1024: it doesn't learn
1000 utt., 7 cont., 4 x 2048: it doesn't learn

less data: (acc up to 0.25 at 56)
300 utt., 7 cont., DBN[585, 512, 512, 512, 55], 300 epochs, LR: 0.03, mom: 0.5, LR_decay: 1.0, L2: 0.0001, [15, 15, 15, 15] pretr. epochs, LR_pretr: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.91346914556962022, 0.914754746835443, 0.913370253164557, 0.90892009493670889, 0.909315664556962, 0.90427215189873422, 0.90051424050632911, 0.90674446202531644, 0.89883306962025311, 0.88607594936708856, 0.87964794303797467, 0.86837420886075944, 0.85601265822784811, 0.850870253164557, 0.86164952531645567, 0.85532041139240511, 0.85136471518987344, 0.84117879746835444, 0.82931170886075944, 0.8046875, 0.79222705696202533, 0.77808544303797467, 0.76414161392405067, 0.76008702531645567, 0.74940664556962022, 0.75019778481012656, 0.74980221518987344, 0.74663765822784811, 0.74950553797468356, 0.74841772151898733, 0.74228639240506333, 0.73922072784810122, 0.73457278481012656, 0.73308939873417722, 0.73012262658227844, 0.73566060126582278, 0.72329905063291144, 0.71726661392405067, 0.72082674050632911, 0.72033227848101267, 0.70539952531645567, 0.71420094936708856, 0.70015822784810122, 0.69857594936708856, 0.69996044303797467, 0.69274129746835444, 0.69996044303797467, 0.69185126582278478, 0.68868670886075944, 0.68255537974683544, 0.68393987341772156, 0.67622626582278478, 0.67385284810126578, 0.66890822784810122, 0.66772151898734178, 0.66702927215189878, 0.66050237341772156, 0.66178797468354433, 0.653876582278481, 0.66060126582278478, 0.65090981012658233, 0.64161392405063289, 0.63914161392405067, 0.62856012658227844, 0.62341772151898733, 0.63093354430379744, 0.62183544303797467, 0.61857199367088611, 0.611748417721519, 0.60551819620253167, 0.60502373417721522, 0.611056170886076, 0.6015625, 0.59226661392405067, 0.59760680379746833, 0.60443037974683544, 0.59355221518987344, 0.59404667721518989, 0.58405854430379744, 0.57703718354430378, 0.57308148734177211, 0.57060917721518989, 0.55765427215189878, 0.55201740506329111, 0.55824762658227844, 0.55933544303797467, 0.54272151898734178, 0.53787579113924056, 0.53767800632911389, 0.53006329113924056, 0.529568829113924, 0.52946993670886078, 0.51720727848101267, 0.51839398734177211, 0.5234375, 0.50336234177215189, 0.50217563291139244, 0.49317642405063289, 0.49169303797468356, 0.48872626582278483, 0.48239715189873417, 0.48922072784810128, 0.47310126582278483, 0.46528876582278483, 0.46232199367088606, 0.46054193037974683, 0.456190664556962, 0.44511471518987344, 0.44610363924050633, 0.42365506329113922, 0.43858781645569622, 0.42790743670886078, 0.4128757911392405, 0.39942642405063289, 0.4128757911392405, 0.39032832278481011, 0.39507515822784811, 0.385878164556962, 0.37430775316455694, 0.38132911392405061, 0.36323180379746833, 0.35433148734177217, 0.35304588607594939, 0.36342958860759494, 0.33732199367088606, 0.3449367088607595, 0.33198180379746833, 0.32525712025316456, 0.31497231012658228, 0.31714794303797467, 0.31141218354430378, 0.29202927215189872, 0.30221518987341772, 0.27660205696202533, 0.28223892405063289, 0.26720727848101267, 0.26315268987341772, 0.26720727848101267, 0.25316455696202533, 0.24080300632911392, 0.24406645569620253, 0.23892405063291139, 0.22844145569620253, 0.2265625, 0.19847705696202531, 0.23140822784810128, 0.19392800632911392, 0.19897151898734178, 0.205498417721519, 0.17909414556962025, 0.17691851265822786, 0.17355617088607594, 0.14754746835443039, 0.15803006329113925, 0.15951344936708861, 0.14596518987341772, 0.13746044303797469, 0.17118275316455697, 0.10621044303797468, 0.14200949367088608, 0.11946202531645569, 0.11629746835443038, 0.11303401898734178, 0.10522151898734178, 0.099782436708860764]
  valid.accur. [0.07621890547263677, 0.09492537313432836, 0.09492537313432836, 0.07621890547263677, 0.07661691542288562, 0.09691542288557209, 0.08338308457711441, 0.11741293532338304, 0.08975124378109456, 0.0909452736318408, 0.12179104477611935, 0.12497512437810943, 0.14208955223880593, 0.11681592039800992, 0.1303482587064677, 0.13771144278606962, 0.13293532338308456, 0.1482587064676617, 0.16656716417910444, 0.17412935323383083, 0.1773134328358209, 0.17830845771144277, 0.1810945273631841, 0.1789054726368159, 0.17830845771144277, 0.18129353233830847, 0.18129353233830847, 0.18447761194029855, 0.1802985074626866, 0.1840796019900498, 0.1735323383084577, 0.1906467661691542, 0.19044776119402984, 0.1892537313432836, 0.18208955223880596, 0.18885572139303486, 0.19681592039801, 0.18447761194029855, 0.19343283582089554, 0.19024875621890547, 0.20597014925373136, 0.1996019900497512, 0.19482587064676615, 0.20676616915422885, 0.20318407960199003, 0.20676616915422885, 0.20776119402985072, 0.21353233830845775, 0.21114427860696516, 0.20557213930348261, 0.2093532338308458, 0.21194029850746265, 0.21651741293532334, 0.21950248756218904, 0.21333333333333337, 0.2123383084577114, 0.21930348258706467, 0.22089552238805965, 0.22009950248756216, 0.22069651741293528, 0.22228855721393037, 0.2280597014925373, 0.22447761194029847, 0.21432835820895524, 0.2286567164179104, 0.22547263681592045, 0.2191044776119403, 0.2204975124378109, 0.22407960199004973, 0.21552238805970148, 0.21791044776119406, 0.2234825870646766, 0.22009950248756216, 0.21850746268656718, 0.21970149253731341, 0.22368159203980098, 0.2153233830845771, 0.22487562189054722, 0.2204975124378109, 0.2228855721393035, 0.22328358208955223, 0.2199004975124378, 0.22228855721393037, 0.22547263681592045, 0.2183084577114428, 0.22527363184079607, 0.222089552238806, 0.222089552238806, 0.21810945273631843, 0.22606965174129356, 0.2280597014925373, 0.21512437810945273, 0.21273631840796015, 0.21970149253731341, 0.21651741293532334, 0.20776119402985072, 0.205771144278607, 0.2115422885572139, 0.22089552238805965, 0.2204975124378109, 0.22527363184079607, 0.2242786069651741, 0.22149253731343288, 0.21592039800995022, 0.22467661691542284, 0.21492537313432836, 0.2093532338308458, 0.21333333333333337, 0.21850746268656718, 0.21552238805970148, 0.21253731343283577, 0.2153233830845771, 0.2085572139303482, 0.20835820895522383, 0.2093532338308458, 0.20537313432835824, 0.20457711442786075, 0.20019900497512433, 0.20955223880597018, 0.20477611940298512, 0.20238805970149254, 0.2085572139303482, 0.20238805970149254, 0.21174129353233828, 0.20955223880597018, 0.2049751243781095, 0.20278606965174129, 0.20995024875621893, 0.20616915422885573, 0.20815920398009946, 0.2033830845771144, 0.2025870646766169, 0.20378109452736315, 0.1960199004975124, 0.20756218905472634, 0.20318407960199003, 0.19800995024875623, 0.20676616915422885, 0.20059701492537318, 0.19582089552238802, 0.19562189054726364, 0.19999999999999996, 0.18825870646766174, 0.21293532338308463, 0.19761194029850748, 0.2011940298507463, 0.1944278606965174, 0.19880597014925372, 0.19582089552238802, 0.2025870646766169, 0.19343283582089554, 0.2003980099502487, 0.19363184079601992, 0.20099502487562193, 0.1974129353233831, 0.19482587064676615, 0.19721393034825874, 0.19721393034825874, 0.18388059701492532, 0.20238805970149254, 0.18945273631840798, 0.1974129353233831, 0.19363184079601992, 0.1990049751243781, 0.1944278606965174]

--- spec features

momentum varying on 100 utt.:
100 utt., 7 cont., DBN[1920, 1024, 1024, 1024, 42], 25 epochs, LR: 0.01, mom: 0.9, LR_decay: 0.99, L2: 0.0001, 0 pretr. epochs, LR_pretr: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.7943638392857143, 0.7128208705357143, 0.6916155133928571, 0.6718052455357143, 0.6550641741071429, 0.6363002232142857, 0.6153041294642857, 0.5984235491071429, 0.5849609375, 0.5684291294642857, 0.5661272321428571, 0.5481305803571429, 0.5244838169642857, 0.5225306919642857, 0.5071847098214286, 0.4966517857142857, 0.49448939732142855, 0.486328125, 0.46791294642857145, 0.46630859375, 0.4619838169642857, 0.44510323660714285, 0.43715122767857145, 0.4248046875, 0.42354910714285715]
  valid.accur. [0.26530612244897955, 0.2740752551020408, 0.3118622448979592, 0.29496173469387754, 0.3458227040816326, 0.31951530612244894, 0.3215880102040817, 0.3286033163265306, 0.3346619897959183, 0.34725765306122447, 0.345344387755102, 0.3431122448979592, 0.3676658163265306, 0.35251913265306123, 0.36080994897959184, 0.34693877551020413, 0.37197066326530615, 0.36033163265306123, 0.3770727040816326, 0.36367984693877553, 0.3491709183673469, 0.3705357142857143, 0.35076530612244894, 0.36352040816326525, 0.3424744897959183]
100 utt., 7 cont., DBN[1920, 1024, 1024, 1024, 42], 25 epochs, LR: 0.01, mom: 0.8, LR_decay: 0.99, L2: 0.0001, 0 pretr. epochs, LR_pretr: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.8508586711711712, 0.74619932432432434, 0.71114864864864868, 0.69580518018018023, 0.69115990990990994, 0.66730011261261257, 0.65617961711711714, 0.64731137387387383, 0.63837274774774777, 0.63309403153153154, 0.62281813063063063, 0.61641328828828834, 0.60353322072072069, 0.59980292792792789, 0.59494650900900903, 0.59114583333333337, 0.58657094594594594, 0.5706644144144144, 0.5736908783783784, 0.56897522522522526, 0.56489301801801806, 0.56798986486486491, 0.5543355855855856, 0.55525056306306309, 0.5394144144144144]
  valid.accur. [0.23835869064084836, 0.2878438604579684, 0.2973720608575381, 0.30244352236053484, 0.310127554940833, 0.322268326417704, 0.32272936837252186, 0.3228830490241279, 0.3302597203012141, 0.3276471492239127, 0.3336406946365452, 0.3445520209005686, 0.3376363915783003, 0.34332257568772095, 0.32795451052712465, 0.33548486245581677, 0.33225756877209156, 0.35669279237743967, 0.355617027816198, 0.35761487628707544, 0.3457814661134163, 0.3589980021515291, 0.34977716305517137, 0.3482403565391117, 0.36652835408022133]
100 utt., 7 cont., DBN[1920, 1024, 1024, 1024, 42], 25 epochs, LR: 0.01, mom: 0.7, LR_decay: 0.99, L2: 0.0001, 0 pretr. epochs, LR_pretr: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.83994932432432434, 0.75689752252252251, 0.7098817567567568, 0.69622747747747749, 0.68510698198198194, 0.6722269144144144, 0.66772240990990994, 0.65484234234234229, 0.64449605855855852, 0.63027871621621623, 0.62507038288288286, 0.62865990990990994, 0.61549831081081086, 0.61050112612612617, 0.60374436936936937, 0.60325168918918914, 0.581151463963964, 0.5886120495495496, 0.58305180180180183, 0.57566159909909909, 0.56425957207207211, 0.56932713963963966, 0.55862894144144148, 0.5573620495495496, 0.55356137387387383]
  valid.accur. [0.13898832684824902, 0.2188326848249027, 0.24062256809338523, 0.24311284046692605, 0.24964980544747084, 0.2731517509727627, 0.26132295719844356, 0.27066147859922174, 0.28980544747081716, 0.28342412451361865, 0.30070038910505836, 0.2930739299610895, 0.29540856031128404, 0.3069260700389105, 0.3111284046692607, 0.2874708171206226, 0.31377431906614783, 0.2992996108949416, 0.3176653696498054, 0.3161089494163424, 0.313307392996109, 0.31470817120622563, 0.3224902723735409, 0.3243579766536965, 0.3168871595330739]
100 utt., 7 cont., DBN[1920, 1024, 1024, 1024, 42], 25 epochs, LR: 0.01, mom: 0.6, LR_decay: 0.99, L2: 0.0001, 0 pretr. epochs, LR_pretr: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.87866426991150437, 0.81132466814159288, 0.74723451327433632, 0.73250829646017701, 0.71232024336283184, 0.69462112831858402, 0.68058628318584069, 0.67387997787610621, 0.65521294247787609, 0.64809181415929207, 0.63827433628318586, 0.63205199115044253, 0.62659015486725667, 0.62292588495575218, 0.61538993362831862, 0.6132466814159292, 0.60792311946902655, 0.6025304203539823, 0.59119192477876104, 0.59146847345132747, 0.58794247787610621, 0.58455475663716816, 0.58517699115044253, 0.58213495575221241, 0.5761891592920354]
  valid.accur. [0.07364528059173503, 0.24473388004502328, 0.2773757838880849, 0.2826821032320309, 0.27013989387361315, 0.26065283807686124, 0.24827142627432064, 0.2651551696414215, 0.2907219810258884, 0.30873130728412923, 0.28493326901431093, 0.2666023476443158, 0.28525486412606527, 0.2751246181058048, 0.2918475639170285, 0.2751246181058048, 0.2961890979257116, 0.29425952725518567, 0.2812349252291365, 0.291365171249397, 0.2617784209680013, 0.3130728412928123, 0.2907219810258884, 0.29860106126386876, 0.3175751728573726]
100 utt., 7 cont., DBN[1920, 1024, 1024, 1024, 42], 25 epochs, LR: 0.01, mom: 0.5, LR_decay: 0.99, L2: 0.0001, 0 pretr. epochs, LR_pretr: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.82637392241379315, 0.7911503232758621, 0.72413793103448276, 0.70171066810344829, 0.6974003232758621, 0.69214709051724133, 0.68258351293103448, 0.66830549568965514, 0.65995420258620685, 0.66076239224137934, 0.65153556034482762, 0.64789870689655171, 0.63516971982758619, 0.62836745689655171, 0.63537176724137934, 0.62803071120689657, 0.62654903017241381, 0.61880387931034486, 0.61294450431034486, 0.61267510775862066, 0.60600754310344829, 0.60809536637931039, 0.61220366379310343, 0.60216864224137934, 0.60627693965517238]
  valid.accur. [0.1306136441549537, 0.1444977716832362, 0.17963661295851907, 0.20191978059650328, 0.22283167637984236, 0.2276311278711004, 0.22540281110730198, 0.23054508056222145, 0.22334590332533422, 0.23174494343503604, 0.23311621528968118, 0.24837161467260882, 0.2514569763455605, 0.2500857044909153, 0.2523140212547137, 0.26191292423723, 0.25865615358244776, 0.2553993829276654, 0.26602673980116553, 0.26979773740143986, 0.2742543709290367, 0.2749400068563592, 0.2689406924922866, 0.27562564278368185, 0.27991086732944803]

=> optimal moment=0.9

L2 varying on 100 utt.:
100 utt., 7 cont., DBN[1920, 1024, 1024, 1024, 42], 25 epochs, LR: 0.01, mom: 0.9, LR_decay: 0.99, L2: 1e-05, 0 pretr. epochs, LR_pretr: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.80736019736842102, 0.71018366228070173, 0.67735745614035092, 0.65035635964912286, 0.62643914473684215, 0.60560581140350878, 0.59196820175438591, 0.57682291666666663, 0.56133497807017541, 0.55825109649122806, 0.54331140350877194, 0.52960526315789469, 0.52412280701754388, 0.5134320175438597, 0.50082236842105265, 0.49465460526315791, 0.4896518640350877, 0.47416392543859648, 0.47299890350877194, 0.46169133771929827, 0.45853892543859648, 0.45141173245614036, 0.43098958333333331, 0.42893366228070173, 0.42660361842105265]
  valid.accur. [0.2576054955839058, 0.2904808635917566, 0.3197579326136736, 0.3307163886162905, 0.3084723585214262, 0.3279358848544325, 0.3120706575073602, 0.31108930323846906, 0.3320248609748119, 0.31959437356885834, 0.30013084723585215, 0.3107621851488387, 0.3307163886162905, 0.3204121687929342, 0.32237487733071635, 0.30372914622178604, 0.32744520771998686, 0.32646385345109585, 0.32777232580961724, 0.30569185475956817, 0.2808308799476611, 0.29702322538436376, 0.31370624795551194, 0.30323846908734053, 0.33316977428851813]
100 utt., 7 cont., DBN[1920, 1024, 1024, 1024, 42], 25 epochs, LR: 0.01, mom: 0.9, LR_decay: 0.99, L2: 3e-05, 0 pretr. epochs, LR_pretr: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.79483389639639634, 0.70059121621621623, 0.67131193693693691, 0.65632038288288286, 0.637598536036036, 0.62155123873873874, 0.61359797297297303, 0.59973254504504503, 0.578125, 0.56362612612612617, 0.54905686936936937, 0.54328547297297303, 0.52139639639639634, 0.51288006756756754, 0.50520833333333337, 0.49401745495495497, 0.48317849099099097, 0.47501407657657657, 0.466356981981982, 0.45474380630630629, 0.44742398648648651, 0.44552364864864863, 0.43320664414414417, 0.42518299549549549, 0.4205377252252252]
  valid.accur. [0.22548866301798276, 0.24128225175918683, 0.2697419859265051, 0.26379984362783426, 0.2688037529319781, 0.27771696637998433, 0.2825645035183737, 0.2860046911649726, 0.27646598905394837, 0.30492572322126665, 0.3099296325254105, 0.29038311180609855, 0.29304143862392495, 0.3136825645035184, 0.2897576231430805, 0.3108678655199375, 0.30774042220484754, 0.3007036747458952, 0.306958561376075, 0.30774042220484754, 0.3016419077404222, 0.3135261923377639, 0.311024237685692, 0.3316653635652854, 0.32243940578577013]
100 utt., 7 cont., DBN[1920, 1024, 1024, 1024, 42], 25 epochs, LR: 0.01, mom: 0.9, LR_decay: 0.99, L2: 0.0001, 0 pretr. epochs, LR_pretr: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.7964564732142857, 0.7121930803571429, 0.6796875, 0.6478794642857143, 0.6320452008928571, 0.6153041294642857, 0.6127232142857143, 0.5904715401785714, 0.5794503348214286, 0.5635463169642857, 0.55224609375, 0.5422712053571429, 0.5325753348214286, 0.5154157366071429, 0.5072544642857143, 0.4931640625, 0.4906529017857143, 0.48618861607142855, 0.46812220982142855, 0.4686802455357143, 0.44747488839285715, 0.43722098214285715, 0.4365234375, 0.42857142857142855, 0.42215401785714285]
  valid.accur. [0.19573180442745663, 0.2572065615543876, 0.27329192546583847, 0.29511068641503424, 0.30164038859691034, 0.2911291606943781, 0.2973403408186017, 0.29096989966555187, 0.2995699952221691, 0.28093645484949836, 0.2984551680203854, 0.2892180283484631, 0.287147634973722, 0.2984551680203854, 0.29749960184742796, 0.31406274884535756, 0.2987736900780379, 0.2888995062908106, 0.29096989966555187, 0.2830068482242395, 0.3041885650581303, 0.29208472686733555, 0.2740882306099698, 0.2965440356744704, 0.2892180283484631]
100 utt., 7 cont., DBN[1920, 1024, 1024, 1024, 42], 25 epochs, LR: 0.01, mom: 0.9, LR_decay: 0.99, L2: 0.0003, 0 pretr. epochs, LR_pretr: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.78851902173913047, 0.69823369565217386, 0.66766304347826089, 0.6398097826086957, 0.62133152173913042, 0.60713315217391306, 0.59069293478260865, 0.57173913043478264, 0.56182065217391308, 0.55081521739130435, 0.5304347826086957, 0.52187499999999998, 0.51086956521739135, 0.50502717391304353, 0.49307065217391305, 0.48444293478260869, 0.47262228260869565, 0.47316576086956524, 0.46012228260869564, 0.45672554347826089, 0.44680706521739133, 0.44069293478260868, 0.43410326086956524, 0.4171195652173913, 0.4175271739130435]
  valid.accur. [0.16801756163458292, 0.2578520770010132, 0.24113475177304966, 0.2580209388720027, 0.2563323201621074, 0.2894292468760554, 0.3112124282337049, 0.28047956771361027, 0.31762917933130697, 0.3049645390070922, 0.3171225937183384, 0.30665315771698753, 0.31543397500844306, 0.3198243836541709, 0.32607227288078355, 0.339918946301925, 0.32742316784869974, 0.34177642688280985, 0.3264099966227626, 0.3414387031408308, 0.3505572441742655, 0.3270854441067207, 0.32320162107396155, 0.3422830124957784, 0.32978723404255317]
100 utt., 7 cont., DBN[1920, 1024, 1024, 1024, 42], 25 epochs, LR: 0.01, mom: 0.9, LR_decay: 0.99, L2: 0.001, 0 pretr. epochs, LR_pretr: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.77303340517241381, 0.6837284482758621, 0.65955010775862066, 0.6329471982758621, 0.61408943965517238, 0.59684806034482762, 0.57846174568965514, 0.56741648706896552, 0.54963631465517238, 0.54721174568965514, 0.53859105603448276, 0.52613146551724133, 0.51616379310344829, 0.50606142241379315, 0.50202047413793105, 0.49717133620689657, 0.49265894396551724, 0.47878502155172414, 0.48067079741379309, 0.47137661637931033, 0.46140894396551724, 0.46619073275862066, 0.45285560344827586, 0.44605334051724138, 0.44632273706896552]
  valid.accur. [0.21399176954732513, 0.1718106995884774, 0.21776406035665297, 0.2505144032921811, 0.24811385459533608, 0.2525720164609053, 0.2309670781893004, 0.23285322359396432, 0.230281207133059, 0.2314814814814815, 0.2496570644718793, 0.22942386831275718, 0.2709190672153635, 0.23851165980795608, 0.2712620027434842, 0.24537037037037035, 0.24348422496570643, 0.27520576131687247, 0.26423182441700965, 0.25, 0.25651577503429357, 0.25445816186556924, 0.2707475994513031, 0.27486282578875176, 0.25274348422496573]
100 utt., 7 cont., DBN[1920, 1024, 1024, 1024, 42], 25 epochs, LR: 0.01, mom: 0.9, LR_decay: 0.99, L2: 0.003, 0 pretr. epochs, LR_pretr: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.77530715811965811, 0.69284188034188032, 0.66840277777777779, 0.63688568376068377, 0.62052617521367526, 0.60743856837606836, 0.59975961538461542, 0.58880876068376065, 0.59161324786324787, 0.57592147435897434, 0.57171474358974361, 0.5625, 0.56276709401709402, 0.55121527777777779, 0.54881143162393164, 0.54814369658119655, 0.54607371794871795, 0.54139957264957261, 0.53245192307692313, 0.53712606837606836, 0.53145032051282048, 0.53151709401709402, 0.52383814102564108, 0.52116720085470081, 0.51909722222222221]
  valid.accur. [0.19606103619588355, 0.22054648687012068, 0.23687012065294533, 0.23438608942512418, 0.22657913413768627, 0.25035486160397447, 0.234208658623137, 0.2512420156139106, 0.2311923349893541, 0.25443577004968065, 0.24467707594038324, 0.2460965223562811, 0.25035486160397447, 0.24130589070262598, 0.23970901348474094, 0.2579843860894251, 0.24769339957416603, 0.2501774308019872, 0.2469836763662172, 0.2512420156139106, 0.25922640170333566, 0.26242015613910574, 0.2627750177430802, 0.25638750887154005, 0.26153300212916963]


--- varying a\part of spectrum cutting

on full spectrum [0, 22100]: (acc up to 0.35)
100 utt., 7 cont., DBN[1920, 1024, 1024, 1024, 42], 20 epochs, LR: 0.01, mom: 0.9, LR_decay: 0.99, L2: 0.0001, 0 pretr. epochs, LR_pretr: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.82059403153153154, 0.71276745495495497, 0.69144144144144148, 0.67032657657657657, 0.65188626126126126, 0.62253659909909909, 0.60318130630630629, 0.58797860360360366, 0.5848817567567568, 0.56559684684684686, 0.54553772522522526, 0.53631756756756754, 0.52942004504504503, 0.51780686936936937, 0.50591216216216217, 0.49852195945945948, 0.48317849099099097, 0.47670326576576577, 0.46776463963963966, 0.45594031531531531]
  valid.accur. [0.2652589395807645, 0.30980271270036996, 0.32567817509247843, 0.32305795314426633, 0.3030209617755857, 0.33153514180024657, 0.3387792848335388, 0.3196670776818742, 0.3363131935881628, 0.32151664611590625, 0.34617755856966703, 0.34956843403205917, 0.3403205918618989, 0.3310727496917386, 0.34602342786683105, 0.34355733662145505, 0.3503390875462392, 0.33569667077681875, 0.3415536374845869, 0.3350801479654747]

spec freq of [300, 4000] and [300, 15000] and  [0, 8000]: worse (acc up to 0.31)

spec freq of [0, 15000]: better (acc up to 0.37)
100 utt., 7 cont., DBN[1305, 1024, 1024, 1024, 42], 20 epochs, LR: 0.01, mom: 0.9, LR_decay: 0.99, L2: 0.0001, 0 pretr. epochs, LR_pretr: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.81640625, 0.72243923611111116, 0.69017650462962965, 0.67599826388888884, 0.66304976851851849, 0.63794849537037035, 0.61921296296296291, 0.60040509259259256, 0.59837962962962965, 0.57964409722222221, 0.55902777777777779, 0.54723668981481477, 0.54405381944444442, 0.53436053240740744, 0.52068865740740744, 0.51200810185185186, 0.49840856481481483, 0.49168113425925924, 0.48473668981481483, 0.47359664351851855]
  valid.accur. [0.29944895591647336, 0.3342517401392111, 0.34164733178654294, 0.31946055684454755, 0.33831206496519717, 0.3628190255220418, 0.34092227378190254, 0.32772621809744784, 0.36383410672853833, 0.3578886310904872, 0.3200406032482599, 0.35701856148491884, 0.35803364269141535, 0.34875290023201855, 0.3488979118329466, 0.31090487238979114, 0.3413573085846868, 0.34527262180974483, 0.3500580046403712, 0.3667343387470998]

low-pass filter with cutoff=15000:
100 utt., 7 cont., DBN[1305, 1024, 1024, 1024, 42], 20 epochs, LR: 0.01, mom: 0.9, LR_decay: 0.99, L2: 0.0001, 0 pretr. epochs, LR_pretr: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.78228705752212391, 0.68107024336283184, 0.66288716814159288, 0.63585453539823011, 0.62437776548672563, 0.61082688053097345, 0.59921183628318586, 0.57397676991150437, 0.56768528761061943, 0.55150719026548678, 0.53353152654867253, 0.52855365044247793, 0.51576327433628322, 0.50580752212389379, 0.49191095132743362, 0.48720962389380529, 0.47275995575221241, 0.47372787610619471, 0.45533738938053098, 0.45416205752212391]
  valid.accur. [0.2145384367963975, 0.24911547121260857, 0.2626246381473143, 0.2692183981987778, 0.2960759086522998, 0.3010614345448698, 0.2981666130588614, 0.308941781923448, 0.3044387262785462, 0.3280797684142811, 0.3311354133161788, 0.3174654229655838, 0.30733354776455457, 0.3148922483113541, 0.3192344805403666, 0.3304921196526214, 0.3250241235123834, 0.3285622386619492, 0.29382438082984885, 0.33885493727886784]

low-pass filter with cutoff=4000:

low-pass filter with cutoff=8000:
100 utt., 7 cont., DBN[1920, 1024, 1024, 1024, 42], 20 epochs, LR: 0.01, mom: 0.9, LR_decay: 0.99, L2: 0.0001, 0 pretr. epochs, LR_pretr: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.80203804347826091, 0.70074728260869568, 0.66548913043478264, 0.63091032608695652, 0.61610054347826082, 0.59361413043478262, 0.57900815217391299, 0.56141304347826082, 0.54035326086956526, 0.53763586956521736, 0.52017663043478257, 0.51311141304347829, 0.50536684782608698, 0.49191576086956523, 0.4904211956521739, 0.47105978260869563, 0.46256793478260871, 0.45095108695652175, 0.44463315217391303, 0.4362092391304348]
  valid.accur. [0.24974941530237216, 0.27581022385566323, 0.2719679251587036, 0.29619111259605746, 0.29251587036418314, 0.3098897427330438, 0.3040427664550618, 0.299198128967591, 0.30487804878048785, 0.30086869361844304, 0.31974607417307055, 0.3274306715669897, 0.3210825258937521, 0.31523554961577016, 0.31306381556966256, 0.32191780821917804, 0.31774139659204814, 0.31373204143000333, 0.3190778483127297, 0.3190778483127297]

nfft=510:
100 utt., 7 cont., DBN[3840, 1024, 1024, 1024, 42], 20 epochs, LR: 0.01, mom: 0.9, LR_decay: 0.99, L2: 0.0001, 0 pretr. epochs, LR_pretr: 0.0001, valid. size 0.3: accuracy=no,
  train errors [0.87178308823529416, 0.75689338235294112, 0.69715073529411764, 0.65885416666666663, 0.64675245098039214, 0.62484681372549022, 0.60876225490196079, 0.58777573529411764, 0.57429534313725494, 0.57613357843137258, 0.56541053921568629, 0.54059436274509809, 0.51899509803921573, 0.52098651960784315, 0.51210171568627449, 0.50367647058823528, 0.48636642156862747, 0.47533700980392157, 0.47365196078431371, 0.46231617647058826]
  valid.accur. [0.21258278145695364, 0.276158940397351, 0.3182119205298013, 0.28576158940397356, 0.32615894039735094, 0.31390728476821195, 0.31423841059602653, 0.31158940397351, 0.31357615894039736, 0.3317880794701987, 0.31059602649006623, 0.3387417218543046, 0.3264900662251655, 0.31721854304635766, 0.32913907284768207, 0.3427152317880795, 0.32251655629139075, 0.3145695364238411, 0.32417218543046356, 0.3321192052980132]

nfft=126: bad

